{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание №2: Фрактальное сжатие\n",
    "\n",
    "ФИО: Егор Александрович Чистов\n",
    "Группа: 204"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Баллы за задание складываются из двух частей: баллы за выполнение промежуточных подзаданий и баллы за качество**\n",
    "\n",
    "**Максимальное количество баллов за выполнение промежуточных подзаданий — 15**\n",
    "\n",
    "**Баллы за качество выставляются по итогам сравнения всех решений**\n",
    "\n",
    "## Правила сдачи\n",
    "* У каждого подзадания указано максимальное количество баллов, которые можно за него получить\n",
    "* Для сдачи необходимо в Google Classroom загрузить Jupyter-ноутбук с выполненными подзаданиями\n",
    "* В некоторых ячейках есть строки (`# GRADED CELL: [function name]`), эти строки **менять нельзя**, они будет использоваться при проверке вашего решения\n",
    "* Интерфейс функций и классов помеченных таким образом должен остаться без изменений\n",
    "* Ячейка со строкой (`# GRADED CELL: [function name]`) должна содержать только **одну функцию или класс**\n",
    " * Лайфхак: функции можно определять внутри функций\n",
    "* Никакие другие ячейки не будут использованы при проверке, они должны быть самодостаточны\n",
    "* Запрещено импортировать иные библиотеки и функции, кроме указанных в первой ячейке с кодом  \n",
    "(если сильно захочется что-то еще импортировать, спросите в чате курса)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Немного теории\n",
    "Алгоритм описан в главе про [сжатие изображений](https://compression.ru/book/part2/part2__3.htm#_Toc448152512).\n",
    "\n",
    "### Определения\n",
    "**Ранговый блок**: если исходное изображение разбивается на непересекающиеся блоки одинакового размера, замощающие всё изображение, то каждый такой блок называется *ранговым*; имеют меньший размер, чем доменные блоки.\n",
    "\n",
    "**Доменный блок**: если исходное изображение разбивается блоки одинакового размера, которые могут и пересекаться, то каждый такой блок называется *доменным*; имеют больший размер, чем ранговые блоки.\n",
    "\n",
    "**Идея алгоритма**:\n",
    "\n",
    "При сжатии:\n",
    "1. для каждого рангового блока найти наиболее похожий на него доменный блок (с учётом поворотов и симметрии)\n",
    "2. выполнить преобразование яркости\n",
    "3. в качестве сжатого изображения выступают коэффициенты преобразования ранговых блоков, эффективно записанные в файл (строку)\n",
    "\n",
    "При декомпрессии:\n",
    "1. Прочитать файл (строку), извлечь коэффициенты преобразований\n",
    "2. Применить преобразования к исходному изображению (обычно просто серое) пока результат не стабилизируется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python Library\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "# Additional Modules\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io\n",
    "from skimage import data, img_as_float64\n",
    "from skimage.metrics import mean_squared_error as mse, peak_signal_noise_ratio as psnr\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray, rgb2yuv, yuv2rgb\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первым делом нужно загрузить картинку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_rgb_512x512 = io.imread('test_files/lenna.bmp')\n",
    "lenna_rgb_256x256 = resize(lenna_rgb_512x512, (256, 256))\n",
    "lenna_gray_256x256 = np.rint(rgb2gray(lenna_rgb_256x256) * 255).astype('uint8')\n",
    "lenna_rgb_256x256 = np.rint(lenna_rgb_256x256 * 255).astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`plt` — модуль для рисования графиков и всего остального\n",
    "\n",
    "Очень удобная штука, будем пользоваться ей довольно часто"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(lenna_gray_256x256, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общие функции\n",
    "В следующих клетках описаны функции и классы, которые будут использоваться **вами** при выполнении следующих подзаданий. Стоит с ними подробно ознакомиться, понять, что они делают, и поэкспериментировать.\n",
    "\n",
    "**Не следует их менять.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BlockTransform = namedtuple('BlockTransform', ['x', 'y', 'co', 'di', 'tr', 'bad'])\n",
    "FractalCompressionParams = namedtuple(\n",
    "    'FractalCompressionParams', [\n",
    "        'height',\n",
    "        'width',\n",
    "        'is_colored',\n",
    "        'block_size',\n",
    "        'uv_block_size',\n",
    "        'spatial_scale',\n",
    "        'intensity_scale',\n",
    "        'stride'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_num_bits(length, stride):\n",
    "    return np.ceil(np.log2(length / stride)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_colored(image):\n",
    "    if len(image.shape) == 2:\n",
    "        return False\n",
    "    elif len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "        return True\n",
    "    else:\n",
    "        message = 'Invalid shape of the image: `{}`'\n",
    "        raise ValueError(message.format(image.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4 балла] Функция для нахождения наилучшего преобразования рангового блока\n",
    "\n",
    "#### Описание\n",
    "\n",
    "на входе функции подаются:\n",
    "* исходное Ч/Б изображение (`image`)\n",
    "* уменьшенное изображение (`resized_image`)\n",
    "* координаты рангового блока (`x`, `y`)\n",
    "* размер блока (`block_size`)\n",
    "* шаг, через сколько пикселей перескакивать при переборе (`stride`)\n",
    "\n",
    "на выходе функция должна выдавать:\n",
    "* лучшее преобразование в смысле MSE, объект типа `BlockTransform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CELL: find_block_transform\n",
    "\n",
    "BlockTransform = namedtuple('BlockTransform', ['x', 'y', 'co', 'di', 'tr', 'bad'])\n",
    "FractalCompressionParams = namedtuple(\n",
    "    'FractalCompressionParams', [\n",
    "        'height',\n",
    "        'width',\n",
    "        'is_colored',\n",
    "        'block_size',\n",
    "        'uv_block_size',\n",
    "        'spatial_scale',\n",
    "        'intensity_scale',\n",
    "        'stride'\n",
    "    ]\n",
    ")\n",
    "\n",
    "def find_block_transform(image, resized_image, x, y, block_size, stride):\n",
    "    '''Find best transformation for given rank block.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.array\n",
    "        Source B/W image.\n",
    "\n",
    "    resized_image : np.array\n",
    "        Resized source image.\n",
    "\n",
    "    x, y : int, int\n",
    "        Coordinates of the rank block.\n",
    "    \n",
    "    block_size : int\n",
    "        Size of rank block.\n",
    "\n",
    "    stride : int\n",
    "        Vertical and horizontal stride for domain block search.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_transform : BlockTransform\n",
    "        Best transformation.\n",
    "    '''\n",
    "    \n",
    "    def contrast_brightness(domain_block, rank_block):\n",
    "        '''Find constast and brightness to minimize: `mse(contrast * domain_block + brightness, rank_block)`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        domain_block, rank_block : np.array, np.array\n",
    "            Blocks of same size.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        contrast : float\n",
    "            Number in range [-1, 1]\n",
    "        brightness : np.int8\n",
    "            Number in range [-128, 127] \n",
    "        '''\n",
    "\n",
    "        # If these values are small, contrast --> 0 and appears artifacts `gray blocks`\n",
    "        # So if true, make contrast +-0.5\n",
    "        small = 20\n",
    "        d_sub = domain_block.max() - domain_block.min()\n",
    "        r_sub = rank_block.max() - rank_block.min()\n",
    "\n",
    "        # We can rewrite equation as `Ap = rank_block.flatten`, where `A = [[domain_block.flatten 1]]` and `p = [[constrast], [brightness]]`.\n",
    "        dbflat = domain_block.flatten()\n",
    "\n",
    "        #[ [domain_block[0][0] 1]\n",
    "        #  [domain_block[0][1] 1]\n",
    "        #  ...\n",
    "        #  [domain_block[n][n] 1] ]\n",
    "        A = np.vstack([dbflat, np.ones(len(dbflat))]).T\n",
    "\n",
    "        contrast, brightness = np.linalg.lstsq(A, rank_block.flatten(), rcond=None)[0]\n",
    "\n",
    "        if contrast < -1:\n",
    "            contrast = -1\n",
    "        elif d_sub < small and r_sub < small and -0.5 < contrast <= 0:\n",
    "            contrast = -0.5\n",
    "        elif d_sub < small and r_sub < small and 0 < contrast < 0.5:\n",
    "            contrast = 0.5\n",
    "        elif contrast > 1:\n",
    "            contrast = 1\n",
    "\n",
    "        if brightness < -128:\n",
    "            brightness = 128\n",
    "        elif brightness > 127:\n",
    "            brightness = 127\n",
    "        else:\n",
    "            brightness = np.rint(brightness).astype(np.int8)\n",
    "\n",
    "        return contrast, brightness\n",
    "\n",
    "    def find_flip_rotate(domain_block, rank_block, block_size):\n",
    "        '''Find flip and rotate through split blocks to 4 quadrants and compare they.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        domain_block, rank_block : np.array, np.array\n",
    "            Compared blocks\n",
    "\n",
    "        block_size : int\n",
    "            Size of rank block.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bad: bool\n",
    "            If blocks are not similar\n",
    "        flip: 0, 1\n",
    "            Number of flips.\n",
    "        rotate: 0, 1, 2, 3\n",
    "            Number of rotates.\n",
    "        '''\n",
    "\n",
    "        # Axes and quadrants\n",
    "        # 0 -------------> y\n",
    "        # | [[II,   I],\n",
    "        # |  [III, IV]]\n",
    "        # ↓\n",
    "        # x\n",
    "\n",
    "        I = np.s_[0 : block_size // 2, block_size // 2 : block_size]\n",
    "        II = np.s_[0 : block_size // 2, 0 : block_size // 2]\n",
    "        III = np.s_[block_size // 2 : block_size, 0 : block_size // 2]\n",
    "        IV = np.s_[block_size // 2 : block_size, block_size // 2 : block_size]\n",
    "        quadrants = [I, II, III, IV]\n",
    "\n",
    "        db_sums = {num + 1: domain_block[quadrant].sum() for num, quadrant in enumerate(quadrants)}\n",
    "        dbs = sorted(db_sums, key=db_sums.get)\n",
    "        rb_sums = {num + 1: rank_block[quadrant].sum() for num, quadrant in enumerate(quadrants)}\n",
    "        rbs = sorted(rb_sums, key=rb_sums.get)\n",
    "\n",
    "        match_1 = dbs[rbs.index(1)]  # Domain's block qudrant that corresponds to rank block first quadrant\n",
    "        match_2 = dbs[rbs.index(2)]  # Domain's block qudrant that corresponds to rank block second quadrant\n",
    "\n",
    "        _ = 0\n",
    "        nothing = (True, _, _)\n",
    "\n",
    "        presets = ((      nothing, (False, 0, 0),       nothing, (False, 1, 1)),\n",
    "                   ((False, 1, 0),       nothing, (False, 0, 1),       nothing),\n",
    "                   (      nothing, (False, 1, 3),       nothing, (False, 0, 2)),\n",
    "                   ((False, 0, 3),       nothing, (False, 1, 2),       nothing))\n",
    "\n",
    "        bad, flip, rotate = presets[match_1 - 1][match_2 - 1]\n",
    "\n",
    "        return bad, flip, rotate\n",
    "\n",
    "    def domain_blocks(resized_image, block_size, stride, rank_block):\n",
    "        '''Yield domain_block from resized_image.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        resized_image : np.array\n",
    "            Resized source image.\n",
    "\n",
    "        block_size : int\n",
    "            Size of rank block.\n",
    "\n",
    "        stride : int\n",
    "            Vertical and horizontal stride for domain block search.\n",
    "\n",
    "        rank_block : np.array\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x, y : int\n",
    "            Coordinates of domain_block\n",
    "        transform_code : int (3 bits)\n",
    "            Number of rotates and flips\n",
    "        transformed_block : np.array\n",
    "            Transformed domain_block\n",
    "        '''\n",
    "\n",
    "        for x in range(0, resized_image.shape[0] - block_size + 1, stride):\n",
    "            for y in range(0, resized_image.shape[1] - block_size + 1, stride):\n",
    "                domain_block = resized_image[x : x + block_size, y : y + block_size]\n",
    "                bad, flip, rotate = find_flip_rotate(domain_block, rank_block, block_size)\n",
    "                if bad:\n",
    "                    continue\n",
    "\n",
    "                transformed_block = domain_block\n",
    "                if (flip):\n",
    "                    transformed_block = np.flip(transformed_block, axis=1)\n",
    "                transformed_block = np.rot90(transformed_block, k=rotate)\n",
    "\n",
    "                yield x, y, (rotate << 1) + flip, transformed_block\n",
    "\n",
    "    best_transform = BlockTransform(0, 0, 1.0, 0, 0, True)\n",
    "    best_transform_err = float('inf')\n",
    "\n",
    "    rank_block = image[x : x + block_size,\n",
    "                       y : y + block_size]\n",
    "\n",
    "    for domain_x, domain_y, tr, domain_block in domain_blocks(resized_image, block_size, stride, rank_block):\n",
    "        contrast, brightness = contrast_brightness(domain_block, rank_block)\n",
    "\n",
    "        err = mse(contrast * domain_block + brightness, rank_block)\n",
    "        if err < best_transform_err:\n",
    "            best_transform = BlockTransform(domain_x, domain_y, contrast, brightness, tr, err >= 500)\n",
    "            best_transform_err = err\n",
    "\n",
    "    return best_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4 балла] Применение IFS к изображению\n",
    "\n",
    "#### Описание\n",
    "\n",
    "на входе функции подаются:\n",
    "* исходное изображение (`image`)\n",
    "* уменьшенное изображение (`resized_image`)\n",
    "* IFS, массив объектов типа `BlockTransform` (`transforms`)\n",
    "* размер блока (`block_size`)\n",
    "\n",
    "на выходе функция должна выдавать:\n",
    "* картинку после одинарного применения IFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CELL: perform_transform\n",
    "\n",
    "def perform_transform(image, resized_image, transforms, block_size):\n",
    "    '''Perform IFS on given image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.array\n",
    "        Source image.\n",
    "\n",
    "    resized_image : np.array\n",
    "        Resized source image.\n",
    "\n",
    "    transforms : list of BlockTransform's\n",
    "        Given IFS, Iterated Function System\n",
    "    \n",
    "    block_size : int\n",
    "        Size of rank block.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    transformed_image : np.array\n",
    "        Transformed image.\n",
    "    '''\n",
    "\n",
    "    def transforms_(image, block_size, transforms):\n",
    "        '''Yield transforms for image.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image : np.array\n",
    "            Resized source image.\n",
    "            \n",
    "        block_size : int\n",
    "            Size of rank block.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x, y : int\n",
    "            Coordinates of rank_block for transform\n",
    "\n",
    "        qtransform : list of BlockTransform's\n",
    "            List of all transforms for rank_block\n",
    "        '''\n",
    "\n",
    "        t_idx = 0\n",
    "\n",
    "        def get_transforms(block_size, transforms):\n",
    "            '''Recursively find transforms for current rank block.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            block_size : int\n",
    "                Size of rank block.\n",
    "            \n",
    "            transforms : list of BlockTransform's\n",
    "                Given IFS, Iterated Function System\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            qtransform : list of BlockTransform's\n",
    "                List of all transforms for rank_block\n",
    "            '''\n",
    "\n",
    "            nonlocal t_idx\n",
    "            qtransforms = [transforms[t_idx]]\n",
    "            t_idx += 1\n",
    "\n",
    "            if qtransforms[0].bad and block_size >= 4:\n",
    "                for i in range(4):\n",
    "                    qtransforms.extend(get_transforms(block_size // 2, transforms))\n",
    "\n",
    "            return qtransforms\n",
    "\n",
    "        xs = range(0, image.shape[0] - block_size + 1, block_size)\n",
    "        ys = range(0, image.shape[1] - block_size + 1, block_size)\n",
    "\n",
    "        for x in xs:\n",
    "            for y in ys:\n",
    "                yield x, y, get_transforms(block_size, transforms)\n",
    "\n",
    "    def apply_transforms(transformed_image, x, y, block_size, qtransforms):\n",
    "        '''Recursively apply transforms for current rank block.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            transformed_image : np.array\n",
    "                Image to apply transforms\n",
    "\n",
    "            x, y : int, int\n",
    "                Coordinates of rank_block\n",
    "\n",
    "            block_size : int\n",
    "                Size of rank block.\n",
    "\n",
    "            qtransform : list of BlockTransform's\n",
    "                List of all transforms for rank_block\n",
    "            '''\n",
    "\n",
    "        transform = qtransforms.pop(0)\n",
    "        if transform.bad:\n",
    "            apply_transforms(transformed_image, x, y, block_size // 2, qtransforms)\n",
    "            apply_transforms(transformed_image, x + block_size // 2, y, block_size // 2, qtransforms)\n",
    "            apply_transforms(transformed_image, x, y + block_size // 2, block_size // 2, qtransforms)\n",
    "            apply_transforms(transformed_image, x + block_size // 2, y + block_size // 2, block_size // 2, qtransforms)\n",
    "        else:\n",
    "            domain_block = resized_image[transform.x : transform.x + block_size,\n",
    "                                         transform.y : transform.y + block_size]\n",
    "\n",
    "            rot_times = transform.tr >> 1\n",
    "            flip = transform.tr & 1\n",
    "            if flip:\n",
    "                domain_block = np.flip(domain_block, axis=1)\n",
    "            domain_block = np.rot90(domain_block, k=rot_times)\n",
    "\n",
    "            transformed_image[x : x + block_size,\n",
    "                              y : y + block_size] = transform.co * domain_block + transform.di\n",
    "\n",
    "    transformed_image = np.zeros(image.shape)\n",
    "\n",
    "    for x, y, qtransforms in transforms_(image, block_size, transforms):\n",
    "        apply_transforms(transformed_image, x, y, block_size, qtransforms)\n",
    "\n",
    "    return transformed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [7 баллов] Класс, реализующий интерфейс битового массива\n",
    "Он понадобится для преобразования найденной IFS в строку, чтобы записать сжатый файл на диск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CELL: BitBuffer\n",
    "\n",
    "class BitBuffer:\n",
    "    '''Class that provides storing and and reading integer numbers \n",
    "    in continuous bytearray.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    buffer : bytearray, optional (default=None)\n",
    "        Input bytearray, for initialization.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    _pushed_bits : int\n",
    "        Count of pushed into last byte bits\n",
    "    _left_bits : int\n",
    "        Count of bits that can be popped from first byte\n",
    "    _bufcap : int\n",
    "        Max bits in byte\n",
    "    _buffer : bytearray\n",
    "        Bytearray that can contain any information.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> buffer = BitBuffer()\n",
    "    >>> buffer.push(1, 1)\n",
    "    >>> x = buffer.pop(1)\n",
    "    >>> print(x)\n",
    "    1\n",
    "    >>> buffer.push(125, 18)\n",
    "    >>> x = buffer.pop(18)\n",
    "    >>> print(x)\n",
    "    125\n",
    "    >>> buffer.push(5, 3)\n",
    "    >>> x = buffer.pop(3)\n",
    "    >>> print(x)\n",
    "    5\n",
    "\n",
    "    >>> dy = transform.y // stride\n",
    "    >>> buffer.push(dy, self._num_bits_ver)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, buffer=None):\n",
    "        self._pushed_bits = 0\n",
    "        self._left_bits = 8\n",
    "        self._bufcap = 8\n",
    "        self._buffer = buffer or bytearray(1)\n",
    "\n",
    "    def to_bytearray(self):\n",
    "        '''Convert to bytearray.\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        buffer: bytearray\n",
    "            Bytearray that contains all data.\n",
    "        '''\n",
    "\n",
    "        return self._buffer\n",
    "\n",
    "    def _push_bit(self, bit):\n",
    "        '''Push given bit to buffer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        bit: int\n",
    "            Input bit.\n",
    "        '''\n",
    "\n",
    "        if self._pushed_bits == self._bufcap:\n",
    "            self._buffer.append(0)\n",
    "            self._pushed_bits = 0\n",
    "        self._buffer[-1] |= bit << (self._bufcap - 1 - self._pushed_bits)\n",
    "        self._pushed_bits += 1\n",
    "\n",
    "    def _pop_bit(self):\n",
    "        '''Pop one bit from buffer.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bit: int\n",
    "            Popped bit.\n",
    "        '''\n",
    "\n",
    "        if not self._left_bits:\n",
    "            self._buffer.pop(0)\n",
    "            self._left_bits = self._bufcap\n",
    "        bit = (self._buffer[0] & 1 << (self._left_bits - 1)) >> (self._left_bits - 1)\n",
    "        self._left_bits -= 1\n",
    "\n",
    "        return bit\n",
    "\n",
    "    def push(self, x, n_bits):\n",
    "        '''Push given integer to buffer.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        x: int\n",
    "            Input number.\n",
    "\n",
    "        n_bits: int\n",
    "            Number of bits for store input number,\n",
    "            should be greater than log2(x).\n",
    "        '''\n",
    "\n",
    "        assert x < 2 ** n_bits\n",
    "\n",
    "        bits_left = n_bits\n",
    "\n",
    "        while bits_left:\n",
    "            bit = (x & (1 << (bits_left - 1))) >> (bits_left - 1)\n",
    "            self._push_bit(bit)\n",
    "            bits_left -= 1\n",
    "\n",
    "    def pop(self, n_bits):\n",
    "        '''Pop n_bits from buffer and transform it to a number.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_bits: int\n",
    "            Number of bits for pop from buffer.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x: int\n",
    "            Extracted number.\n",
    "        '''\n",
    "\n",
    "        bits_left = n_bits\n",
    "        x = 0\n",
    "\n",
    "        while bits_left:\n",
    "            x |= self._pop_bit() << (bits_left - 1)\n",
    "            bits_left -= 1\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Баллы за качество] Класс, реализующий интерфейс архиватора изображений\n",
    "\n",
    "#### Условие\n",
    "* Класс будет тестироваться как на черно-белых, так и на **цветных** изображениях\n",
    "* Для цветных изображений необходимо переходить в YUV, сжимать, а потом обратно в RGB для финального результата\n",
    "* В качестве оценки алгоритма будет использоваться кривая размер-качество, построенная на основе запуска метода compress2, с параметрами качества [0, 20, 40, 60, 80, 100]\n",
    "* Следует обеспечить непрерывную монотонную зависимость реального качества декодированного изображения от параметра качества\n",
    "* Баллы будут выставляться исходя из того, насколько построенный график размер-качество лежит близко к верхнему левому углу (высокое качество и низкий размер)\n",
    "* За красивые графики с равномерно распределенными узлами [0 ... 100] и без точек перегиба выставляются дополнительные баллы\n",
    "* Ограничение времени работы (суммарно сжатие и разжатие) на всех уровнях качества: 8 минут\n",
    "\n",
    "**Интерфейсом данного класса считаются только методы compress2 и decompress, остальные можно менять как угодно**`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CELL: FractalCompressor\n",
    " \n",
    "class FractalCompressor:\n",
    "    '''Class that performs fractal compression/decompression of images.\n",
    " \n",
    "    Attributes\n",
    "    ----------\n",
    "    _num_bits_ver : int\n",
    "        Number of bits for store VERTICAL OFFSET for each transformation.\n",
    "    \n",
    "    _num_bits_hor : int\n",
    "        Number of bits for store HORIZONTAL OFFSET for each transformation.\n",
    " \n",
    "    _num_bits_con : int\n",
    "        Number of bits for store INTENSITY SCALE for each transformation.\n",
    " \n",
    "    _num_bits_pix : int\n",
    "        Number of bits for store INTENSITY OFFSET for each transformation.\n",
    "        \n",
    "    _num_bits_tfm : int\n",
    "        Number of bits for store TRANFORMATION INDEX for each transformation.\n",
    " \n",
    "    _num_bits_bad : int\n",
    "        Number of bits for store flag of split into 4 block for each transformation.\n",
    " \n",
    "    Examples\n",
    "    --------\n",
    "    >>> comp = FractalCompressor()\n",
    "    >>> compressed_image = comp.compress(image, block_size=8, stride=2)\n",
    "    >>> decompressed_image = comp.decompress(compressed_image, num_iters=9)\n",
    "    >>> yet_another_compressed_image = comp.compress(image, 8, 4, 0.5, 0.7)\n",
    "    >>> yet_another_decompressed_image = comp.compress(yet_another_compressed_image, 5)\n",
    "    '''\n",
    " \n",
    "    def __init__(self):\n",
    "        self._num_bits_ver = 8\n",
    "        self._num_bits_hor = 8\n",
    "        self._num_bits_con = 8\n",
    "        self._num_bits_pix = 8\n",
    "        self._num_bits_tfm = 3\n",
    "        self._num_bits_bad = 1\n",
    " \n",
    "    def _float2int(self, f):\n",
    "        '''Convert float value from range [-1.0, 1.0] to uint8 value in range [0, 255]\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        f : float\n",
    "            Number to convert\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        u : np.uint8\n",
    "            Converted number\n",
    "        '''\n",
    " \n",
    "        assert -1 <= f <= 1, f\"{f} must be in [-1, 1]\"\n",
    " \n",
    "        return int((f + 1) * 127)\n",
    " \n",
    "    def _int2float(self, u):\n",
    "        '''Convert uint8 value from range [0, 255] to float value in range [-1, 1]\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        u : np.uint8\n",
    "            Number to convert\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        f : float\n",
    "            Converted number\n",
    "        '''\n",
    " \n",
    "        return u / 127 - 1\n",
    " \n",
    "    def _int2uint(self, i):\n",
    "        '''Convert int8 value from range [-128, 127] to uint8 value in range [0, 255]\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        i : np.int8\n",
    "            Number to convert\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        u : np.uint8\n",
    "            Converted number\n",
    "        '''\n",
    " \n",
    "        return i + 128\n",
    "    \n",
    "    def _uint2int(self, u):\n",
    "        '''Convert int8 value from range [0, 255] to uint8 value in range [-128, 127]\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        u : np.uint8\n",
    "            Number to convert\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        i : np.int8\n",
    "            Converted number\n",
    "        '''\n",
    " \n",
    "        return u - 128\n",
    " \n",
    "    def _add_header(self, buffer, params):\n",
    "        '''Store header in buffer.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        buffer: BitBuffer\n",
    "            \n",
    "        params: FractalCompressionParams\n",
    "            Parameters that should be stored in buffer.\n",
    " \n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `_read_header`.\n",
    "        '''\n",
    " \n",
    "        buffer.push(params.height, 9)\n",
    "        buffer.push(params.width, 9)\n",
    "        buffer.push(params.is_colored, 1)\n",
    "        buffer.push(params.block_size, 8)\n",
    "        buffer.push(params.uv_block_size, 8)\n",
    "        buffer.push(self._float2int(params.spatial_scale), 8)\n",
    "        buffer.push(self._float2int(params.intensity_scale), 8)\n",
    "        buffer.push(params.stride, 8)\n",
    " \n",
    "    def _read_header(self, buffer):\n",
    "        '''Read header from buffer.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        buffer: BitiBuffer\n",
    " \n",
    "        Returns\n",
    "        -------\n",
    "        params: FractalCompressionParams\n",
    "            Extracted parameters.\n",
    "            \n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `_add_header`.\n",
    "        '''\n",
    " \n",
    "        params = FractalCompressionParams(\n",
    "            height = buffer.pop(9),\n",
    "            width = buffer.pop(9),\n",
    "            is_colored = buffer.pop(1),\n",
    "            block_size = buffer.pop(8),\n",
    "            uv_block_size = buffer.pop(8),\n",
    "            spatial_scale = self._int2float(buffer.pop(8)),\n",
    "            intensity_scale = self._int2float(buffer.pop(8)),\n",
    "            stride = buffer.pop(8)\n",
    "        )\n",
    " \n",
    "        return params\n",
    " \n",
    "    def _add_to_buffer(self, buffer, transform, stride):\n",
    "        '''Store block transformation in buffer.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        buffer: BitBuffer\n",
    " \n",
    "        transform: BlockTransform\n",
    "            \n",
    "        stride: int\n",
    "            Vertical and horizontal stride for domain block search.\n",
    " \n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `_read_transform`.\n",
    "        '''\n",
    " \n",
    "        buffer.push(transform.bad, self._num_bits_bad)\n",
    "        if not transform.bad:\n",
    "            buffer.push(transform.x // stride, derive_num_bits(2 ** self._num_bits_ver, stride))\n",
    "            buffer.push(transform.y // stride, derive_num_bits(2 ** self._num_bits_hor, stride))\n",
    "            buffer.push(self._float2int(transform.co), self._num_bits_con)\n",
    "            buffer.push(self._int2uint(transform.di), self._num_bits_pix)\n",
    "            buffer.push(transform.tr, self._num_bits_tfm)\n",
    " \n",
    "    def _read_transform(self, buffer, stride):\n",
    "        '''Read block transformation from buffer.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        buffer: BitBuffer\n",
    " \n",
    "            \n",
    "        stride: int\n",
    "            Vertical and horizontal stride for domain block search.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        transform: BlockTransform\n",
    "            Extracted block transformation.\n",
    " \n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `_add_to_buffer`.\n",
    "        '''\n",
    " \n",
    "        bad = bool(buffer.pop(self._num_bits_bad))\n",
    " \n",
    "        if bad:\n",
    "            transform = BlockTransform(x=0, y=0, co=0.0, di=0, tr=0, bad=True)\n",
    "        else:\n",
    "            transform = BlockTransform(\n",
    "                x = buffer.pop(derive_num_bits(2 ** self._num_bits_ver, stride)) * stride,\n",
    "                y = buffer.pop(derive_num_bits(2 ** self._num_bits_hor, stride)) * stride,\n",
    "                co = self._int2float(buffer.pop(self._num_bits_con)),\n",
    "                di = self._uint2int(buffer.pop(self._num_bits_pix)),\n",
    "                tr = buffer.pop(self._num_bits_tfm),\n",
    "                bad = bad\n",
    "            )\n",
    " \n",
    "        return transform\n",
    "    \n",
    "    def _ifs2buf(self, params, transformations):\n",
    "        '''Store compression parameters and IFS in buffer.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        params: FractalCompressionParams\n",
    "            Parameters of the compression.\n",
    " \n",
    "        transformations: list of BlockTransform's\n",
    "            Given IFS.\n",
    " \n",
    "        Returns\n",
    "        -------\n",
    "        buffer: BitBuffer\n",
    " \n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `_buf2ifs`.\n",
    "        '''\n",
    "        \n",
    "        buffer = BitBuffer()\n",
    "        self._add_header(buffer, params)\n",
    "        for t in transformations:\n",
    "            self._add_to_buffer(buffer, t, params.stride)\n",
    " \n",
    "        return buffer\n",
    "    \n",
    "    def _buf2ifs(self, buffer):\n",
    "        '''Store compression parameters and IFS in buffer.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        buffer: BitBuffer\n",
    " \n",
    "        Returns\n",
    "        -------\n",
    "        params: FractalCompressionParams\n",
    "            Extracted compression parameters.\n",
    " \n",
    "        transforms, transforms_{u,y,v}: list of BlockTransform's\n",
    "            Extracted IFS.\n",
    " \n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `_ifs2buf`.\n",
    "        '''\n",
    " \n",
    "        def read_transform_for_block(buffer, block_size, stride):\n",
    "            '''Recursively get transforms for current rank block.\n",
    " \n",
    "            Parameters\n",
    "            ----------\n",
    "            buffer : BitBuffer\n",
    " \n",
    "            block_size : int\n",
    "                Size of rank block.\n",
    "            \n",
    "            stride : int\n",
    "                Vertical and horizontal stride for domain block search.\n",
    " \n",
    "            Returns\n",
    "            -------\n",
    "            qtransform : list of BlockTransform's\n",
    "                List of all transforms for rank_block\n",
    "            '''\n",
    " \n",
    "            qtransforms = [self._read_transform(buffer, stride)]\n",
    "            if qtransforms[0].bad and block_size >= 4:\n",
    "                for i in range(4):\n",
    "                    qtransforms.extend(read_transform_for_block(buffer, block_size // 2, stride))\n",
    "            return qtransforms\n",
    " \n",
    "        def read_transforms(buffer, num_transforms, block_size, stride):\n",
    "            '''Read transforms.\n",
    " \n",
    "            Parameters\n",
    "            ----------\n",
    "            buffer : BitBuffer\n",
    " \n",
    "            num_transforms : int\n",
    "                Number of transforms to read\n",
    " \n",
    "            block_size : int\n",
    "                Size of rank block.\n",
    "            \n",
    "            stride : int\n",
    "                Vertical and horizontal stride for domain block search.\n",
    " \n",
    "            Returns\n",
    "            -------\n",
    "            transforms : list of BlockTransform's\n",
    "                List of all transforms\n",
    "            '''\n",
    " \n",
    "            transforms = []\n",
    "            for _ in range(num_transforms):\n",
    "                transforms.extend(read_transform_for_block(buffer, block_size, stride))\n",
    " \n",
    "            return transforms\n",
    " \n",
    "        params = self._read_header(buffer)\n",
    " \n",
    "        num_transforms = int(params.height * params.width / params.block_size ** 2)\n",
    "        num_transforms_uv = int(params.height * params.width / params.uv_block_size ** 2)\n",
    " \n",
    "        if params.is_colored:\n",
    "            transforms_y = read_transforms(buffer, num_transforms, params.block_size, params.stride)\n",
    "            transforms_u = read_transforms(buffer, num_transforms_uv, params.uv_block_size, params.stride)\n",
    "            transforms_v = read_transforms(buffer, num_transforms_uv, params.uv_block_size, params.stride)\n",
    " \n",
    "            return params, transforms_y, transforms_u, transforms_v\n",
    "        else:\n",
    "            transforms = read_transforms(buffer, num_transforms, params.block_size, params.stride)\n",
    " \n",
    "            return params, transforms, None, None\n",
    "\n",
    "    @staticmethod\n",
    "    def _compress_block(image, resized_image, x, y, block_size, stride, block_size_limit):\n",
    "        '''Recursively find transforms for rank block.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image : np.array\n",
    "            Source image.\n",
    "\n",
    "        resized_image : np.array\n",
    "            Resized source image.\n",
    "\n",
    "        x, y : int, int\n",
    "            Coordinates of the rank block.\n",
    "\n",
    "        block_size : int\n",
    "            Size of rank block.\n",
    "\n",
    "        stride : int\n",
    "            Vertical and horizontal stride for domain block search.\n",
    "\n",
    "        block_size_limit : int\n",
    "            Min block_size to use\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        transforms : list of BlockTransform's\n",
    "            Transformations for rank block.\n",
    "        '''\n",
    "\n",
    "        transforms = [find_block_transform(\n",
    "            image, resized_image,\n",
    "            x, y, block_size, stride\n",
    "        )]\n",
    "        if transforms[0].bad:\n",
    "            if block_size > block_size_limit:\n",
    "                for x_, y_ in ((x, y), (x + block_size // 2, y), (x, y + block_size // 2), (x + block_size // 2, y + block_size // 2)):\n",
    "                    transforms.extend(FractalCompressor._compress_block(\n",
    "                        image, resized_image,\n",
    "                        x_, y_, block_size // 2, stride, block_size_limit\n",
    "                    ))\n",
    "            else:\n",
    "                transforms[0] = transforms[0]._replace(bad=False)\n",
    "\n",
    "        return transforms\n",
    "\n",
    "    @staticmethod\n",
    "    def _compress_one_component(image, block_size, stride, block_size_limit):\n",
    "        '''Compress one color component of input image\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        image : np.array\n",
    "            Source image.\n",
    "\n",
    "        block_size: int, optional (default=8)\n",
    "            Size of rank block.\n",
    " \n",
    "        stride: int, optional (default=1)\n",
    "            Vertical and horizontal stride for domain block search.\n",
    " \n",
    "        block_size_limit : int\n",
    "            Min block_size to use\n",
    " \n",
    "        Returns\n",
    "        -------\n",
    "        transformations : list of BlockTransform's\n",
    "            Transformations for color component.\n",
    "        '''\n",
    " \n",
    "        # Instead of reducing each domain block we will reduce the entire image\n",
    "        resized_image = resize(image, (image.shape[0] // 2, image.shape[1] // 2))\n",
    " \n",
    "        # Splitting source image into rank blocks\n",
    "        xs = range(0, image.shape[0] - block_size + 1, block_size)\n",
    "        ys = range(0, image.shape[1] - block_size + 1, block_size)\n",
    " \n",
    "        transformations = []\n",
    "        for x, y in tqdm(itertools.product(xs, ys), total=len(xs) * len(ys)):\n",
    "            transforms = FractalCompressor._compress_block(\n",
    "                image, resized_image,\n",
    "                x, y, block_size, stride, block_size_limit\n",
    "            )\n",
    "            transformations.extend(transforms)\n",
    " \n",
    "        return transformations\n",
    "\n",
    "    def compress(self, image, block_size=8, stride=4,\n",
    "                 spatial_scale=0.5, intensity_scale=0.75, block_size_limit=8, uv_block_size=64):\n",
    "        '''Compress input image\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        image : np.array\n",
    "            Source image.\n",
    " \n",
    "        block_size: int, optional (default=8)\n",
    "            Size of rank block.\n",
    " \n",
    "        stride: int, optional (default=1)\n",
    "            Vertical and horizontal stride for domain block search.\n",
    "        \n",
    "        spatial_scale : float, optional (default=0.5)\n",
    "            ({rank block size} / {domain block size}) ratio, must be <1.\n",
    "        \n",
    "        intensity_scale : float, optional (default=0.75)\n",
    "            Reduce coefficient for image intensity.\n",
    " \n",
    "        block_size_limit : int, optional (default=8)\n",
    "            Min block_size to use\n",
    " \n",
    "        Returns\n",
    "        -------\n",
    "        byte_array: bytearray\n",
    "            Compressed image.\n",
    "            \n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `decompress`.\n",
    "        '''\n",
    "\n",
    "        if not (image.dtype == np.uint8 and 0 <= image.min() and image.max() <= 255):\n",
    "            raise ValueError(f'Image values must be np.uint8 in 0..255, but {image.dtype} in {image.min()}..{image.max()} given.')\n",
    "\n",
    "        if (is_colored(image)):\n",
    "            y, u, v = np.split(rgb2yuv(image), [1,2], axis=2)\n",
    " \n",
    "            y8 = (y + 0.000) * 255\n",
    "            u8 = (u + 0.436) * 292\n",
    "            v8 = (v + 0.615) * 207\n",
    " \n",
    "            transformations = []\n",
    "            transformations.extend(self._compress_one_component(y8, block_size, stride, block_size_limit))\n",
    "            transformations.extend(self._compress_one_component(u8, uv_block_size, stride, uv_block_size))\n",
    "            transformations.extend(self._compress_one_component(v8, uv_block_size, stride, uv_block_size))\n",
    "        else:\n",
    "            image = image.astype(np.float)\n",
    "            transformations = self._compress_one_component(image, block_size, stride, block_size_limit)\n",
    " \n",
    "        params = FractalCompressionParams(\n",
    "            height = image.shape[0],\n",
    "            width = image.shape[1],\n",
    "            is_colored = is_colored(image),\n",
    "            block_size = block_size,\n",
    "            uv_block_size = uv_block_size,\n",
    "            spatial_scale = spatial_scale,\n",
    "            intensity_scale = intensity_scale,\n",
    "            stride = stride\n",
    "        )\n",
    " \n",
    "        buffer = self._ifs2buf(params, transformations)\n",
    "        return buffer.to_bytearray()\n",
    " \n",
    "    def compress2(self, image, quality=40):\n",
    "        '''Compress input image\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        image : np.array\n",
    "            Source image.\n",
    " \n",
    "        quality: int, optional (default=50)\n",
    "            Quality of image compression\n",
    " \n",
    "        Returns\n",
    "        -------\n",
    "        byte_array: bytearray\n",
    "            Compressed image.\n",
    "            \n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `decompress`.\n",
    "        '''\n",
    " \n",
    "        presets = {\n",
    "            0: {\n",
    "                \"block_size\": 16,\n",
    "                \"stride\": 2,\n",
    "                \"block_size_limit\": 16,\n",
    "                \"uv_block_size\": 64\n",
    "            },\n",
    "            20: {\n",
    "                \"block_size\": 16,\n",
    "                \"stride\": 3,\n",
    "                \"block_size_limit\": 8,\n",
    "                \"uv_block_size\": 64\n",
    "            },\n",
    "            40: {\n",
    "                \"block_size\": 16,\n",
    "                \"stride\": 4,\n",
    "                \"block_size_limit\": 4,\n",
    "                \"uv_block_size\": 32\n",
    "            },\n",
    "            60: {\n",
    "                \"block_size\": 8,\n",
    "                \"stride\": 4,\n",
    "                \"block_size_limit\": 4,\n",
    "                \"uv_block_size\": 32\n",
    "            },\n",
    "            80: {\n",
    "                \"block_size\": 8,\n",
    "                \"stride\": 4,\n",
    "                \"block_size_limit\": 4,\n",
    "                \"uv_block_size\": 16\n",
    "            },\n",
    "            100: {\n",
    "                \"block_size\": 8,\n",
    "                \"stride\": 3,\n",
    "                \"block_size_limit\": 4,\n",
    "                \"uv_block_size\": 16\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            preset = presets[quality]\n",
    "        except KeyError:\n",
    "            raise ValueError(f'quality must be in {tuple(presets.keys())}')\n",
    " \n",
    "        return self.compress(image, **preset)\n",
    " \n",
    "    def decompress(self, byte_array, num_iters=16):\n",
    "        '''Compress input image\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        byte_array: bytearray\n",
    "            Compressed image.\n",
    " \n",
    "        num_iters: int, optional (default=10)\n",
    "            Number of iterations to perform IFS.\n",
    " \n",
    "        Returns\n",
    "        -------\n",
    "        image: np.array\n",
    "            Decompressed image.\n",
    "            \n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `compress`.\n",
    "        '''\n",
    " \n",
    "        def decompress_one_component(params, transforms, num_iters):\n",
    "            '''Recursively apply transforms for rank block.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            params: FractalCompressionParams\n",
    "                Extracted compression parameters.\n",
    "\n",
    "            transforms : list of BlockTransform's\n",
    "                Given IFS, Iterated Function System\n",
    "\n",
    "            num_iters: int\n",
    "                Number of iterations to perform IFS.\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            image: np.array\n",
    "                Transformed image.\n",
    "\n",
    "            '''\n",
    "\n",
    "            image = np.zeros((params.height, params.width))\n",
    " \n",
    "            for _ in range(num_iters):\n",
    "                # Instead of reducing each domain block we will reduce the entire image\n",
    "                resized_image = resize(image, (image.shape[0] // 2, image.shape[1] // 2))\n",
    "                image = perform_transform(image, resized_image, transforms, params.block_size)\n",
    " \n",
    "            return image\n",
    " \n",
    "        buffer = BitBuffer(buffer=byte_array.copy())\n",
    "        params, transforms_y, transforms_u, transforms_v = self._buf2ifs(buffer)\n",
    " \n",
    "        if params.is_colored:\n",
    "            y8 = decompress_one_component(params, transforms_y, num_iters)\n",
    "            u8 = decompress_one_component(params._replace(block_size=params.uv_block_size), transforms_u, num_iters)\n",
    "            v8 = decompress_one_component(params._replace(block_size=params.uv_block_size), transforms_v, num_iters)\n",
    " \n",
    "            y = y8 / 255 - 0.000\n",
    "            u = u8 / 292 - 0.436\n",
    "            v = v8 / 207 - 0.615\n",
    "\n",
    "            rgb = yuv2rgb(np.dstack((y, u, v)))\n",
    "            rgb = np.rint(rgb * 255)\n",
    "            rgb[rgb < 0] = 0\n",
    "            rgb[rgb > 255] = 255\n",
    "            return rgb.astype(np.uint8)\n",
    "        else:\n",
    "            gray = decompress_one_component(params, transforms_y, num_iters)\n",
    "            gray[gray < 0] = 0\n",
    "            gray[gray > 255] = 255\n",
    "            return gray.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = FractalCompressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_psnr(ref, img):\n",
    "    assert ref.shape == img.shape, \"Shape mismatch\"\n",
    "    if is_colored(img):\n",
    "        ref_yuv = rgb2yuv(ref)\n",
    "        img_yuv = rgb2yuv(img)\n",
    "        \n",
    "        return (4 * psnr(ref_yuv[..., 0], img_yuv[..., 0]) +\n",
    "                    psnr(ref_yuv[..., 1], img_yuv[..., 1]) +\n",
    "                    psnr(ref_yuv[..., 2], img_yuv[..., 2])\n",
    "               ) / 6\n",
    "    else:\n",
    "        return psnr(ref, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пробуем применить FractalCompressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_gray = comp.compress2(lenna_gray_256x256, quality=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер сжатого изображения в байтах == длина полученного массива `bytearray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эволюция изображения при декомпрессии\n",
    "Выглядит как увеличение фотографии в CSI: Место прреступления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = [4, 8, 16]\n",
    "\n",
    "imgs = [comp.decompress(result_gray, n) for n in n_iters]\n",
    "_, axs = plt.subplots(ncols=len(imgs) + 1, figsize=(18, 6))\n",
    "for index in range(len(imgs)):\n",
    "    axs[index].imshow(imgs[index], cmap='gray')\n",
    "    axs[index].set_title(f'its: {n_iters[index]}, psnr: {round(psnr(imgs[index], lenna_gray_256x256), 2)}')\n",
    "axs[-1].imshow(lenna_gray_256x256, cmap='gray')\n",
    "axs[-1].set_title('orig')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YUV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, u, v = np.split(rgb2yuv(lenna_rgb_256x256), [1,2], axis=2)\n",
    "\n",
    "_, axs = plt.subplots(ncols=3, figsize=(18, 6))\n",
    "\n",
    "axs[0].imshow(y, cmap='gray')\n",
    "axs[0].set_title('Y')\n",
    "axs[1].imshow(u, cmap='gray')\n",
    "axs[1].set_title('U')\n",
    "axs[2].imshow(v, cmap='gray')\n",
    "axs[2].set_title('V')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Какие преобразования использует функция rgb2yuv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.zeros((1, 1, 3))\n",
    "z[:,:,0] = 1\n",
    "y = rgb2yuv(z)[0][0]\n",
    "z = np.zeros((1, 1, 3))\n",
    "z[:,:,1] = 1\n",
    "u = rgb2yuv(z)[0][0]\n",
    "z = np.zeros((1, 1, 3))\n",
    "z[:,:,2] = 1\n",
    "v = rgb2yuv(z)[0][0]\n",
    "np.vstack((y, u, v)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Какие максимум и минимум достижимы для каждого канала?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.zeros((1, 1, 3))\n",
    "y_min = rgb2yuv(z)[0][0][0]\n",
    "o = np.ones((1, 1, 3))\n",
    "y_max = rgb2yuv(o)[0][0][0]\n",
    "print(y_min, y_max)\n",
    "\n",
    "z = np.zeros((1, 1, 3))\n",
    "z[:,:,0:2] = 1\n",
    "u_min = rgb2yuv(z)[0][0][1]\n",
    "z = np.zeros((1, 1, 3))\n",
    "z[:,:,2] = 1\n",
    "u_max = rgb2yuv(z)[0][0][1]\n",
    "print(u_min, u_max)\n",
    "\n",
    "z = np.zeros((1, 1, 3))\n",
    "z[:,:,1:3] = 1\n",
    "v_min = rgb2yuv(z)[0][0][2]\n",
    "z = np.zeros((1, 1, 3))\n",
    "z[:,:,0] = 1\n",
    "v_max = rgb2yuv(z)[0][0][2]\n",
    "print(v_min, v_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Изобретая свой ~велосипед~ rgb2ycbcr\n",
    "\n",
    "Хочу сжимать изображение, представленное np.float `[0, 255]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, u, v = np.split(rgb2yuv(lenna_rgb_256x256), [1,2], axis=2)\n",
    "assert y_min <= y.min(), y.max() <= y_max\n",
    "assert u_min <= u.min(), u.max() <= u_max\n",
    "assert v_min <= v.min(), v.max() <= v_max\n",
    "\n",
    "y8 = (y + 0.000) * 255\n",
    "u8 = (u + 0.436) * 292\n",
    "v8 = (v + 0.615) * 207\n",
    "\n",
    "y = y8 / 255 - 0.000\n",
    "u = u8 / 292 - 0.436\n",
    "v = v8 / 207 - 0.615\n",
    "\n",
    "rgb = yuv2rgb(np.dstack((y, u, v)))\n",
    "\n",
    "print(rgb.min(), rgb.max())\n",
    "rgb[rgb < 0] = 0\n",
    "rgb[rgb > 1] = 1\n",
    "\n",
    "print(weighted_psnr(rgb, lenna_rgb_256x256))\n",
    "\n",
    "# print(weighted_psnr(ycbcr2rgb(rgb2ycbcr(lenna_rgb_256x256)), lenna_rgb_256x256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Эксперименты\n",
    "\n",
    "Что если получать U из Y, а V уменьшить в 4 раза?\n",
    "\n",
    "Получение U из Y оставляет желать лучшего на некоторых изображениях, а вот уменьшение V оказывает незначительное влияние.\n",
    "\n",
    "Сжимаем три канала по отдельности, выделяя больше места каналу Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(ncols=4, figsize=(18, 6))\n",
    "\n",
    "y, u, v = np.split(rgb2yuv(lenna_rgb_256x256), [1,2], axis=2)\n",
    "\n",
    "axs[0].imshow(lenna_rgb_256x256)\n",
    "axs[0].set_title('RGB')\n",
    "axs[1].imshow(u, cmap='gray')\n",
    "axs[1].set_title('U')\n",
    "\n",
    "v = resize(v, (v.shape[0] // 4, v.shape[1] // 4))\n",
    "\n",
    "y8 = (y + 0.000) * 255\n",
    "u8 = (u + 0.436) * 292\n",
    "v8 = (v + 0.615) * 207\n",
    "\n",
    "tr = find_block_transform(u8, y8, 0, 0, y8.shape[0], 1)\n",
    "contrast_u8, brightness_u8 = tr.co, tr.di\n",
    "\n",
    "u8_from_y8 = contrast_u8 * y8 + brightness_u8\n",
    "\n",
    "y = y8 / 255 - 0.000\n",
    "u_from_y = u8_from_y8 / 292 - 0.436\n",
    "v = v8 / 207 - 0.615\n",
    "\n",
    "v = resize(v, (v.shape[0] * 4, v.shape[1] * 4))\n",
    "\n",
    "axs[2].imshow(u_from_y, cmap='gray')\n",
    "axs[2].set_title(f'U from Y, psnr: {round(psnr(u, u_from_y), 2)}')\n",
    "\n",
    "rgb = yuv2rgb(np.dstack((y, u_from_y, v)))\n",
    "rgb[rgb < 0] = 0\n",
    "rgb[rgb > 1] = 1\n",
    "\n",
    "axs[3].imshow(rgb, cmap='gray')\n",
    "axs[3].set_title(f'result, psnr: {round(weighted_psnr(rgb, lenna_rgb_256x256), 2)}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Цветное изображение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rgb = comp.compress2(lenna_rgb_256x256, quality=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = [4, 8, 16]\n",
    "\n",
    "imgs = [comp.decompress(result_rgb, n) for n in n_iters]\n",
    "_, axs = plt.subplots(ncols=len(imgs) + 1, figsize=(18, 6))\n",
    "for index in range(len(imgs)):\n",
    "    axs[index].imshow(imgs[index])\n",
    "    axs[index].set_title(f'its: {n_iters[index]}, psnr: {round(weighted_psnr(lenna_rgb_256x256, imgs[index]), 2)}')\n",
    "axs[-1].imshow(lenna_rgb_256x256, cmap='gray')\n",
    "axs[-1].set_title('orig')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построим график качества\n",
    "Качество в данном случае будет измеряться по PSNR (а значит в децибелах).\n",
    "\n",
    "Это базовый график для понимания соотношения между коэффициентом сжатия и качеством, получаемым на выходе. Можно посмотреть, как он будет меняться в зависимости от количества итераций при декомпрессии, например."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality = [0, 20, 40, 60, 80, 100]\n",
    "\n",
    "def test_image(img):\n",
    "    compressed_images = [comp.compress2(img, quality=q) for q in quality]\n",
    "    decompressed_images = [comp.decompress(compressed) for compressed in compressed_images]\n",
    "    compression_rates = np.array([len(compressed) for compressed in compressed_images]) / img.size\n",
    "    psnrs = [weighted_psnr(img, decompressed) for decompressed in decompressed_images]\n",
    "    return compression_rates, psnrs, decompressed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_collection(collection):\n",
    "    results = []\n",
    "    for image, name in collection:\n",
    "        results.append((test_image(image), name))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results):\n",
    "    _, ax = plt.subplots(figsize=(18, 6))\n",
    " \n",
    "    for result, name in results:\n",
    "        compression_rates, psnrs, _ = result\n",
    "        ax.plot(compression_rates, psnrs, marker='o', ms=10, ls='-.', label=name)\n",
    " \n",
    "    ax.set_xlabel('Compression Rate', fontsize=16)\n",
    "    ax.set_ylabel('PSNR, dB', fontsize=16)\n",
    " \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(results):\n",
    "    _, axs = plt.subplots(nrows=len(results), ncols=len(quality), figsize=(18, 100), squeeze=False)\n",
    "\n",
    "    for j, res in enumerate(results):\n",
    "        result, name = res\n",
    "        compression_rates, psnrs, decompressed_images = result\n",
    "        for i, image in enumerate(decompressed_images):\n",
    "            if 'gray' in name:\n",
    "                axs[j][i].imshow(image, cmap='gray')\n",
    "                orig_size = 256 * 256\n",
    "            else:\n",
    "                axs[j][i].imshow(image)\n",
    "                orig_size = 256 * 256 * 3\n",
    "            axs[j][i].set_title(f'psnr: {round(psnrs[i], 2)}, size: {compression_rates[i] * orig_size}')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = []\n",
    "for image_name in os.listdir('test_files'):\n",
    "    image = resize(io.imread(os.path.join('test_files', image_name)), (256, 256))\n",
    "    if is_colored(image):\n",
    "        image_rgb = np.rint(image * 255).astype('uint8')\n",
    "        collection.append((image_rgb, image_name.split('.')[0] + '_rgb'))\n",
    "    image_gray = np.rint(rgb2gray(image) * 255).astype('uint8')\n",
    "    collection.append((image_gray, image_name.split('.')[0] + '_gray'))\n",
    "\n",
    "for image, name in collection:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_collection(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Улучшим алгоритм\n",
    "Одним из основных способов улучшения сжатия изображений является разбиение картинки не на равные блоки, а на блоки разных размеров. Как дополнительную часть задания, мы предлагаем реализовать разбиение квадродеревом, это позволит более гибко настраивать параметры сжатия и получить лучшие результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Пример разбиения изображения на блоки с использованием квадродерева</center>\n",
    "\n",
    "Исходное изображение | Разбиение квадродеревом\n",
    "- | -\n",
    "![Source image](images/house.jpg) | ![Segmentation](images/quadtree.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Базовые тесты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM_UNIT_TESTS = (((np.array([[1, 2], \n",
    "                                    [3, 4]]),\n",
    "                         np.array([[4, 6], \n",
    "                                   [8, 10]]),\n",
    "                         0, 0, 2, 1), \n",
    "                        1.5),\n",
    "                       ((np.array([[1, 2], \n",
    "                                   [3, 4]]),\n",
    "                         np.array([[4, 6, 7, 6], \n",
    "                                   [6, 7, 5, 4]]),\n",
    "                         0, 0, 2, 1), \n",
    "                        0),\n",
    "                       ((np.array([[1, 2], \n",
    "                                   [3, 4]]),\n",
    "                         np.array([[4, 8, 6, 8], \n",
    "                                   [6, 7, 5, 8]]),\n",
    "                         0, 0, 2, 1), \n",
    "                        0),\n",
    "                       ((np.array([[1, 2], \n",
    "                                   [3, 4]]),\n",
    "                         np.array([[4, 2, 3, 6], \n",
    "                                   [6, 4, 5, 5]]),\n",
    "                         0, 0, 2, 2),\n",
    "                        0.5))\n",
    "    \n",
    "    \n",
    "def test_transform():\n",
    "    for test, answer in TRANSFORM_UNIT_TESTS:\n",
    "        transform = find_block_transform(*test)\n",
    "        img, resized_img, x, y, block_size, stride = test\n",
    "        transformed = perform_transform(np.zeros_like(img), resized_img, [transform], block_size)\n",
    "        loss = mse(img, transformed)\n",
    "        if loss > answer + 1e-5:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_bit_buffer():\n",
    "    def fill():\n",
    "        bb = BitBuffer()\n",
    "        bb.push(15, 6)\n",
    "        bb.push(0, 7)\n",
    "        bb.push(1, 1)\n",
    "        bb.push(100, 400)\n",
    "        answer = [100, 1, 0, 15]\n",
    "        return bb, answer\n",
    "\n",
    "    bb, answer = fill()\n",
    "    res1 = []\n",
    "    res1.append(bb.pop(400))\n",
    "    res1.append(bb.pop(1))\n",
    "    res1.append(bb.pop(7))\n",
    "    res1.append(bb.pop(6))\n",
    "    if res1 == answer:\n",
    "        return True\n",
    "    bb, answer = fill()\n",
    "    res2 = []\n",
    "    res2.append(bb.pop(6))\n",
    "    res2.append(bb.pop(7))\n",
    "    res2.append(bb.pop(1))\n",
    "    res2.append(bb.pop(400))\n",
    "    if res2 == answer[::-1]:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_bit_buffer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преодолевая разные штуки\n",
    "\n",
    "- [x] Уменьшение изображения занимает слишком много времени\n",
    "- [x] Плохо подбираются преобразования по констрасту / яркости\n",
    "- [x] Артефакты для цветных изображений\n",
    "- [x] BitBuffer не оптимизирован для квадродерева\n",
    "- [x] find_block_transform не проходит тесты\n",
    "- [x] Квадродерево слишком много делится при использовании маленького качества\n",
    "- [x] Итоговая кривая размер-качество не выглядит хорошо\n",
    "- [x] Проверка всех восьми возможных трансформаций требует в восемь раз больше времени\n",
    "- [x] Цветные изображения весят слишком много\n",
    "- [x] Серые артефакты для блоков с малым изменением яркости (из-за подобранного контраста, стремящегося к нулю)\n",
    "- [x] Зеленые артефакты при малом размере блоков для U и V\n",
    "- [ ] tqdm показывает прогресс-бар для каждой компоненты\n",
    "- [ ] Все-равно сжимается долго\n",
    "- [ ] Хочу вместо прогресс-бара видеть в реальном времени, откуда берутся блоки\n",
    "- [ ] А что если не перебирать все доменные блоки?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fractal_task",
   "language": "python",
   "name": "fractal_task"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
