{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Фрактальное сжатие\n",
    "\n",
    "## Немного теории\n",
    "Алгоритм описан в главе про [сжатие изображений](https://compression.ru/book/part2/part2__3.htm#_Toc448152512).\n",
    "\n",
    "### Определения\n",
    "**Ранговый блок**: если исходное изображение разбивается на непересекающиеся блоки одинакового размера, замощающие всё\n",
    "изображение, то каждый такой блок называется *ранговым*; имеют меньший размер, чем доменные блоки.\n",
    "\n",
    "**Доменный блок**: если исходное изображение разбивается блоки одинакового размера, которые могут и пересекаться, то\n",
    "каждый такой блок называется *доменным*; имеют больший размер, чем ранговые блоки.\n",
    "\n",
    "**Идея алгоритма**:\n",
    "\n",
    "При сжатии:\n",
    "1. для каждого рангового блока найти наиболее похожий на него доменный блок (с учётом поворотов и симметрии)\n",
    "2. выполнить преобразование яркости\n",
    "3. в качестве сжатого изображения выступают коэффициенты преобразования ранговых блоков, эффективно записанные в файл\n",
    "(строку)\n",
    "\n",
    "При декомпрессии:\n",
    "1. Прочитать файл (строку), извлечь коэффициенты преобразований\n",
    "2. Применить преобразования к исходному изображению (обычно просто серое) пока результат не стабилизируется"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import itertools\n",
    "import time\n",
    "from collections import deque\n",
    "from typing import NamedTuple\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.patches import Rectangle\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray, rgb2ycbcr, rgb2yuv, ycbcr2rgb, yuv2rgb\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первым делом нужно загрузить картинку"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "lenna_rgb_256x256 = resize(io.imread(\"test_files/lenna.bmp\"), (256, 256))\n",
    "lenna_gray_256x256 = np.rint(rgb2gray(lenna_rgb_256x256) * 255).astype(np.uint8)\n",
    "lenna_rgb_256x256 = np.rint(lenna_rgb_256x256 * 255).astype(np.uint8)\n",
    "\n",
    "plt.imshow(lenna_rgb_256x256)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общие функции\n",
    "Функции и классы, используемые при написании алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "class BlockTransform(NamedTuple):\n",
    "    x: int\n",
    "    y: int\n",
    "    intensity_offset: int\n",
    "    flip: bool\n",
    "    rotates: int\n",
    "    bad: int\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class FractalCompressionParams(NamedTuple):\n",
    "    height: int\n",
    "    width: int\n",
    "    is_colored: bool\n",
    "    block_size: int\n",
    "    uv_block_size: int\n",
    "    spatial_scale: float\n",
    "    intensity_scale: float\n",
    "    stride: int\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def derive_num_bits(length, stride):\n",
    "    return np.ceil(np.log2(length / stride)).astype(int)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def is_colored(image):\n",
    "    if len(image.shape) == 2:\n",
    "        return False\n",
    "    elif len(image.shape) == 3 and image.shape[-1] == 3:\n",
    "        return True\n",
    "    else:\n",
    "        message = \"Invalid shape of the image: `{}`\"\n",
    "        raise ValueError(message.format(image.shape))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для нахождения наилучшего преобразования рангового блока"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как искать повороты и отражения?\n",
    "\n",
    "Простейший способ -- перепробовать все комбинации и найти лучшую.\n",
    "\n",
    "В качестве улучшения можно разбить ранговый и доменные блоки на четыре части, отсортировать их по яркости и по взаимному\n",
    "положению блоков определить нужную трансформацию.\n",
    "\n",
    "Такое решение повышает скорость примерно в 6 раз при потере в качестве около 0.4 PSNR"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class FR(NamedTuple):\n",
    "    flip: bool\n",
    "    rotates: int\n",
    "\n",
    "\n",
    "def find_flip_rotate(domain_block, rank_block, block_size):\n",
    "    \"\"\"Find flip and rotate through split blocks to 4 quadrants and compare they.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    domain_block, rank_block : np.array, np.array\n",
    "        Compared blocks\n",
    "\n",
    "    block_size : int\n",
    "        Size of rank block.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fr : FR\n",
    "        Transformations parameters: flip and rotates\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    xs = range(0, block_size, block_size // 2)\n",
    "    ys = range(0, block_size, block_size // 2)\n",
    "\n",
    "    quadrants = tuple(\n",
    "        np.s_[x : x + block_size // 2, y : y + block_size // 2]\n",
    "        for x, y in itertools.product(xs, ys)\n",
    "    )\n",
    "\n",
    "    presets = [\n",
    "        [None, FR(flip=False, rotates=0), None, FR(flip=True, rotates=1)],\n",
    "        [FR(flip=True, rotates=0), None, FR(flip=False, rotates=1), None],\n",
    "        [None, FR(flip=True, rotates=3), None, FR(flip=False, rotates=2)],\n",
    "        [FR(flip=False, rotates=3), None, FR(flip=True, rotates=2), None],\n",
    "    ]\n",
    "\n",
    "    db_sums = {\n",
    "        num + 1: domain_block[quadrant].sum() for num, quadrant in enumerate(quadrants)\n",
    "    }\n",
    "\n",
    "    dbs = sorted(db_sums, key=db_sums.get)\n",
    "\n",
    "    rb_sums = {\n",
    "        num + 1: rank_block[quadrant].sum() for num, quadrant in enumerate(quadrants)\n",
    "    }\n",
    "\n",
    "    rbs = sorted(rb_sums, key=rb_sums.get)\n",
    "\n",
    "    match_1 = dbs[rbs.index(1)] - 1\n",
    "    match_2 = dbs[rbs.index(2)] - 1\n",
    "\n",
    "    return presets[match_1][match_2]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как искать intensity_scale и intensity_offset?\n",
    "\n",
    "Решим задачу\n",
    "$$\n",
    "min_{a, b} E - ?\\\\\n",
    "$$\n",
    "\n",
    "где \n",
    "\n",
    "$$\n",
    "E(a, b) = \\sum_{i=1}^n \\sum_{j=1}^n (R_{ij} - (a D_{ij} + b))^2\\\\\n",
    "$$\n",
    "\n",
    "а $a$ - intensity scale, $b$ - intensity offset, $R_{ij}$, $D_{ij}$ - ранговые и доменные блоки соответственно.\n",
    "\n",
    "Найдем частные производные по $a$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial a} = \\sum_{i=1}^n \\sum_{j=1}^n 2 (R_{ij} - (a D_{ij} + b)) (-D_{ij}) = 2 \\sum_{i=1}^n \\sum_{j=1}^n (a D_{ij}^2 + b D_{ij} - R_{ij} D_{ij})\\\\\n",
    "$$\n",
    "\n",
    "и по $b$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial b} = \\sum_{i=1}^n \\sum_{j=1}^n 2 (R_{ij} - (a D_{ij} + b)) (-1) = 2 \\sum_{i=1}^n \\sum_{j=1}^n (a D_{ij} + b - R_{ij})\\\\\n",
    "$$\n",
    "\n",
    "На практике вычисляемый $a$ не дает больших преимуществ по качеству (+0.3 PSNR), но немного проигрывает по времени и значительно по размеру сжатого изображения. Будем оптимизировать только $b$.\n",
    "\n",
    "Ищем экстремум, приравнивая функцию к нулю.\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^n \\sum_{j=1}^n (a D_{ij} + b - R_{ij}) = 0\\\\\n",
    "$$\n",
    "\n",
    "Раскрываем скобки и переносим слагаемые, содержащие $b$, в одну сторону.\n",
    "\n",
    "$$\n",
    "n^2 b = \\sum_{i=1}^n \\sum_{j=1}^n R_{ij} - a \\sum_{i=1}^n \\sum_{j=1}^n D_{ij}\\\\\n",
    "$$\n",
    "\n",
    "Мы получили формулу для коэффициента $b$\n",
    "\n",
    "$$\n",
    "b = mean(R - a D)\\\\\n",
    "$$\n",
    "\n",
    "Перебором приходим к оптимальному $a=0.75$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def find_block_transform(\n",
    "    image, resized_image, x, y, block_size, stride, intensity_scale=0.75, loss_limit=256\n",
    "):\n",
    "    \"\"\"Find best transformation for given rank block.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.array\n",
    "        Source B/W image.\n",
    "\n",
    "    resized_image : np.array\n",
    "        Resized source image.\n",
    "\n",
    "    x, y : int, int\n",
    "        Coordinates of the rank block.\n",
    "\n",
    "    block_size : int\n",
    "        Size of rank block.\n",
    "\n",
    "    stride : int\n",
    "        Vertical and horizontal stride for domain block search.\n",
    "\n",
    "    intensity_scale : float, optional (default=0.75)\n",
    "        Reduce coefficient for image intensity.\n",
    "\n",
    "    loss_limit : int, optional (default=512)\n",
    "        Error limit for founded block in terms of MSE\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_transform : BlockTransform\n",
    "        Best transformation.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    best_transform = BlockTransform(\n",
    "        x=0, y=0, intensity_offset=0, flip=False, rotates=0, bad=True\n",
    "    )\n",
    "    best_transform_loss = float(\"inf\")\n",
    "\n",
    "    rank_block = image[x : x + block_size, y : y + block_size]\n",
    "\n",
    "    xs = range(0, resized_image.shape[0] - block_size + 1, stride)\n",
    "    ys = range(0, resized_image.shape[1] - block_size + 1, stride)\n",
    "\n",
    "    for domain_x, domain_y in itertools.product(xs, ys):\n",
    "        domain_block = resized_image[\n",
    "            domain_x : domain_x + block_size, domain_y : domain_y + block_size\n",
    "        ]\n",
    "\n",
    "        fr = find_flip_rotate(domain_block, rank_block, block_size)\n",
    "\n",
    "        if fr is None:\n",
    "            continue\n",
    "\n",
    "        if fr.flip:\n",
    "            domain_block = np.flip(domain_block, axis=1)\n",
    "\n",
    "        domain_block = np.rot90(domain_block, k=fr.rotates)\n",
    "\n",
    "        intensity_offset = int(\n",
    "            np.mean(rank_block - intensity_scale * domain_block).astype(np.int8)\n",
    "        )  # See explanations above\n",
    "\n",
    "        loss = mse(intensity_scale * domain_block + intensity_offset, rank_block)\n",
    "        if loss < best_transform_loss:\n",
    "            best_transform = BlockTransform(\n",
    "                x=domain_x,\n",
    "                y=domain_y,\n",
    "                intensity_offset=intensity_offset,\n",
    "                flip=fr.flip,\n",
    "                rotates=fr.rotates,\n",
    "                bad=loss >= loss_limit,\n",
    "            )\n",
    "            best_transform_loss = loss\n",
    "\n",
    "            if not best_transform.bad:\n",
    "                break\n",
    "\n",
    "    return best_transform\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Лучшее -- враг хорошего\n",
    "\n",
    "Идея остановки поиска при достижении заданной похожести блоков ускоряет алгоритм на порядок. Но возникает проблема: \n",
    "большая часть блоков берется из левого верхнего угла (смотри визуализацию ниже). Для устранения проблемы можно \n",
    "попробовать модифицировать перебор (например перебирать по спирали от стартового блока к краям). Но кажется, что это не \n",
    "проблема, а особенность алгоритма. По крайней мере, при полном переборе алгоритм ведет себя похоже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Посмотрим, где мы находим блоки"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def find_simple_transforms(image, block_size, stride):\n",
    "    \"\"\"Find simple (not use quadtree) transformations for given image.\n",
    "\n",
    "    Use this function for visualization.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.array\n",
    "        Source B/W image.\n",
    "\n",
    "    block_size : int\n",
    "        Size of rank block.\n",
    "\n",
    "    stride : int\n",
    "        Vertical and horizontal stride for domain block search.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    transforms : array of tuples (x, y, BlockTransform)\n",
    "        x, y are coordinates of rank block for which we find transform\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    image = image.astype(np.double)\n",
    "    resized_image = resize(image, (image.shape[0] // 2, image.shape[1] // 2))\n",
    "\n",
    "    # Splitting source image into rank blocks\n",
    "    xs = range(0, image.shape[0], block_size)\n",
    "    ys = range(0, image.shape[1], block_size)\n",
    "\n",
    "    transforms = []\n",
    "    for x, y in tqdm(itertools.product(xs, ys), total=len(xs) * len(ys)):\n",
    "        transform = find_block_transform(image, resized_image, x, y, block_size, stride)\n",
    "        transforms.append((x, y, transform))\n",
    "\n",
    "    return transforms\n",
    "\n",
    "\n",
    "simple_transforms = find_simple_transforms(lenna_gray_256x256, block_size=16, stride=4)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def save_transforms(image, transforms, block_size):\n",
    "    \"\"\"Save each transform on image as mp4 video.\n",
    "\n",
    "    Rank block is red, domain block is green. If transform is bad then blocks have face color.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.array\n",
    "        Source B/W image.\n",
    "\n",
    "    transforms : array of tuples (x, y, BlockTransform)\n",
    "        x, y are coordinates of rank block for which we find transform\n",
    "\n",
    "    block_size : int\n",
    "        Size of rank block.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def animate(index):\n",
    "        x, y, transform = transforms[index]\n",
    "        plt.clf()\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "        plt.gca().add_patch(\n",
    "            Rectangle(\n",
    "                (x, y),\n",
    "                block_size,\n",
    "                block_size,\n",
    "                linewidth=1,\n",
    "                edgecolor=\"r\",\n",
    "                facecolor=\"r\" if transform.bad else \"none\",\n",
    "            )\n",
    "        )\n",
    "        plt.gca().add_patch(\n",
    "            Rectangle(\n",
    "                (transform.x, transform.y),\n",
    "                block_size * 2,\n",
    "                block_size * 2,\n",
    "                linewidth=2,\n",
    "                edgecolor=\"g\",\n",
    "                facecolor=\"g\" if transform.bad else \"none\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    ani = matplotlib.animation.FuncAnimation(\n",
    "        plt.figure(), animate, frames=len(transforms)\n",
    "    )\n",
    "\n",
    "    ani.save(\"images/simple_transforms.mp4\")\n",
    "\n",
    "\n",
    "save_transforms(lenna_gray_256x256, simple_transforms, block_size=16)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Simple transforms](images/simple_transforms.gif)](images/simple_transforms.mp4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Где мы нашли недостаточно хорошие блоки?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def show_bad_blocks(image, transforms, block_size):\n",
    "    \"\"\"Show bad block for given image. Red blocks are bad.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.array\n",
    "        Source B/W image.\n",
    "\n",
    "    transforms : array of tuples (x, y, BlockTransform)\n",
    "        x, y are coordinates of rank block for which we find transform\n",
    "\n",
    "    block_size : int\n",
    "        Size of rank block.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Splitting source image into rank blocks\n",
    "    xs = range(0, image.shape[0], block_size)\n",
    "    ys = range(0, image.shape[1], block_size)\n",
    "\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    for (\n",
    "        x,\n",
    "        y,\n",
    "        transform,\n",
    "    ) in transforms:\n",
    "        plt.gca().add_patch(\n",
    "            Rectangle(\n",
    "                (x, y),\n",
    "                block_size,\n",
    "                block_size,\n",
    "                linewidth=1,\n",
    "                edgecolor=\"none\",\n",
    "                facecolor=\"r\" if transform.bad else \"none\",\n",
    "            )\n",
    "        )\n",
    "    plt.show()\n",
    "\n",
    "    print(\n",
    "        \"Доля плохих блоков:\",\n",
    "        sum(transform.bad for _, _, transform in transforms) / (len(xs) * len(ys)),\n",
    "    )\n",
    "\n",
    "\n",
    "show_bad_blocks(lenna_gray_256x256, simple_transforms, block_size=16)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение IFS к изображению"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_transforms_for_current_block(transforms):\n",
    "    \"\"\"Recursively find transforms for one rank block.\n",
    "\n",
    "    If transform is bad then there are 4 more transforms for this rank block.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    transforms : list of BlockTransform's\n",
    "        Given IFS, Iterated Function System\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    block_transforms : deque of BlockTransform's\n",
    "        Deque of all transforms for one rank_block\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    t = transforms.popleft()\n",
    "    block_transforms = [t]\n",
    "\n",
    "    if t.bad:\n",
    "        for _ in range(4):  # Quadtree\n",
    "            block_transforms.extend(get_transforms_for_current_block(transforms))\n",
    "\n",
    "    return deque(block_transforms)\n",
    "\n",
    "\n",
    "def apply_transforms(\n",
    "    transformed_image,\n",
    "    resized_image,\n",
    "    x,\n",
    "    y,\n",
    "    block_size,\n",
    "    block_transforms,\n",
    "    intensity_scale,\n",
    "):\n",
    "    \"\"\"Recursively apply transforms for current rank block.\n",
    "\n",
    "    If transform is bad then there are 4 more transforms for this rank block.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    transformed_image : np.array\n",
    "        Image to apply transforms\n",
    "\n",
    "    resized_image : np.array\n",
    "        Resized source image.\n",
    "\n",
    "    x, y : int, int\n",
    "        Coordinates of rank_block\n",
    "\n",
    "    block_size : int\n",
    "        Size of rank block.\n",
    "\n",
    "    block_transforms : list of BlockTransform's\n",
    "        List of all transforms for current rank_block\n",
    "\n",
    "    intensity_scale : float\n",
    "        Reduce coefficient for image intensity.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    transform = block_transforms.popleft()\n",
    "    if transform.bad:\n",
    "        xs = range(x, x + block_size, block_size // 2)\n",
    "        ys = range(y, y + block_size, block_size // 2)\n",
    "\n",
    "        for x_, y_ in itertools.product(xs, ys):\n",
    "            apply_transforms(\n",
    "                transformed_image,\n",
    "                resized_image,\n",
    "                x_,\n",
    "                y_,\n",
    "                block_size // 2,\n",
    "                block_transforms,\n",
    "                intensity_scale,\n",
    "            )\n",
    "    else:\n",
    "        domain_block = resized_image[\n",
    "            transform.x : transform.x + block_size,\n",
    "            transform.y : transform.y + block_size,\n",
    "        ]\n",
    "\n",
    "        if transform.flip:\n",
    "            domain_block = np.flip(domain_block, axis=1)\n",
    "\n",
    "        domain_block = np.rot90(domain_block, k=transform.rotates)\n",
    "\n",
    "        transformed_image[x : x + block_size, y : y + block_size] = (\n",
    "            intensity_scale * domain_block + transform.intensity_offset\n",
    "        )\n",
    "\n",
    "\n",
    "def perform_transform(\n",
    "    image, resized_image, transforms, block_size, intensity_scale=0.75\n",
    "):\n",
    "    \"\"\"Perform IFS on given image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.array\n",
    "        Source image.\n",
    "\n",
    "    resized_image : np.array\n",
    "        Resized source image.\n",
    "\n",
    "    transforms : list of BlockTransform's\n",
    "        Given IFS, Iterated Function System\n",
    "\n",
    "    block_size : int\n",
    "        Size of rank block.\n",
    "\n",
    "    intensity_scale : float, optional (default=0.75)\n",
    "        Reduce coefficient for image intensity.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    transformed_image : np.array\n",
    "        Transformed image.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    transformed_image = np.zeros_like(image)\n",
    "\n",
    "    xs = range(0, image.shape[0], block_size)\n",
    "    ys = range(0, image.shape[1], block_size)\n",
    "\n",
    "    transforms = deque(transforms)\n",
    "\n",
    "    for x, y in itertools.product(xs, ys):\n",
    "        block_transforms = get_transforms_for_current_block(transforms)\n",
    "        apply_transforms(\n",
    "            transformed_image,\n",
    "            resized_image,\n",
    "            x,\n",
    "            y,\n",
    "            block_size,\n",
    "            block_transforms,\n",
    "            intensity_scale,\n",
    "        )\n",
    "\n",
    "    return transformed_image\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверим, что связка find + perform работает"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def test_transform():\n",
    "    tests = (\n",
    "        ((np.array([[1, 2], [3, 4]]), np.array([[4, 6], [8, 10]]), 0, 0, 2, 1), 0.5),\n",
    "        (\n",
    "            (\n",
    "                np.array([[1, 2], [3, 4]]),\n",
    "                np.array([[4, 6, 7, 6], [6, 7, 5, 4]]),\n",
    "                0,\n",
    "                0,\n",
    "                2,\n",
    "                1,\n",
    "            ),\n",
    "            0.5,\n",
    "        ),\n",
    "        (\n",
    "            (\n",
    "                np.array([[1, 2], [3, 4]]),\n",
    "                np.array([[4, 2, 3, 6], [6, 4, 5, 5]]),\n",
    "                0,\n",
    "                0,\n",
    "                2,\n",
    "                2,\n",
    "            ),\n",
    "            0.25,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    for test, answer in tests:\n",
    "        transform = find_block_transform(*test)\n",
    "        img, resized_img, x, y, block_size, stride = test\n",
    "        transformed = perform_transform(\n",
    "            np.zeros_like(img), resized_img, [transform], block_size\n",
    "        )\n",
    "        loss = mse(img, transformed)\n",
    "        if loss > answer + 1e-5:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "test_transform()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Класс, реализующий интерфейс битового массива\n",
    "Он понадобится для преобразования найденной IFS в строку, чтобы записать сжатый файл на диск."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# GRADED CELL: BitBuffer\n",
    "\n",
    "\n",
    "class BitBuffer:\n",
    "    \"\"\"Class that provides storing and and reading integer numbers\n",
    "    in continuous bytearray.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    buffer : bytearray, optional (default=None)\n",
    "        Input bytearray, for initialization.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    _pushed_bits : int\n",
    "        Count of pushed into last byte bits\n",
    "\n",
    "    _left_bits : int\n",
    "        Count of bits that can be popped from first byte\n",
    "\n",
    "    _buf_cap : int\n",
    "        Max bits in byte\n",
    "\n",
    "    _buffer : bytearray\n",
    "        Bytearray that can contain any information.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> buffer = BitBuffer()\n",
    "    >>> buffer.push(1, 1)\n",
    "    >>> buffer.pop(1)\n",
    "    1\n",
    "    >>> buffer.push(125, 18)\n",
    "    >>> buffer.pop(18)\n",
    "    125\n",
    "    >>> buffer.push(5, 3)\n",
    "    >>> buffer.pop(3)\n",
    "    5\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, buffer=None):\n",
    "        self._pushed_bits = 0\n",
    "        self._left_bits = 8\n",
    "        self._buf_cap = 8\n",
    "        self._buffer = buffer or bytearray(1)\n",
    "\n",
    "    def to_bytearray(self):\n",
    "        \"\"\"Convert to bytearray.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        buffer: bytearray\n",
    "            Bytearray that contains all data.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        return self._buffer\n",
    "\n",
    "    def _push_bit(self, bit):\n",
    "        \"\"\"Push given bit to buffer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        bit: int\n",
    "            Input bit.\n",
    "        \"\"\"\n",
    "\n",
    "        if self._pushed_bits == self._buf_cap:\n",
    "            self._buffer.append(0)\n",
    "            self._pushed_bits = 0\n",
    "\n",
    "        self._buffer[-1] |= bit << (self._buf_cap - 1 - self._pushed_bits)\n",
    "        self._pushed_bits += 1\n",
    "\n",
    "    def _pop_bit(self):\n",
    "        \"\"\"Pop one bit from buffer.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bit: int\n",
    "            Popped bit.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if not self._left_bits:\n",
    "            self._buffer.pop(0)\n",
    "            self._left_bits = self._buf_cap\n",
    "\n",
    "        bit = (self._buffer[0] & 1 << (self._left_bits - 1)) >> (self._left_bits - 1)\n",
    "        self._left_bits -= 1\n",
    "\n",
    "        return bit\n",
    "\n",
    "    def push(self, x, n_bits):\n",
    "        \"\"\"Push given integer to buffer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: int\n",
    "            Input number.\n",
    "\n",
    "        n_bits: int\n",
    "            Number of bits for store input number,\n",
    "            should be greater than log2(x).\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        assert x < 2 ** n_bits, f\"{x} >= 2^{n_bits}\"\n",
    "\n",
    "        bits_left = n_bits\n",
    "\n",
    "        while bits_left:\n",
    "            bit = (x & (1 << (bits_left - 1))) >> (bits_left - 1)\n",
    "            self._push_bit(bit)\n",
    "            bits_left -= 1\n",
    "\n",
    "    def pop(self, n_bits):\n",
    "        \"\"\"Pop n_bits from buffer and transform it to a number.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_bits: int\n",
    "            Number of bits for pop from buffer.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x: int\n",
    "            Extracted number.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        bits_left = n_bits\n",
    "        x = 0\n",
    "\n",
    "        while bits_left:\n",
    "            x |= self._pop_bit() << (bits_left - 1)\n",
    "            bits_left -= 1\n",
    "\n",
    "        return x\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверим, что битовый массив правильно работает"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def test_bit_buffer():\n",
    "    bb = BitBuffer()\n",
    "    bb.push(15, 6)\n",
    "    bb.push(0, 7)\n",
    "    bb.push(1, 1)\n",
    "    bb.push(100, 400)\n",
    "    answer = [15, 0, 1, 100]\n",
    "\n",
    "    res2 = [bb.pop(6), bb.pop(7), bb.pop(1), bb.pop(400)]\n",
    "    if res2 == answer:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "test_bit_buffer()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В дальнейшем можно попробовать сжать битовый массив алгоритмом сжатия без потерь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Класс, реализующий интерфейс архиватора изображений"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# GRADED CELL: FractalCompressor\n",
    "\n",
    "\n",
    "class FractalCompressor:\n",
    "    \"\"\"Class that performs fractal compression/decompression of images.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    _num_bits_ver : int\n",
    "        Number of bits for store VERTICAL OFFSET for each transformation.\n",
    "\n",
    "    _num_bits_hor : int\n",
    "        Number of bits for store HORIZONTAL OFFSET for each transformation.\n",
    "\n",
    "    _num_bits_pix : int\n",
    "        Number of bits for store INTENSITY OFFSET for each transformation.\n",
    "\n",
    "    _num_bits_tfm : int\n",
    "        Number of bits for store TRANSFORMATION INDEX for each transformation.\n",
    "\n",
    "    _num_bits_flip : int\n",
    "        Number of bits for store FLIP for each transformation.\n",
    "\n",
    "    _num_bits_rotates : int\n",
    "        Number of bits for store ROTATES for each transformation.\n",
    "\n",
    "    _num_bits_bad : int\n",
    "        Number of bits for store flag of split into 4 block for each transformation.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._num_bits_ver = 8\n",
    "        self._num_bits_hor = 8\n",
    "        self._num_bits_pix = 8\n",
    "        self._num_bits_tfm = 3\n",
    "        self._num_bits_flip = 1\n",
    "        self._num_bits_rotates = 2\n",
    "        self._num_bits_bad = 1\n",
    "\n",
    "    def _add_header(self, buffer, params):\n",
    "        \"\"\"Store header in buffer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        buffer: BitBuffer\n",
    "\n",
    "        params: FractalCompressionParams\n",
    "            Parameters that should be stored in buffer.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `_read_header`.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        buffer.push(params.height, 16)\n",
    "        buffer.push(params.width, 16)\n",
    "        buffer.push(params.is_colored, 1)\n",
    "        buffer.push(params.block_size, 8)\n",
    "        buffer.push(params.uv_block_size, 8)\n",
    "        buffer.push(np.rint(params.spatial_scale * 255).astype(np.uint8), 8)\n",
    "        buffer.push(np.rint(params.intensity_scale * 255).astype(np.uint8), 8)\n",
    "        buffer.push(params.stride, 8)\n",
    "\n",
    "    def _read_header(self, buffer):\n",
    "        \"\"\"Read header from buffer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        buffer: BitBuffer\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        params: FractalCompressionParams\n",
    "            Extracted parameters.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `_add_header`.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        params = FractalCompressionParams(\n",
    "            height=buffer.pop(16),\n",
    "            width=buffer.pop(16),\n",
    "            is_colored=bool(buffer.pop(1)),\n",
    "            block_size=buffer.pop(8),\n",
    "            uv_block_size=buffer.pop(8),\n",
    "            spatial_scale=buffer.pop(8) / 255,\n",
    "            intensity_scale=buffer.pop(8) / 255,\n",
    "            stride=buffer.pop(8),\n",
    "        )\n",
    "\n",
    "        return params\n",
    "\n",
    "    def _add_to_buffer(self, buffer, transform, stride):\n",
    "        \"\"\"Store block transformation in buffer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        buffer: BitBuffer\n",
    "\n",
    "        transform: BlockTransform\n",
    "\n",
    "        stride: int\n",
    "            Vertical and horizontal stride for domain block search.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `_read_transform`.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        buffer.push(transform.bad, self._num_bits_bad)\n",
    "        if not transform.bad:\n",
    "            buffer.push(\n",
    "                transform.x // stride, derive_num_bits(2 ** self._num_bits_ver, stride)\n",
    "            )\n",
    "            buffer.push(\n",
    "                transform.y // stride, derive_num_bits(2 ** self._num_bits_hor, stride)\n",
    "            )\n",
    "            buffer.push(transform.intensity_offset + 128, self._num_bits_pix)\n",
    "            buffer.push(transform.flip, self._num_bits_flip)\n",
    "            buffer.push(transform.rotates, self._num_bits_rotates)\n",
    "\n",
    "    def _read_transform(self, buffer, stride):\n",
    "        \"\"\"Read block transformation from buffer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        buffer: BitBuffer\n",
    "\n",
    "        stride: int\n",
    "            Vertical and horizontal stride for domain block search.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        transform: BlockTransform\n",
    "            Extracted block transformation.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `_add_to_buffer`.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        bad = bool(buffer.pop(self._num_bits_bad))\n",
    "\n",
    "        if bad:\n",
    "            return BlockTransform(\n",
    "                x=0, y=0, intensity_offset=0, flip=False, rotates=0, bad=True\n",
    "            )\n",
    "\n",
    "        return BlockTransform(\n",
    "            x=buffer.pop(derive_num_bits(2 ** self._num_bits_ver, stride)) * stride,\n",
    "            y=buffer.pop(derive_num_bits(2 ** self._num_bits_hor, stride)) * stride,\n",
    "            intensity_offset=buffer.pop(self._num_bits_pix) - 128,\n",
    "            flip=bool(buffer.pop(self._num_bits_flip)),\n",
    "            rotates=buffer.pop(self._num_bits_rotates),\n",
    "            bad=bad,\n",
    "        )\n",
    "\n",
    "    def _ifs2buf(self, params, transformations):\n",
    "        \"\"\"Store compression parameters and IFS in buffer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        params: FractalCompressionParams\n",
    "            Parameters of the compression.\n",
    "\n",
    "        transformations: list of BlockTransform's\n",
    "            Given IFS.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        buffer: BitBuffer\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `_buf2ifs`.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        buffer = BitBuffer()\n",
    "        self._add_header(buffer, params)\n",
    "        for t in transformations:\n",
    "            self._add_to_buffer(buffer, t, params.stride)\n",
    "\n",
    "        return buffer\n",
    "\n",
    "    def _read_transform_for_block(self, buffer, block_size, stride):\n",
    "        \"\"\"Recursively get all transforms for one rank block.\n",
    "\n",
    "        If transform is bad then there are 4 more transforms for this rank block.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        buffer : BitBuffer\n",
    "\n",
    "        block_size : int\n",
    "            Size of rank block.\n",
    "\n",
    "        stride : int\n",
    "            Vertical and horizontal stride for domain block search.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        transforms : list of BlockTransform's\n",
    "            List of all transforms for this rank_block\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        transform = self._read_transform(buffer, stride)\n",
    "        transforms = [transform]\n",
    "        if transform.bad:\n",
    "            for _ in range(4):  # Quadtree\n",
    "                transforms.extend(\n",
    "                    self._read_transform_for_block(buffer, block_size // 2, stride)\n",
    "                )\n",
    "        return transforms\n",
    "\n",
    "    def _read_transforms(self, buffer, num_transforms, block_size, stride):\n",
    "        \"\"\"Read transforms.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        buffer : BitBuffer\n",
    "\n",
    "        num_transforms : int\n",
    "            Number of transforms to read\n",
    "\n",
    "        block_size : int\n",
    "            Size of rank block.\n",
    "\n",
    "        stride : int\n",
    "            Vertical and horizontal stride for domain block search.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        transforms : list of BlockTransform's\n",
    "            List of all transforms\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        transforms = []\n",
    "        for _ in range(num_transforms):\n",
    "            transforms.extend(\n",
    "                self._read_transform_for_block(buffer, block_size, stride)\n",
    "            )\n",
    "\n",
    "        return transforms\n",
    "\n",
    "    def _buf2ifs(self, buffer):\n",
    "        \"\"\"Store compression parameters and IFS in buffer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        buffer: BitBuffer\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        params: FractalCompressionParams\n",
    "            Extracted compression parameters.\n",
    "        transforms, transforms_{u,y,v}: list of BlockTransform's\n",
    "            Extracted IFS.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `_ifs2buf`.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        params = self._read_header(buffer)\n",
    "\n",
    "        num_transforms = int(params.height * params.width / params.block_size ** 2)\n",
    "\n",
    "        if params.is_colored:\n",
    "            num_transforms_uv = int(\n",
    "                params.height * params.width / params.uv_block_size ** 2\n",
    "            )\n",
    "\n",
    "            transforms_y = self._read_transforms(\n",
    "                buffer, num_transforms, params.block_size, params.stride\n",
    "            )\n",
    "            transforms_u = self._read_transforms(\n",
    "                buffer, num_transforms_uv, params.uv_block_size, params.stride\n",
    "            )\n",
    "            transforms_v = self._read_transforms(\n",
    "                buffer, num_transforms_uv, params.uv_block_size, params.stride\n",
    "            )\n",
    "        else:\n",
    "            transforms_y = self._read_transforms(\n",
    "                buffer, num_transforms, params.block_size, params.stride\n",
    "            )\n",
    "            transforms_u = transforms_v = None\n",
    "\n",
    "        return params, transforms_y, transforms_u, transforms_v\n",
    "\n",
    "    def _compress_block(\n",
    "        self,\n",
    "        image,\n",
    "        resized_image,\n",
    "        x,\n",
    "        y,\n",
    "        block_size,\n",
    "        stride,\n",
    "        block_size_limit,\n",
    "        loss_limit,\n",
    "    ):\n",
    "        \"\"\"Recursively find transforms for rank block.\n",
    "\n",
    "        If transform is bad then find 4 more transforms for this rank block.\n",
    "        block_size_limit limits minimal size of rank block.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image : np.array\n",
    "            Source image.\n",
    "\n",
    "        resized_image : np.array\n",
    "            Resized source image.\n",
    "\n",
    "        x, y : int, int\n",
    "            Coordinates of the rank block.\n",
    "\n",
    "        block_size : int\n",
    "            Size of rank block.\n",
    "\n",
    "        stride : int\n",
    "            Vertical and horizontal stride for domain block search.\n",
    "\n",
    "        block_size_limit : int\n",
    "            Min block_size to use\n",
    "\n",
    "        loss_limit : int\n",
    "            Loss limit for founded block in terms of MSE\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        transforms : list of BlockTransform's\n",
    "            Transformations for rank block.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        transform = find_block_transform(\n",
    "            image, resized_image, x, y, block_size, stride, loss_limit=loss_limit\n",
    "        )\n",
    "\n",
    "        transforms = [transform]\n",
    "\n",
    "        if transform.bad:\n",
    "            if block_size > block_size_limit:\n",
    "                xs = range(x, x + block_size, block_size // 2)\n",
    "                ys = range(y, y + block_size, block_size // 2)\n",
    "\n",
    "                for x_, y_ in itertools.product(xs, ys):\n",
    "                    transforms.extend(\n",
    "                        self._compress_block(\n",
    "                            image,\n",
    "                            resized_image,\n",
    "                            x_,\n",
    "                            y_,\n",
    "                            block_size // 2,\n",
    "                            stride,\n",
    "                            block_size_limit,\n",
    "                            loss_limit,\n",
    "                        )\n",
    "                    )\n",
    "            else:\n",
    "                transforms[0] = transforms[0]._replace(bad=False)\n",
    "\n",
    "        return transforms\n",
    "\n",
    "    def _compress_one_component(\n",
    "        self, image, block_size, stride, block_size_limit, loss_limit\n",
    "    ):\n",
    "        \"\"\"Compress one color component of input image\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image : np.array\n",
    "            Source image.\n",
    "\n",
    "        block_size: int, optional (default=8)\n",
    "            Size of rank block.\n",
    "\n",
    "        stride: int, optional (default=1)\n",
    "            Vertical and horizontal stride for domain block search.\n",
    "\n",
    "        block_size_limit : int\n",
    "            Min block_size to use\n",
    "\n",
    "        loss_limit : int\n",
    "            Loss limit for founded block in terms of MSE\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        transformations : list of BlockTransform's\n",
    "            Transformations for color component.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Instead of reducing each domain block we will reduce the entire image\n",
    "        resized_image = resize(image, (image.shape[0] // 2, image.shape[1] // 2))\n",
    "\n",
    "        # Splitting source image into rank blocks\n",
    "        xs = range(0, image.shape[0], block_size)\n",
    "        ys = range(0, image.shape[1], block_size)\n",
    "\n",
    "        transformations = []\n",
    "        for x, y in tqdm(itertools.product(xs, ys), total=len(xs) * len(ys)):\n",
    "            transforms = self._compress_block(\n",
    "                image,\n",
    "                resized_image,\n",
    "                x,\n",
    "                y,\n",
    "                block_size,\n",
    "                stride,\n",
    "                block_size_limit,\n",
    "                loss_limit,\n",
    "            )\n",
    "            transformations.extend(transforms)\n",
    "\n",
    "        return transformations\n",
    "\n",
    "    def rgb2yuv8(self, image):\n",
    "        \"\"\"Convert image from rgb to my own format based on YUV.\n",
    "\n",
    "        RGB -> YUV -> Scale to UINT\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image: np.array\n",
    "            Source rgb image\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y8, u8, v8: np.array, np.array, np.array\n",
    "            Color components\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        y, u, v = np.split(rgb2yuv(image), [1, 2], axis=2)\n",
    "\n",
    "        y8 = (y + 0.000) * 255\n",
    "        u8 = (u + 0.436) * 292\n",
    "        v8 = (v + 0.615) * 207\n",
    "\n",
    "        return y8, u8, v8\n",
    "\n",
    "    def yuv82rgb(self, y8, u8, v8):\n",
    "        \"\"\"Convert image from my own format based on YUV to RGB.\n",
    "\n",
    "        Scale from UINT to FLOAT -> YUV -> RGB\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y8, u8, v8: np.array, np.array, np.array\n",
    "            Color components\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        image: np.array\n",
    "            rgb image\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        y = y8 / 255 - 0.000\n",
    "        u = u8 / 292 - 0.436\n",
    "        v = v8 / 207 - 0.615\n",
    "\n",
    "        rgb = yuv2rgb(np.dstack((y, u, v)))\n",
    "\n",
    "        rgb = np.rint(rgb * 255)\n",
    "        rgb[rgb < 0] = 0\n",
    "        rgb[rgb > 255] = 255\n",
    "\n",
    "        return rgb.astype(np.uint8)\n",
    "\n",
    "    def compress(\n",
    "        self,\n",
    "        image,\n",
    "        block_size=8,\n",
    "        stride=4,\n",
    "        spatial_scale=0.5,\n",
    "        intensity_scale=0.75,\n",
    "        block_size_limit=2,\n",
    "        uv_block_size=16,\n",
    "        loss_limit=256,\n",
    "    ):\n",
    "        \"\"\"Compress input image\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image : np.array\n",
    "            Source image.\n",
    "\n",
    "        block_size: int, optional (default=8)\n",
    "            Size of rank block.\n",
    "\n",
    "        stride: int, optional (default=1)\n",
    "            Vertical and horizontal stride for domain block search.\n",
    "\n",
    "        spatial_scale : float, optional (default=0.5)\n",
    "            ({rank block size} / {domain block size}) ratio, must be <1.\n",
    "\n",
    "        intensity_scale : float, optional (default=0.75)\n",
    "            Reduce coefficient for image intensity.\n",
    "\n",
    "        block_size_limit : int, optional (default=8)\n",
    "            Min block_size to use\n",
    "\n",
    "        uv_block_size : int, optional (default=16)\n",
    "            Size of rank block for U and V components of colored image\n",
    "\n",
    "        loss_limit : int, optional(default=256)\n",
    "            Error limit for founded block in terms of MSE\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        byte_array: bytearray\n",
    "            Compressed image.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `decompress`.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if not (image.dtype == np.uint8 and 0 <= image.min() and image.max() <= 255):\n",
    "            raise ValueError(\n",
    "                f\"Image values must be np.uint8 in 0..255, but {image.dtype} in {image.min()}..{image.max()} given.\"\n",
    "            )\n",
    "\n",
    "        if is_colored(image):\n",
    "            y8, u8, v8 = self.rgb2yuv8(image)\n",
    "\n",
    "            transformations = []\n",
    "            transformations.extend(\n",
    "                self._compress_one_component(\n",
    "                    y8, block_size, stride, block_size_limit, loss_limit\n",
    "                )\n",
    "            )\n",
    "            transformations.extend(\n",
    "                self._compress_one_component(\n",
    "                    u8, uv_block_size, stride, uv_block_size, loss_limit\n",
    "                )\n",
    "            )\n",
    "            transformations.extend(\n",
    "                self._compress_one_component(\n",
    "                    v8, uv_block_size, stride, uv_block_size, loss_limit\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            image = image.astype(np.double)\n",
    "            transformations = self._compress_one_component(\n",
    "                image, block_size, stride, block_size_limit, loss_limit\n",
    "            )\n",
    "\n",
    "        params = FractalCompressionParams(\n",
    "            height=image.shape[0],\n",
    "            width=image.shape[1],\n",
    "            is_colored=is_colored(image),\n",
    "            block_size=block_size,\n",
    "            uv_block_size=uv_block_size,\n",
    "            spatial_scale=spatial_scale,\n",
    "            intensity_scale=intensity_scale,\n",
    "            stride=stride,\n",
    "        )\n",
    "\n",
    "        buffer = self._ifs2buf(params, transformations)\n",
    "\n",
    "        return buffer.to_bytearray()\n",
    "\n",
    "    def compress2(self, image, quality=60):\n",
    "        \"\"\"Compress input image\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image : np.array\n",
    "            Source image.\n",
    "\n",
    "        quality: int, optional (default=50)\n",
    "            Quality of image compression\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        byte_array: bytearray\n",
    "            Compressed image.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `decompress`.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        presets = {\n",
    "            0: {\n",
    "                \"block_size\": 16,\n",
    "                \"stride\": 4,\n",
    "                \"block_size_limit\": 8,\n",
    "                \"uv_block_size\": 32,\n",
    "            },\n",
    "            20: {\n",
    "                \"block_size\": 16,\n",
    "                \"stride\": 4,\n",
    "                \"block_size_limit\": 4,\n",
    "                \"uv_block_size\": 32,\n",
    "            },\n",
    "            40: {\n",
    "                \"block_size\": 8,\n",
    "                \"stride\": 4,\n",
    "                \"block_size_limit\": 4,\n",
    "                \"uv_block_size\": 16,\n",
    "            },\n",
    "            60: {\n",
    "                \"block_size\": 8,\n",
    "                \"stride\": 4,\n",
    "                \"block_size_limit\": 2,\n",
    "                \"uv_block_size\": 16,\n",
    "            },\n",
    "            80: {\n",
    "                \"block_size\": 4,\n",
    "                \"stride\": 2,\n",
    "                \"block_size_limit\": 4,\n",
    "                \"uv_block_size\": 16,\n",
    "            },\n",
    "            100: {\n",
    "                \"block_size\": 4,\n",
    "                \"stride\": 2,\n",
    "                \"block_size_limit\": 2,\n",
    "                \"uv_block_size\": 16,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            preset = presets[quality]\n",
    "        except KeyError:\n",
    "            raise ValueError(f\"quality must be in {tuple(presets.keys())}\")\n",
    "\n",
    "        return self.compress(image, **preset)\n",
    "\n",
    "    def _decompress_one_component(self, params, transforms, num_iterations):\n",
    "        \"\"\"Recursively apply transforms for rank block.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        params: FractalCompressionParams\n",
    "            Extracted compression parameters.\n",
    "\n",
    "        transforms : list of BlockTransform's\n",
    "            Given IFS, Iterated Function System\n",
    "\n",
    "        num_iterations: int\n",
    "            Number of iterations to perform IFS.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        image: np.array\n",
    "            Transformed image.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        image = np.zeros((params.height, params.width), dtype=np.double)\n",
    "\n",
    "        for _ in range(num_iterations):\n",
    "            # Instead of reducing each domain block we will reduce the entire image\n",
    "            resized_image = resize(image, (image.shape[0] // 2, image.shape[1] // 2))\n",
    "            image = perform_transform(\n",
    "                image, resized_image, transforms, params.block_size\n",
    "            )\n",
    "\n",
    "        return image\n",
    "\n",
    "    def decompress(self, byte_array, num_iterations=25):\n",
    "        \"\"\"Compress input image\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        byte_array: bytearray\n",
    "            Compressed image.\n",
    "\n",
    "        num_iterations: int, optional (default=25)\n",
    "            Number of iterations to perform IFS.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        image: np.array\n",
    "            Decompressed image.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        This method must be consistent with `compress`.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        buffer = BitBuffer(buffer=byte_array.copy())\n",
    "        params, transforms_y, transforms_u, transforms_v = self._buf2ifs(buffer)\n",
    "\n",
    "        if params.is_colored:\n",
    "            y8 = self._decompress_one_component(params, transforms_y, num_iterations)\n",
    "            u8 = self._decompress_one_component(\n",
    "                params._replace(block_size=params.uv_block_size),\n",
    "                transforms_u,\n",
    "                num_iterations,\n",
    "            )\n",
    "            v8 = self._decompress_one_component(\n",
    "                params._replace(block_size=params.uv_block_size),\n",
    "                transforms_v,\n",
    "                num_iterations,\n",
    "            )\n",
    "\n",
    "            return self.yuv82rgb(y8, u8, v8)\n",
    "        else:\n",
    "            gray = self._decompress_one_component(params, transforms_y, num_iterations)\n",
    "            gray[gray < 0] = 0\n",
    "            gray[gray > 255] = 255\n",
    "            return gray.astype(np.uint8)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "comp = FractalCompressor()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def weighted_psnr(ref, img):\n",
    "    assert ref.shape == img.shape, \"Shape mismatch\"\n",
    "    if is_colored(img):\n",
    "        ref_yuv = rgb2yuv(ref)\n",
    "        img_yuv = rgb2yuv(img)\n",
    "\n",
    "        return (\n",
    "            4 * psnr(ref_yuv[..., 0], img_yuv[..., 0])\n",
    "            + psnr(ref_yuv[..., 1], img_yuv[..., 1])\n",
    "            + psnr(ref_yuv[..., 2], img_yuv[..., 2])\n",
    "        ) / 6\n",
    "    else:\n",
    "        return psnr(ref, img)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пробуем применить FractalCompressor"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "result_gray = comp.compress2(lenna_gray_256x256, quality=60)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер сжатого изображения в байтах == длина полученного массива `bytearray`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "len(result_gray)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эволюция изображения при декомпрессии\n",
    "\n",
    "Подбором приходим к 25 итерациям для достижения оптимального PSNR."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def show_decompress(orig, result, n_iterations=(1, 2, 4, 8, 16, 25)):\n",
    "    images = []\n",
    "    for n in tqdm(n_iterations):\n",
    "        images.append(comp.decompress(result, n))\n",
    "\n",
    "    _, axs = plt.subplots(ncols=len(images) + 1)\n",
    "    for index in range(len(images)):\n",
    "        axs[index].imshow(images[index], cmap=\"gray\")\n",
    "        axs[index].set_title(\n",
    "            f\"its: {n_iterations[index]}, psnr: {round(psnr(images[index], orig), 2)}\"\n",
    "        )\n",
    "\n",
    "    axs[-1].imshow(orig, cmap=\"gray\")\n",
    "    axs[-1].set_title(\"orig\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_decompress(lenna_gray_256x256, result_gray)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разберемся с `YUV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот так выглядят компоненты YUV изображения."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_yuv(image):\n",
    "    components = np.split(rgb2yuv(image), [1, 2], axis=2)\n",
    "\n",
    "    _, axs = plt.subplots(ncols=len(components))\n",
    "\n",
    "    for idx, component in enumerate(components):\n",
    "        axs[idx].imshow(component, cmap=\"gray\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_yuv(lenna_rgb_256x256)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Какие преобразования использует функция rgb2yuv?\n",
    "\n",
    "Функция rgb2yuv принимает на вход rgb изображение, где каждый пиксель представлен тремя числами из диапазона `[0, 1]`.\n",
    "\n",
    "Преобразуем три базисных вектора и на основе полученных данных составим матрицу преобразований."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def find_yuv_transform():\n",
    "    i = [[[1.0, 0.0, 0.0]]]\n",
    "    y = rgb2yuv(i)[0][0]\n",
    "\n",
    "    j = [[[0.0, 1.0, 0.0]]]\n",
    "    u = rgb2yuv(j)[0][0]\n",
    "\n",
    "    k = [[[0.0, 0.0, 1.0]]]\n",
    "    v = rgb2yuv(k)[0][0]\n",
    "\n",
    "    return np.vstack((y, u, v)).T\n",
    "\n",
    "\n",
    "find_yuv_transform()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Какие максимум и минимум достижимы для каждого канала?\n",
    "\n",
    "Подбираем векторы так, чтобы получить максимальные и минимальные значения."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def find_yuv_minmax():\n",
    "    z = [[[0.0, 0.0, 0.0]]]\n",
    "    y_min = rgb2yuv(z)[0][0][0]\n",
    "    o = [[[1.0, 1.0, 1.0]]]\n",
    "    y_max = rgb2yuv(o)[0][0][0]\n",
    "\n",
    "    z = [[[1.0, 1.0, 0.0]]]\n",
    "    u_min = rgb2yuv(z)[0][0][1]\n",
    "    z = [[[0.0, 0.0, 1.0]]]\n",
    "    u_max = rgb2yuv(z)[0][0][1]\n",
    "\n",
    "    z = [[[0.0, 1.0, 1.0]]]\n",
    "    v_min = rgb2yuv(z)[0][0][2]\n",
    "    z = [[[1.0, 0.0, 0.0]]]\n",
    "    v_max = rgb2yuv(z)[0][0][2]\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        data={\n",
    "            \"components\": [\"Y\", \"U\", \"V\"],\n",
    "            \"min\": [y_min, u_min, v_min],\n",
    "            \"max\": [y_max, u_max, v_max],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "find_yuv_minmax()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Изобретая свой ~~велосипед~~ `rgb2ycbcr`\n",
    "\n",
    "Будет здорово сжимать изображение `[0, 255]`. Не буду использовать YCbCr так, как он уменьшает диапазон по Y. Изобретем \n",
    "свое преобразование на основе `rgb2yuv`, так чтобы результат был представим в типе `uint8`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def my_rgb2yuv(image):\n",
    "    y, u, v = np.split(rgb2yuv(image), [1, 2], axis=2)\n",
    "\n",
    "    y8 = (y + 0.000) * 255\n",
    "    u8 = (u + 0.436) * 292\n",
    "    v8 = (v + 0.615) * 207\n",
    "\n",
    "    # Compress, decompress\n",
    "    y8 = np.rint(y8).astype(np.uint8)\n",
    "    u8 = np.rint(u8).astype(np.uint8)\n",
    "    v8 = np.rint(v8).astype(np.uint8)\n",
    "\n",
    "    y = y8 / 255 - 0.000\n",
    "    u = u8 / 292 - 0.436\n",
    "    v = v8 / 207 - 0.615\n",
    "\n",
    "    rgb = yuv2rgb(np.dstack((y, u, v)))\n",
    "\n",
    "    print(\"Минимум и максимум в rgb изображении:\", rgb.min(), rgb.max())\n",
    "    print(\n",
    "        \"На некоторых изображениях получаем выходящие за пределы яркости. Лучше всего их обрезать.\"\n",
    "    )\n",
    "    rgb[rgb < 0] = 0\n",
    "    rgb[rgb > 1] = 1\n",
    "    rgb = np.rint(rgb * 255).astype(np.uint8)\n",
    "    plt.imshow(rgb)\n",
    "\n",
    "    print(\"PSNR:\", weighted_psnr(rgb, lenna_rgb_256x256))\n",
    "\n",
    "\n",
    "my_rgb2yuv(lenna_rgb_256x256)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\n",
    "    weighted_psnr(\n",
    "        np.rint(ycbcr2rgb(np.rint(rgb2ycbcr(lenna_rgb_256x256))) * 255).astype(\n",
    "            np.uint8\n",
    "        ),\n",
    "        lenna_rgb_256x256,\n",
    "    )\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Свой велосипед немного лучше библиотечного решения, так как хранит данные в полном диапазоне."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Эксперимент1. Каналы похожи друг на друга. Что если получать U или V из Y?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def only_y_transform(image):\n",
    "    _, axs = plt.subplots(ncols=4)\n",
    "\n",
    "    y, u, v = np.split(rgb2yuv(image), [1, 2], axis=2)\n",
    "\n",
    "    axs[0].imshow(image)\n",
    "    axs[0].set_title(\"RGB\")\n",
    "    axs[1].imshow(u, cmap=\"gray\")\n",
    "    axs[1].set_title(\"U\")\n",
    "\n",
    "    y8 = (y + 0.000) * 255\n",
    "    u8 = (u + 0.436) * 292\n",
    "    v8 = (v + 0.615) * 207\n",
    "\n",
    "    tr = find_block_transform(u8, y8, 0, 0, y8.shape[0], 1)\n",
    "    intensity_offset_u8 = tr.intensity_offset\n",
    "\n",
    "    tr = find_block_transform(v8, y8, 0, 0, y8.shape[0], 1)\n",
    "    intensity_offset_v8 = tr.intensity_offset\n",
    "\n",
    "    u8_from_y8 = 0.75 * y8 + intensity_offset_u8\n",
    "    v8_from_y8 = 0.75 * y8 + intensity_offset_v8\n",
    "\n",
    "    # Compress, decompress\n",
    "\n",
    "    y = y8 / 255 - 0.000\n",
    "    u_from_y = u8_from_y8 / 292 - 0.436\n",
    "    v_from_y = v8_from_y8 / 207 - 0.615\n",
    "\n",
    "    axs[2].imshow(u_from_y, cmap=\"gray\")\n",
    "    axs[2].set_title(f\"U from Y, psnr: {round(psnr(u, u_from_y), 2)}\")\n",
    "\n",
    "    rgb = yuv2rgb(np.dstack((y, u_from_y, v_from_y)))\n",
    "    rgb[rgb < 0] = 0\n",
    "    rgb[rgb > 1] = 1\n",
    "\n",
    "    axs[3].imshow(rgb, cmap=\"gray\")\n",
    "    axs[3].set_title(f\"result, psnr: {round(weighted_psnr(rgb, image), 2)}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "only_y_transform(lenna_rgb_256x256)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U восстановленный из Y совершенно непохож на оригинал.\n",
    "\n",
    "На общем изображении видно сильное искажение цветов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Эксперимент 2. Что если хранить меньше информации о цвете?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "def resize_uv_transform(image, mn=8):\n",
    "    _, axs = plt.subplots(ncols=2)\n",
    "\n",
    "    y, u, v = np.split(rgb2yuv(image), [1, 2], axis=2)\n",
    "\n",
    "    axs[0].imshow(image)\n",
    "    axs[0].set_title(\"RGB\")\n",
    "\n",
    "    u = resize(u, (u.shape[0] // mn, u.shape[1] // mn))\n",
    "    v = resize(v, (v.shape[0] // mn, v.shape[1] // mn))\n",
    "\n",
    "    y8 = (y + 0.000) * 255\n",
    "    u8 = (u + 0.436) * 292\n",
    "    v8 = (v + 0.615) * 207\n",
    "\n",
    "    # Compress, decompress\n",
    "\n",
    "    y = y8 / 255 - 0.000\n",
    "    u = u8 / 292 - 0.436\n",
    "    v = v8 / 207 - 0.615\n",
    "\n",
    "    u = resize(u, (u.shape[0] * mn, u.shape[1] * mn))\n",
    "    v = resize(v, (v.shape[0] * mn, v.shape[1] * mn))\n",
    "\n",
    "    rgb = yuv2rgb(np.dstack((y, u, v)))\n",
    "    rgb[rgb < 0] = 0\n",
    "    rgb[rgb > 1] = 1\n",
    "\n",
    "    axs[1].imshow(rgb)\n",
    "    axs[1].set_title(f\"result, psnr: {round(weighted_psnr(rgb, image), 2)}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "resize_uv_transform(lenna_rgb_256x256)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def optimal_mn(image, mns=(2, 4, 8, 16, 32, 64, 128, 256)):\n",
    "    psnrs = []\n",
    "\n",
    "    for mn in mns:\n",
    "        y, u, v = np.split(rgb2yuv(image), [1, 2], axis=2)\n",
    "        u = resize(u, (u.shape[0] // mn, u.shape[1] // mn))\n",
    "        v = resize(v, (v.shape[0] // mn, v.shape[1] // mn))\n",
    "\n",
    "        y8 = (y + 0.000) * 255\n",
    "        u8 = (u + 0.436) * 292\n",
    "        v8 = (v + 0.615) * 207\n",
    "\n",
    "        # Compress, decompress\n",
    "\n",
    "        y = y8 / 255 - 0.000\n",
    "        u = u8 / 292 - 0.436\n",
    "        v = v8 / 207 - 0.615\n",
    "\n",
    "        u = resize(u, (u.shape[0] * mn, u.shape[1] * mn))\n",
    "        v = resize(v, (v.shape[0] * mn, v.shape[1] * mn))\n",
    "\n",
    "        rgb = yuv2rgb(np.dstack((y, u, v)))\n",
    "        rgb[rgb < 0] = 0\n",
    "        rgb[rgb > 1] = 1\n",
    "\n",
    "        psnrs.append(weighted_psnr(rgb, image))\n",
    "\n",
    "    plt.plot(mns, psnrs)\n",
    "\n",
    "\n",
    "optimal_mn(lenna_rgb_256x256)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшение размера U и V оказывает минимальное влияние."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Цветное изображение"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "result_rgb = comp.compress2(lenna_rgb_256x256, quality=60)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "len(result_rgb)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def show_colored_decompress(orig, result):\n",
    "    img = comp.decompress(result, 25)\n",
    "    _, axs = plt.subplots(ncols=2)\n",
    "    axs[0].imshow(img)\n",
    "    axs[0].set_title(f\"its: 25, psnr: {round(weighted_psnr(orig, img), 2)}\")\n",
    "    axs[1].imshow(orig, cmap=\"gray\")\n",
    "    axs[1].set_title(\"orig\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_colored_decompress(lenna_rgb_256x256, result_rgb)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор параметра `loss_limit`\n",
    "\n",
    "Параметр влияет на количество просматриваемых блоков. Его увеличение приводит к значительному ускорению программы за \n",
    "счет качества найденных блоков."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def find_loss_limit(image, loss_limits=(16, 32, 64, 128, 256)):\n",
    "    data = {\"loss_limit\": [], \"psnr\": [], \"time\": []}\n",
    "\n",
    "    for loss_limit in loss_limits:\n",
    "        start = time.time()\n",
    "        result = comp.compress(\n",
    "            image,\n",
    "            block_size=8,\n",
    "            stride=4,\n",
    "            block_size_limit=4,\n",
    "            uv_block_size=16,\n",
    "            loss_limit=loss_limit,\n",
    "        )\n",
    "        result = comp.decompress(result, 25)\n",
    "        duration = time.time() - start\n",
    "\n",
    "        data[\"loss_limit\"].append(loss_limit)\n",
    "        data[\"psnr\"].append(weighted_psnr(result, image))\n",
    "        data[\"time\"].append(duration)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        data={\n",
    "            \"loss_limit\": data[\"loss_limit\"],\n",
    "            \"psnr\": data[\"psnr\"],\n",
    "            \"time\": data[\"time\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    plt.plot(df[\"loss_limit\"], df[\"psnr\"], label=\"psnr\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(df[\"loss_limit\"], df[\"time\"], label=\"time\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "find_loss_limit(lenna_rgb_256x256)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Небольшие значения `loss_limit` приводят к слишком долгим поискам блоков. Выберем большое значение для ускорения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построим график качества\n",
    "Качество в данном случае будет измеряться по PSNR (а значит в децибелах).\n",
    "\n",
    "Это базовый график для понимания соотношения между коэффициентом сжатия и качеством, получаемым на выходе. Можно \n",
    "посмотреть, как он будет меняться в зависимости от количества итераций при декомпрессии, например."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def test_image(img, quality=(0, 20, 40, 60, 80, 100)):\n",
    "    compressed_images = [comp.compress2(img, quality=q) for q in quality]\n",
    "    decompressed_images = [\n",
    "        comp.decompress(compressed) for compressed in compressed_images\n",
    "    ]\n",
    "    compression_rates = (\n",
    "        np.array([len(compressed) for compressed in compressed_images]) / img.size\n",
    "    )\n",
    "    psnrs = [weighted_psnr(img, decompressed) for decompressed in decompressed_images]\n",
    "    return compression_rates, psnrs, decompressed_images\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_results(results):\n",
    "    _, ax = plt.subplots()\n",
    "\n",
    "    compression_rates, psnrs, _ = results\n",
    "    ax.plot(compression_rates, psnrs, marker=\"o\", ms=10, ls=\"-.\")\n",
    "\n",
    "    ax.set_xlabel(\"Compression Rate\", fontsize=16)\n",
    "    ax.set_ylabel(\"PSNR, dB\", fontsize=16)\n",
    "\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_images(results, quality=(0, 20, 40, 60, 80, 100)):\n",
    "    _, axs = plt.subplots(ncols=len(quality))\n",
    "\n",
    "    compression_rates, psnrs, decompressed_images = results\n",
    "    for i, image in enumerate(decompressed_images):\n",
    "        axs[i].imshow(image)\n",
    "        orig_size = 256 * 256 * 3\n",
    "        axs[i].set_title(\n",
    "            f\"psnr: {round(psnrs[i], 2)}, size: {compression_rates[i] * orig_size}\"\n",
    "        )\n",
    "\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "lenna_results = test_image(lenna_rgb_256x256)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_results(lenna_results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_images(lenna_results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Улучшим алгоритм\n",
    "Одним из основных способов улучшения сжатия изображений является разбиение картинки не на равные блоки, а на блоки \n",
    "разных размеров. Как дополнительную часть задания, мы предлагаем реализовать разбиение квадродеревом, это позволит более\n",
    "гибко настраивать параметры сжатия и получить лучшие результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Пример разбиения изображения на блоки с использованием квадродерева</center>\n",
    "\n",
    "Исходное изображение | Разбиение квадродеревом\n",
    "- | -\n",
    "![Source image](images/house.jpg) | ![Segmentation](images/quadtree.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changelog\n",
    "\n",
    "1. Наивная реализация\n",
    "1. Оптимизирован поиск `intensity offset`\n",
    "1. Добавлена функция поиска поворотов и отражений на основе полного перебора\n",
    "1. Вместо изменения размера каждого блока, изменяется размер всего изображения\n",
    "1. Реализовано вычисление `intensity scale` для каждого блока\n",
    "1. Добавлена поддержка сжатия цветных изображений на основе конвертации в `YUV`\n",
    "1. Реализовано квадродерево\n",
    "1. Ограничения на возможные значения параметра `intensity scale`\n",
    "1. Быстрое сравнение рангового и доменных блоков на пригодность\n",
    "1. Обновление битового массива для повышения эффективности сжатия при использовании квадродерева\n",
    "1. Добавлены настройки квадродерева\n",
    "1. Умный алгоритм поиска поворотов и отражений\n",
    "1. Прореживание неважных компонент цветного изображения\n",
    "1. Добавлена коррекция разжатого `RGB` изображения\n",
    "1. Поиск блока останавливается при достижении приемлемого качества\n",
    "1. Добавлены пояснения и визуализация"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}