{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \u0424\u0440\u0430\u043a\u0442\u0430\u043b\u044c\u043d\u043e\u0435 \u0441\u0436\u0430\u0442\u0438\u0435\n",
        "\n",
        "## \u041d\u0435\u043c\u043d\u043e\u0433\u043e \u0442\u0435\u043e\u0440\u0438\u0438\n",
        "\u0410\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043e\u043f\u0438\u0441\u0430\u043d \u0432 \u0433\u043b\u0430\u0432\u0435 \u043f\u0440\u043e [\u0441\u0436\u0430\u0442\u0438\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439](https://compression.ru/book/part2/part2__3.htm#_Toc448152512).\n",
        "\n",
        "### \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f\n",
        "**\u0420\u0430\u043d\u0433\u043e\u0432\u044b\u0439 \u0431\u043b\u043e\u043a**: \u0435\u0441\u043b\u0438 \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0440\u0430\u0437\u0431\u0438\u0432\u0430\u0435\u0442\u0441\u044f \u043d\u0430 \u043d\u0435\u043f\u0435\u0440\u0435\u0441\u0435\u043a\u0430\u044e\u0449\u0438\u0435\u0441\u044f \u0431\u043b\u043e\u043a\u0438 \u043e\u0434\u0438\u043d\u0430\u043a\u043e\u0432\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430, \u0437\u0430\u043c\u043e\u0449\u0430\u044e\u0449\u0438\u0435 \u0432\u0441\u0451\n",
        "\u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435, \u0442\u043e \u043a\u0430\u0436\u0434\u044b\u0439 \u0442\u0430\u043a\u043e\u0439 \u0431\u043b\u043e\u043a \u043d\u0430\u0437\u044b\u0432\u0430\u0435\u0442\u0441\u044f *\u0440\u0430\u043d\u0433\u043e\u0432\u044b\u043c*; \u0438\u043c\u0435\u044e\u0442 \u043c\u0435\u043d\u044c\u0448\u0438\u0439 \u0440\u0430\u0437\u043c\u0435\u0440, \u0447\u0435\u043c \u0434\u043e\u043c\u0435\u043d\u043d\u044b\u0435 \u0431\u043b\u043e\u043a\u0438.\n",
        "\n",
        "**\u0414\u043e\u043c\u0435\u043d\u043d\u044b\u0439 \u0431\u043b\u043e\u043a**: \u0435\u0441\u043b\u0438 \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0440\u0430\u0437\u0431\u0438\u0432\u0430\u0435\u0442\u0441\u044f \u0431\u043b\u043e\u043a\u0438 \u043e\u0434\u0438\u043d\u0430\u043a\u043e\u0432\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043c\u043e\u0433\u0443\u0442 \u0438 \u043f\u0435\u0440\u0435\u0441\u0435\u043a\u0430\u0442\u044c\u0441\u044f, \u0442\u043e\n",
        "\u043a\u0430\u0436\u0434\u044b\u0439 \u0442\u0430\u043a\u043e\u0439 \u0431\u043b\u043e\u043a \u043d\u0430\u0437\u044b\u0432\u0430\u0435\u0442\u0441\u044f *\u0434\u043e\u043c\u0435\u043d\u043d\u044b\u043c*; \u0438\u043c\u0435\u044e\u0442 \u0431\u043e\u043b\u044c\u0448\u0438\u0439 \u0440\u0430\u0437\u043c\u0435\u0440, \u0447\u0435\u043c \u0440\u0430\u043d\u0433\u043e\u0432\u044b\u0435 \u0431\u043b\u043e\u043a\u0438.\n",
        "\n",
        "**\u0418\u0434\u0435\u044f \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430**:\n",
        "\n",
        "\u041f\u0440\u0438 \u0441\u0436\u0430\u0442\u0438\u0438:\n",
        "1. \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0440\u0430\u043d\u0433\u043e\u0432\u043e\u0433\u043e \u0431\u043b\u043e\u043a\u0430 \u043d\u0430\u0439\u0442\u0438 \u043d\u0430\u0438\u0431\u043e\u043b\u0435\u0435 \u043f\u043e\u0445\u043e\u0436\u0438\u0439 \u043d\u0430 \u043d\u0435\u0433\u043e \u0434\u043e\u043c\u0435\u043d\u043d\u044b\u0439 \u0431\u043b\u043e\u043a (\u0441 \u0443\u0447\u0451\u0442\u043e\u043c \u043f\u043e\u0432\u043e\u0440\u043e\u0442\u043e\u0432 \u0438 \u0441\u0438\u043c\u043c\u0435\u0442\u0440\u0438\u0438)\n",
        "2. \u0432\u044b\u043f\u043e\u043b\u043d\u0438\u0442\u044c \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u044f\u0440\u043a\u043e\u0441\u0442\u0438\n",
        "3. \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0441\u0436\u0430\u0442\u043e\u0433\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0432\u044b\u0441\u0442\u0443\u043f\u0430\u044e\u0442 \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u044b \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u0440\u0430\u043d\u0433\u043e\u0432\u044b\u0445 \u0431\u043b\u043e\u043a\u043e\u0432, \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u043e \u0437\u0430\u043f\u0438\u0441\u0430\u043d\u043d\u044b\u0435 \u0432 \u0444\u0430\u0439\u043b\n",
        "(\u0441\u0442\u0440\u043e\u043a\u0443)\n",
        "\n",
        "\u041f\u0440\u0438 \u0434\u0435\u043a\u043e\u043c\u043f\u0440\u0435\u0441\u0441\u0438\u0438:\n",
        "1. \u041f\u0440\u043e\u0447\u0438\u0442\u0430\u0442\u044c \u0444\u0430\u0439\u043b (\u0441\u0442\u0440\u043e\u043a\u0443), \u0438\u0437\u0432\u043b\u0435\u0447\u044c \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u044b \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0439\n",
        "2. \u041f\u0440\u0438\u043c\u0435\u043d\u0438\u0442\u044c \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u043a \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u043c\u0443 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044e (\u043e\u0431\u044b\u0447\u043d\u043e \u043f\u0440\u043e\u0441\u0442\u043e \u0441\u0435\u0440\u043e\u0435) \u043f\u043e\u043a\u0430 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u043d\u0435 \u0441\u0442\u0430\u0431\u0438\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u0442\u0441\u044f"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import itertools\n",
        "import time\n",
        "from collections import deque\n",
        "from typing import NamedTuple\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.animation\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from celluloid import Camera\n",
        "from matplotlib.patches import Rectangle\n",
        "from skimage import io\n",
        "from skimage.color import rgb2gray, rgb2ycbcr, rgb2yuv, ycbcr2rgb, yuv2rgb\n",
        "from skimage.metrics import mean_squared_error as mse\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.transform import resize\n",
        "from tqdm import tqdm"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u041f\u0435\u0440\u0432\u044b\u043c \u0434\u0435\u043b\u043e\u043c \u043d\u0443\u0436\u043d\u043e \u0437\u0430\u0433\u0440\u0443\u0437\u0438\u0442\u044c \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0443"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lenna_rgb_256x256 = resize(io.imread(\"test_files/lenna.bmp\"), (256, 256))\n",
        "lenna_gray_256x256 = np.rint(rgb2gray(lenna_rgb_256x256) * 255).astype(np.uint8)\n",
        "lenna_rgb_256x256 = np.rint(lenna_rgb_256x256 * 255).astype(np.uint8)\n",
        "\n",
        "plt.imshow(lenna_rgb_256x256)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u041e\u0431\u0449\u0438\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438\n",
        "\u0424\u0443\u043d\u043a\u0446\u0438\u0438 \u0438 \u043a\u043b\u0430\u0441\u0441\u044b, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u044b\u0435 \u043f\u0440\u0438 \u043d\u0430\u043f\u0438\u0441\u0430\u043d\u0438\u0438 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "class BlockTransform(NamedTuple):\n",
        "    x: int\n",
        "    y: int\n",
        "    intensity_offset: int\n",
        "    flip: bool\n",
        "    rotates: int\n",
        "    bad: int\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class FractalCompressionParams(NamedTuple):\n",
        "    height: int\n",
        "    width: int\n",
        "    is_colored: bool\n",
        "    block_size: int\n",
        "    uv_block_size: int\n",
        "    stride: int\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def derive_num_bits(length, stride):\n",
        "    return np.ceil(np.log2(length / stride)).astype(int)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def is_colored(image):\n",
        "    if len(image.shape) == 2:\n",
        "        return False\n",
        "    elif len(image.shape) == 3 and image.shape[-1] == 3:\n",
        "        return True\n",
        "    else:\n",
        "        message = \"Invalid shape of the image: `{}`\"\n",
        "        raise ValueError(message.format(image.shape))\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043d\u0430\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u044f \u043d\u0430\u0438\u043b\u0443\u0447\u0448\u0435\u0433\u043e \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u0440\u0430\u043d\u0433\u043e\u0432\u043e\u0433\u043e \u0431\u043b\u043e\u043a\u0430"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \u041a\u0430\u043a \u0438\u0441\u043a\u0430\u0442\u044c \u043f\u043e\u0432\u043e\u0440\u043e\u0442\u044b \u0438 \u043e\u0442\u0440\u0430\u0436\u0435\u043d\u0438\u044f?\n",
        "\n",
        "\u041f\u0440\u043e\u0441\u0442\u0435\u0439\u0448\u0438\u0439 \u0441\u043f\u043e\u0441\u043e\u0431 -- \u043f\u0435\u0440\u0435\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c \u0432\u0441\u0435 \u043a\u043e\u043c\u0431\u0438\u043d\u0430\u0446\u0438\u0438 \u0438 \u043d\u0430\u0439\u0442\u0438 \u043b\u0443\u0447\u0448\u0443\u044e.\n",
        "\n",
        "\u0412 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0443\u043b\u0443\u0447\u0448\u0435\u043d\u0438\u044f \u043c\u043e\u0436\u043d\u043e \u0440\u0430\u0437\u0431\u0438\u0442\u044c \u0440\u0430\u043d\u0433\u043e\u0432\u044b\u0439 \u0438 \u0434\u043e\u043c\u0435\u043d\u043d\u044b\u0435 \u0431\u043b\u043e\u043a\u0438 \u043d\u0430 \u0447\u0435\u0442\u044b\u0440\u0435 \u0447\u0430\u0441\u0442\u0438, \u043e\u0442\u0441\u043e\u0440\u0442\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0438\u0445 \u043f\u043e \u044f\u0440\u043a\u043e\u0441\u0442\u0438 \u0438 \u043f\u043e \u0432\u0437\u0430\u0438\u043c\u043d\u043e\u043c\u0443\n",
        "\u043f\u043e\u043b\u043e\u0436\u0435\u043d\u0438\u044e \u0431\u043b\u043e\u043a\u043e\u0432 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u0442\u044c \u043d\u0443\u0436\u043d\u0443\u044e \u0442\u0440\u0430\u043d\u0441\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e.\n",
        "\n",
        "\u0422\u0430\u043a\u043e\u0435 \u0440\u0435\u0448\u0435\u043d\u0438\u0435 \u043f\u043e\u0432\u044b\u0448\u0430\u0435\u0442 \u0441\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u043f\u0440\u0438\u043c\u0435\u0440\u043d\u043e \u0432 6 \u0440\u0430\u0437 \u043f\u0440\u0438 \u043f\u043e\u0442\u0435\u0440\u0435 \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u043e\u043a\u043e\u043b\u043e 0.4 PSNR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class FR(NamedTuple):\n",
        "    flip: bool\n",
        "    rotates: int\n",
        "\n",
        "\n",
        "def find_flip_rotate(domain_block, rank_block, block_size):\n",
        "    \"\"\"Find flip and rotate through split blocks to 4 quadrants and compare they.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    domain_block, rank_block : np.array, np.array\n",
        "        Compared blocks\n",
        "\n",
        "    block_size : int\n",
        "        Size of rank block.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    fr : FR\n",
        "        Transformations parameters: flip and rotates\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    xs = range(0, block_size, block_size // 2)\n",
        "    ys = range(0, block_size, block_size // 2)\n",
        "\n",
        "    quadrants = tuple(\n",
        "        np.s_[x : x + block_size // 2, y : y + block_size // 2]\n",
        "        for x, y in itertools.product(xs, ys)\n",
        "    )\n",
        "\n",
        "    presets = [\n",
        "        [None, FR(flip=False, rotates=0), None, FR(flip=True, rotates=1)],\n",
        "        [FR(flip=True, rotates=0), None, FR(flip=False, rotates=1), None],\n",
        "        [None, FR(flip=True, rotates=3), None, FR(flip=False, rotates=2)],\n",
        "        [FR(flip=False, rotates=3), None, FR(flip=True, rotates=2), None],\n",
        "    ]\n",
        "\n",
        "    db_sums = {\n",
        "        num + 1: domain_block[quadrant].sum() for num, quadrant in enumerate(quadrants)\n",
        "    }\n",
        "\n",
        "    dbs = sorted(db_sums, key=db_sums.get)\n",
        "\n",
        "    rb_sums = {\n",
        "        num + 1: rank_block[quadrant].sum() for num, quadrant in enumerate(quadrants)\n",
        "    }\n",
        "\n",
        "    rbs = sorted(rb_sums, key=rb_sums.get)\n",
        "\n",
        "    match_1 = dbs[rbs.index(1)] - 1\n",
        "    match_2 = dbs[rbs.index(2)] - 1\n",
        "\n",
        "    return presets[match_1][match_2]\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \u041a\u0430\u043a \u0438\u0441\u043a\u0430\u0442\u044c intensity_scale \u0438 intensity_offset?\n",
        "\n",
        "\u0420\u0435\u0448\u0438\u043c \u0437\u0430\u0434\u0430\u0447\u0443\n",
        "$$\n",
        "min_{a, b} E - ?\\\\\n",
        "$$\n",
        "\n",
        "\u0433\u0434\u0435 \n",
        "\n",
        "$$\n",
        "E(a, b) = \\sum_{i=1}^n \\sum_{j=1}^n (R_{ij} - (a D_{ij} + b))^2\\\\\n",
        "$$\n",
        "\n",
        "\u0430 $a$ - intensity scale, $b$ - intensity offset, $R_{ij}$, $D_{ij}$ - \u0440\u0430\u043d\u0433\u043e\u0432\u044b\u0435 \u0438 \u0434\u043e\u043c\u0435\u043d\u043d\u044b\u0435 \u0431\u043b\u043e\u043a\u0438 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0435\u043d\u043d\u043e.\n",
        "\n",
        "\u041d\u0430\u0439\u0434\u0435\u043c \u0447\u0430\u0441\u0442\u043d\u044b\u0435 \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u043d\u044b\u0435 \u043f\u043e $b$\n",
        "\n",
        "$$\n",
        "\\frac{\\partial E}{\\partial b} = \\sum_{i=1}^n \\sum_{j=1}^n 2 (R_{ij} - (a D_{ij} + b)) (-1) = 2 \\sum_{i=1}^n \\sum_{j=1}^n (a D_{ij} + b - R_{ij})\\\\\n",
        "$$\n",
        "\n",
        "\u041d\u0430 \u043f\u0440\u0430\u043a\u0442\u0438\u043a\u0435 \u0432\u044b\u0447\u0438\u0441\u043b\u044f\u0435\u043c\u044b\u0439 $a$ \u043d\u0435 \u0434\u0430\u0435\u0442 \u0431\u043e\u043b\u044c\u0448\u0438\u0445 \u043f\u0440\u0435\u0438\u043c\u0443\u0449\u0435\u0441\u0442\u0432 \u043f\u043e \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0443 (+0.3 PSNR), \u043d\u043e \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u043f\u0440\u043e\u0438\u0433\u0440\u044b\u0432\u0430\u0435\u0442 \u043f\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0438 \n",
        "\u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043f\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0443 \u0441\u0436\u0430\u0442\u043e\u0433\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f. \u0411\u0443\u0434\u0435\u043c \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0442\u043e\u043b\u044c\u043a\u043e $b$.\n",
        "\n",
        "\u0418\u0449\u0435\u043c \u044d\u043a\u0441\u0442\u0440\u0435\u043c\u0443\u043c, \u043f\u0440\u0438\u0440\u0430\u0432\u043d\u0438\u0432\u0430\u044f \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u043a \u043d\u0443\u043b\u044e.\n",
        "\n",
        "$$\n",
        "\\sum_{i=1}^n \\sum_{j=1}^n (a D_{ij} + b - R_{ij}) = 0\\\\\n",
        "$$\n",
        "\n",
        "\u0420\u0430\u0441\u043a\u0440\u044b\u0432\u0430\u0435\u043c \u0441\u043a\u043e\u0431\u043a\u0438 \u0438 \u043f\u0435\u0440\u0435\u043d\u043e\u0441\u0438\u043c \u0441\u043b\u0430\u0433\u0430\u0435\u043c\u044b\u0435, \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0449\u0438\u0435 $b$, \u0432 \u043e\u0434\u043d\u0443 \u0441\u0442\u043e\u0440\u043e\u043d\u0443.\n",
        "\n",
        "$$\n",
        "n^2 b = \\sum_{i=1}^n \\sum_{j=1}^n R_{ij} - a \\sum_{i=1}^n \\sum_{j=1}^n D_{ij}\\\\\n",
        "$$\n",
        "\n",
        "\u041c\u044b \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u0438 \u0444\u043e\u0440\u043c\u0443\u043b\u0443 \u0434\u043b\u044f \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u0430 $b$\n",
        "\n",
        "$$\n",
        "b = mean(R - a D)\\\\\n",
        "$$\n",
        "\n",
        "\u041f\u0435\u0440\u0435\u0431\u043e\u0440\u043e\u043c \u043f\u0440\u0438\u0445\u043e\u0434\u0438\u043c \u043a \u043e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u043c\u0443 $a=0.75$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def find_block_transform(\n",
        "    image, resized_image, x, y, block_size, stride, intensity_scale=0.75, loss_limit=256\n",
        "):\n",
        "    \"\"\"Find best transformation for given rank block.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    image : np.array\n",
        "        Source B/W image.\n",
        "\n",
        "    resized_image : np.array\n",
        "        Resized source image.\n",
        "\n",
        "    x, y : int, int\n",
        "        Coordinates of the rank block.\n",
        "\n",
        "    block_size : int\n",
        "        Size of rank block.\n",
        "\n",
        "    stride : int\n",
        "        Vertical and horizontal stride for domain block search.\n",
        "\n",
        "    intensity_scale : float, optional (default=0.75)\n",
        "        Reduce coefficient for image intensity.\n",
        "\n",
        "    loss_limit : int, optional (default=512)\n",
        "        Error limit for founded block in terms of MSE\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    best_transform : BlockTransform\n",
        "        Best transformation.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    best_transform = BlockTransform(\n",
        "        x=0, y=0, intensity_offset=0, flip=False, rotates=0, bad=True\n",
        "    )\n",
        "    best_transform_loss = float(\"inf\")\n",
        "\n",
        "    rank_block = image[x : x + block_size, y : y + block_size]\n",
        "\n",
        "    xs = range(0, resized_image.shape[0] - block_size + 1, stride)\n",
        "    ys = range(0, resized_image.shape[1] - block_size + 1, stride)\n",
        "\n",
        "    for domain_x, domain_y in itertools.product(xs, ys):\n",
        "        domain_block = resized_image[\n",
        "            domain_x : domain_x + block_size, domain_y : domain_y + block_size\n",
        "        ]\n",
        "\n",
        "        fr = find_flip_rotate(domain_block, rank_block, block_size)\n",
        "\n",
        "        if fr is None:\n",
        "            continue\n",
        "\n",
        "        if fr.flip:\n",
        "            domain_block = np.flip(domain_block, axis=1)\n",
        "\n",
        "        domain_block = np.rot90(domain_block, k=fr.rotates)\n",
        "\n",
        "        intensity_offset = int(\n",
        "            np.mean(rank_block - intensity_scale * domain_block).astype(np.int8)\n",
        "        )  # See explanations above\n",
        "\n",
        "        loss = mse(intensity_scale * domain_block + intensity_offset, rank_block)\n",
        "        if loss < best_transform_loss:\n",
        "            best_transform = BlockTransform(\n",
        "                x=domain_x,\n",
        "                y=domain_y,\n",
        "                intensity_offset=intensity_offset,\n",
        "                flip=fr.flip,\n",
        "                rotates=fr.rotates,\n",
        "                bad=loss >= loss_limit,\n",
        "            )\n",
        "            best_transform_loss = loss\n",
        "\n",
        "            if not best_transform.bad:\n",
        "                break\n",
        "\n",
        "    return best_transform\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \u041b\u0443\u0447\u0448\u0435\u0435 \u2014 \u0432\u0440\u0430\u0433 \u0445\u043e\u0440\u043e\u0448\u0435\u0433\u043e\n",
        "\n",
        "\u0418\u0434\u0435\u044f \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0438 \u043f\u043e\u0438\u0441\u043a\u0430 \u043f\u0440\u0438 \u0434\u043e\u0441\u0442\u0438\u0436\u0435\u043d\u0438\u0438 \u0437\u0430\u0434\u0430\u043d\u043d\u043e\u0439 \u043f\u043e\u0445\u043e\u0436\u0435\u0441\u0442\u0438 \u0431\u043b\u043e\u043a\u043e\u0432 \u0443\u0441\u043a\u043e\u0440\u044f\u0435\u0442 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043d\u0430 \u043f\u043e\u0440\u044f\u0434\u043e\u043a. \u041d\u043e \u0432\u043e\u0437\u043d\u0438\u043a\u0430\u0435\u0442 \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0430: \n",
        "\u0431\u043e\u043b\u044c\u0448\u0430\u044f \u0447\u0430\u0441\u0442\u044c \u0431\u043b\u043e\u043a\u043e\u0432 \u0431\u0435\u0440\u0435\u0442\u0441\u044f \u0438\u0437 \u043b\u0435\u0432\u043e\u0433\u043e \u0432\u0435\u0440\u0445\u043d\u0435\u0433\u043e \u0443\u0433\u043b\u0430 (\u0441\u043c\u043e\u0442\u0440\u0438 \u0432\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044e \u043d\u0438\u0436\u0435). \u0414\u043b\u044f \u0443\u0441\u0442\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u044b \u043c\u043e\u0436\u043d\u043e \n",
        "\u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c \u043c\u043e\u0434\u0438\u0444\u0438\u0446\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043f\u0435\u0440\u0435\u0431\u043e\u0440 (\u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 \u043f\u0435\u0440\u0435\u0431\u0438\u0440\u0430\u0442\u044c \u043f\u043e \u0441\u043f\u0438\u0440\u0430\u043b\u0438 \u043e\u0442 \u0441\u0442\u0430\u0440\u0442\u043e\u0432\u043e\u0433\u043e \u0431\u043b\u043e\u043a\u0430 \u043a \u043a\u0440\u0430\u044f\u043c). \u041d\u043e \u043a\u0430\u0436\u0435\u0442\u0441\u044f, \u0447\u0442\u043e \u044d\u0442\u043e \u043d\u0435 \n",
        "\u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0430, \u0430 \u043e\u0441\u043e\u0431\u0435\u043d\u043d\u043e\u0441\u0442\u044c \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430. \u041f\u043e \u043a\u0440\u0430\u0439\u043d\u0435\u0439 \u043c\u0435\u0440\u0435, \u043f\u0440\u0438 \u043f\u043e\u043b\u043d\u043e\u043c \u043f\u0435\u0440\u0435\u0431\u043e\u0440\u0435 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u0432\u0435\u0434\u0435\u0442 \u0441\u0435\u0431\u044f \u043f\u043e\u0445\u043e\u0436\u0435."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c, \u0433\u0434\u0435 \u043c\u044b \u043d\u0430\u0445\u043e\u0434\u0438\u043c \u0431\u043b\u043e\u043a\u0438"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def find_simple_transforms(image, block_size, stride):\n",
        "    \"\"\"Find simple (not use quadtree) transformations for given image.\n",
        "\n",
        "    Use this function for visualization.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    image : np.array\n",
        "        Source B/W image.\n",
        "\n",
        "    block_size : int\n",
        "        Size of rank block.\n",
        "\n",
        "    stride : int\n",
        "        Vertical and horizontal stride for domain block search.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    transforms : array of tuples (x, y, BlockTransform)\n",
        "        x, y are coordinates of rank block for which we find transform\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    image = image.astype(np.double)\n",
        "    resized_image = resize(image, (image.shape[0] // 2, image.shape[1] // 2))\n",
        "\n",
        "    # Splitting source image into rank blocks\n",
        "    xs = range(0, image.shape[0], block_size)\n",
        "    ys = range(0, image.shape[1], block_size)\n",
        "\n",
        "    transforms = []\n",
        "    for x, y in tqdm(itertools.product(xs, ys), total=len(xs) * len(ys)):\n",
        "        transform = find_block_transform(image, resized_image, x, y, block_size, stride)\n",
        "        transforms.append((x, y, transform))\n",
        "\n",
        "    return transforms\n",
        "\n",
        "\n",
        "simple_transforms = find_simple_transforms(lenna_gray_256x256, block_size=8, stride=4)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def save_transforms(image, transforms, block_size):\n",
        "    \"\"\"Save each transform on image as mp4 video.\n",
        "\n",
        "    Rank block is red, domain block is green. If transform is bad then blocks have face color.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    image : np.array\n",
        "        Source B/W image.\n",
        "\n",
        "    transforms : array of tuples (x, y, BlockTransform)\n",
        "        x, y are coordinates of rank block for which we find transform\n",
        "\n",
        "    block_size : int\n",
        "        Size of rank block.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def animate(index):\n",
        "        x, y, transform = transforms[index]\n",
        "        plt.clf()\n",
        "        plt.imshow(image, cmap=\"gray\")\n",
        "        plt.gca().add_patch(\n",
        "            Rectangle(\n",
        "                (x, y),\n",
        "                block_size,\n",
        "                block_size,\n",
        "                linewidth=1,\n",
        "                edgecolor=\"r\",\n",
        "                facecolor=\"r\" if transform.bad else \"none\",\n",
        "            )\n",
        "        )\n",
        "        plt.gca().add_patch(\n",
        "            Rectangle(\n",
        "                (transform.x, transform.y),\n",
        "                block_size * 2,\n",
        "                block_size * 2,\n",
        "                linewidth=2,\n",
        "                edgecolor=\"g\",\n",
        "                facecolor=\"g\" if transform.bad else \"none\",\n",
        "            )\n",
        "        )\n",
        "\n",
        "    ani = matplotlib.animation.FuncAnimation(\n",
        "        plt.figure(), animate, frames=len(transforms)\n",
        "    )\n",
        "\n",
        "    ani.save(\"images/simple_transforms.mp4\")\n",
        "\n",
        "\n",
        "save_transforms(lenna_gray_256x256, simple_transforms, block_size=16)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Simple transforms](images/simple_transforms.gif)](images/simple_transforms.mp4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \u0413\u0434\u0435 \u043c\u044b \u043d\u0430\u0448\u043b\u0438 \u043d\u0435\u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u0445\u043e\u0440\u043e\u0448\u0438\u0435 \u0431\u043b\u043e\u043a\u0438?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def show_bad_blocks(image, transforms, block_size):\n",
        "    \"\"\"Show bad block for given image. Red blocks are bad.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    image : np.array\n",
        "        Source B/W image.\n",
        "\n",
        "    transforms : array of tuples (x, y, BlockTransform)\n",
        "        x, y are coordinates of rank block for which we find transform\n",
        "\n",
        "    block_size : int\n",
        "        Size of rank block.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Splitting source image into rank blocks\n",
        "    xs = range(0, image.shape[0], block_size)\n",
        "    ys = range(0, image.shape[1], block_size)\n",
        "\n",
        "    plt.imshow(image, cmap=\"gray\")\n",
        "    for (\n",
        "        x,\n",
        "        y,\n",
        "        transform,\n",
        "    ) in transforms:\n",
        "        plt.gca().add_patch(\n",
        "            Rectangle(\n",
        "                (x, y),\n",
        "                block_size,\n",
        "                block_size,\n",
        "                linewidth=1,\n",
        "                edgecolor=\"none\",\n",
        "                facecolor=\"r\" if transform.bad else \"none\",\n",
        "            )\n",
        "        )\n",
        "\n",
        "    bad_blocks_rate = sum(transform.bad for _, _, transform in transforms) / (\n",
        "        len(xs) * len(ys)\n",
        "    )\n",
        "    plt.title(f\"\u0414\u043e\u043b\u044f \u043f\u043b\u043e\u0445\u0438\u0445 \u0431\u043b\u043e\u043a\u043e\u0432: {round(bad_blocks_rate, 3)}\")\n",
        "    plt.savefig(\"images/bad_blocks.png\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "show_bad_blocks(lenna_gray_256x256, simple_transforms, block_size=16)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "def animate_perform(transforms, block_size, num_iterations=4):\n",
        "    image = np.zeros((256, 256), dtype=np.double)\n",
        "\n",
        "    transformed_image = np.zeros_like(image)\n",
        "\n",
        "    fig = plt.figure()\n",
        "    camera = Camera(fig)\n",
        "\n",
        "    for _ in tqdm(range(num_iterations)):\n",
        "        # Instead of reducing each domain block we will reduce the entire image\n",
        "        resized_image = resize(image, (image.shape[0] // 2, image.shape[1] // 2))\n",
        "\n",
        "        i = 0\n",
        "        for x, y, transform in transforms:\n",
        "            domain_block = resized_image[\n",
        "                transform.x : transform.x + block_size,\n",
        "                transform.y : transform.y + block_size,\n",
        "            ]\n",
        "\n",
        "            if transform.flip:\n",
        "                domain_block = np.flip(domain_block, axis=1)\n",
        "\n",
        "            domain_block = np.rot90(domain_block, k=transform.rotates)\n",
        "\n",
        "            intensity_scale = 0.75\n",
        "\n",
        "            transformed_image[x : x + block_size, y : y + block_size] = (\n",
        "                intensity_scale * domain_block + transform.intensity_offset\n",
        "            )\n",
        "\n",
        "            blocks_in_line = image.shape[1] // block_size\n",
        "\n",
        "            i += 1\n",
        "            if i % blocks_in_line == 0:  # Show line transforms to increase performance\n",
        "                plt.imshow(transformed_image, cmap=\"gray\")\n",
        "                camera.snap()\n",
        "\n",
        "        image = transformed_image\n",
        "\n",
        "    print(\"Saving animation to file...\")\n",
        "    animation = camera.animate()\n",
        "    animation.save(\"images/performing_decompress.mp4\")\n",
        "\n",
        "\n",
        "animate_perform(simple_transforms, block_size=8)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Decompression](images/performing_decompress.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Bad blocks](images/bad_blocks.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \u041f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u0435 IFS \u043a \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044e"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_transforms_for_current_block(transforms):\n",
        "    \"\"\"Recursively find transforms for one rank block.\n",
        "\n",
        "    If transform is bad then there are 4 more transforms for this rank block.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    transforms : list of BlockTransform's\n",
        "        Given IFS, Iterated Function System\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    block_transforms : deque of BlockTransform's\n",
        "        Deque of all transforms for one rank_block\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    t = transforms.popleft()\n",
        "    block_transforms = [t]\n",
        "\n",
        "    if t.bad:\n",
        "        for _ in range(4):  # Quadtree\n",
        "            block_transforms.extend(get_transforms_for_current_block(transforms))\n",
        "\n",
        "    return deque(block_transforms)\n",
        "\n",
        "\n",
        "def apply_transforms(\n",
        "    transformed_image,\n",
        "    resized_image,\n",
        "    x,\n",
        "    y,\n",
        "    block_size,\n",
        "    block_transforms,\n",
        "    intensity_scale,\n",
        "):\n",
        "    \"\"\"Recursively apply transforms for current rank block.\n",
        "\n",
        "    If transform is bad then there are 4 more transforms for this rank block.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    transformed_image : np.array\n",
        "        Image to apply transforms\n",
        "\n",
        "    resized_image : np.array\n",
        "        Resized source image.\n",
        "\n",
        "    x, y : int, int\n",
        "        Coordinates of rank_block\n",
        "\n",
        "    block_size : int\n",
        "        Size of rank block.\n",
        "\n",
        "    block_transforms : list of BlockTransform's\n",
        "        List of all transforms for current rank_block\n",
        "\n",
        "    intensity_scale : float\n",
        "        Reduce coefficient for image intensity.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    transform = block_transforms.popleft()\n",
        "    if transform.bad:\n",
        "        xs = range(x, x + block_size, block_size // 2)\n",
        "        ys = range(y, y + block_size, block_size // 2)\n",
        "\n",
        "        for x_, y_ in itertools.product(xs, ys):\n",
        "            apply_transforms(\n",
        "                transformed_image,\n",
        "                resized_image,\n",
        "                x_,\n",
        "                y_,\n",
        "                block_size // 2,\n",
        "                block_transforms,\n",
        "                intensity_scale,\n",
        "            )\n",
        "    else:\n",
        "        domain_block = resized_image[\n",
        "            transform.x : transform.x + block_size,\n",
        "            transform.y : transform.y + block_size,\n",
        "        ]\n",
        "\n",
        "        if transform.flip:\n",
        "            domain_block = np.flip(domain_block, axis=1)\n",
        "\n",
        "        domain_block = np.rot90(domain_block, k=transform.rotates)\n",
        "\n",
        "        transformed_image[x : x + block_size, y : y + block_size] = (\n",
        "            intensity_scale * domain_block + transform.intensity_offset\n",
        "        )\n",
        "\n",
        "\n",
        "def perform_transform(\n",
        "    image, resized_image, transforms, block_size, intensity_scale=0.75\n",
        "):\n",
        "    \"\"\"Perform IFS on given image.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    image : np.array\n",
        "        Source image.\n",
        "\n",
        "    resized_image : np.array\n",
        "        Resized source image.\n",
        "\n",
        "    transforms : list of BlockTransform's\n",
        "        Given IFS, Iterated Function System\n",
        "\n",
        "    block_size : int\n",
        "        Size of rank block.\n",
        "\n",
        "    intensity_scale : float, optional (default=0.75)\n",
        "        Reduce coefficient for image intensity.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    transformed_image : np.array\n",
        "        Transformed image.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    transformed_image = np.zeros_like(image)\n",
        "\n",
        "    xs = range(0, image.shape[0], block_size)\n",
        "    ys = range(0, image.shape[1], block_size)\n",
        "\n",
        "    transforms = deque(transforms)\n",
        "\n",
        "    for x, y in itertools.product(xs, ys):\n",
        "        block_transforms = get_transforms_for_current_block(transforms)\n",
        "        apply_transforms(\n",
        "            transformed_image,\n",
        "            resized_image,\n",
        "            x,\n",
        "            y,\n",
        "            block_size,\n",
        "            block_transforms,\n",
        "            intensity_scale,\n",
        "        )\n",
        "\n",
        "    return transformed_image\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \u041f\u0440\u043e\u0432\u0435\u0440\u0438\u043c, \u0447\u0442\u043e \u0441\u0432\u044f\u0437\u043a\u0430 find + perform \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def test_transform():\n",
        "    tests = (\n",
        "        ((np.array([[1, 2], [3, 4]]), np.array([[4, 6], [8, 10]]), 0, 0, 2, 1), 0.5),\n",
        "        (\n",
        "            (\n",
        "                np.array([[1, 2], [3, 4]]),\n",
        "                np.array([[4, 6, 7, 6], [6, 7, 5, 4]]),\n",
        "                0,\n",
        "                0,\n",
        "                2,\n",
        "                1,\n",
        "            ),\n",
        "            0.5,\n",
        "        ),\n",
        "        (\n",
        "            (\n",
        "                np.array([[1, 2], [3, 4]]),\n",
        "                np.array([[4, 2, 3, 6], [6, 4, 5, 5]]),\n",
        "                0,\n",
        "                0,\n",
        "                2,\n",
        "                2,\n",
        "            ),\n",
        "            0.25,\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    for test, answer in tests:\n",
        "        transform = find_block_transform(*test)\n",
        "        img, resized_img, x, y, block_size, stride = test\n",
        "        transformed = perform_transform(\n",
        "            np.zeros_like(img), resized_img, [transform], block_size\n",
        "        )\n",
        "        loss = mse(img, transformed)\n",
        "        if loss > answer + 1e-5:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "test_transform()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \u041a\u043b\u0430\u0441\u0441, \u0440\u0435\u0430\u043b\u0438\u0437\u0443\u044e\u0449\u0438\u0439 \u0438\u043d\u0442\u0435\u0440\u0444\u0435\u0439\u0441 \u0431\u0438\u0442\u043e\u0432\u043e\u0433\u043e \u043c\u0430\u0441\u0441\u0438\u0432\u0430\n",
        "\u041e\u043d \u043f\u043e\u043d\u0430\u0434\u043e\u0431\u0438\u0442\u0441\u044f \u0434\u043b\u044f \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u043d\u0430\u0439\u0434\u0435\u043d\u043d\u043e\u0439 IFS \u0432 \u0441\u0442\u0440\u043e\u043a\u0443, \u0447\u0442\u043e\u0431\u044b \u0437\u0430\u043f\u0438\u0441\u0430\u0442\u044c \u0441\u0436\u0430\u0442\u044b\u0439 \u0444\u0430\u0439\u043b \u043d\u0430 \u0434\u0438\u0441\u043a."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class BitBuffer:\n",
        "    \"\"\"Class that provides storing and and reading integer numbers\n",
        "    in continuous bytearray.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    buffer : bytearray, optional (default=None)\n",
        "        Input bytearray, for initialization.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    _pushed_bits : int\n",
        "        Count of pushed into last byte bits\n",
        "\n",
        "    _left_bits : int\n",
        "        Count of bits that can be popped from first byte\n",
        "\n",
        "    _buf_cap : int\n",
        "        Max bits in byte\n",
        "\n",
        "    _buffer : bytearray\n",
        "        Bytearray that can contain any information.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> buffer = BitBuffer()\n",
        "    >>> buffer.push(1, 1)\n",
        "    >>> buffer.pop(1)\n",
        "    1\n",
        "    >>> buffer.push(125, 18)\n",
        "    >>> buffer.pop(18)\n",
        "    125\n",
        "    >>> buffer.push(5, 3)\n",
        "    >>> buffer.pop(3)\n",
        "    5\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, buffer=None):\n",
        "        self._pushed_bits = 0\n",
        "        self._left_bits = 8\n",
        "        self._buf_cap = 8\n",
        "        self._buffer = buffer or bytearray(1)\n",
        "\n",
        "    def to_bytearray(self):\n",
        "        \"\"\"Convert to bytearray.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        buffer: bytearray\n",
        "            Bytearray that contains all data.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        return self._buffer\n",
        "\n",
        "    def _push_bit(self, bit):\n",
        "        \"\"\"Push given bit to buffer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        bit: int\n",
        "            Input bit.\n",
        "        \"\"\"\n",
        "\n",
        "        if self._pushed_bits == self._buf_cap:\n",
        "            self._buffer.append(0)\n",
        "            self._pushed_bits = 0\n",
        "\n",
        "        self._buffer[-1] |= bit << (self._buf_cap - 1 - self._pushed_bits)\n",
        "        self._pushed_bits += 1\n",
        "\n",
        "    def _pop_bit(self):\n",
        "        \"\"\"Pop one bit from buffer.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        bit: int\n",
        "            Popped bit.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        if not self._left_bits:\n",
        "            self._buffer.pop(0)\n",
        "            self._left_bits = self._buf_cap\n",
        "\n",
        "        bit = (self._buffer[0] & 1 << (self._left_bits - 1)) >> (self._left_bits - 1)\n",
        "        self._left_bits -= 1\n",
        "\n",
        "        return bit\n",
        "\n",
        "    def push(self, x, n_bits):\n",
        "        \"\"\"Push given integer to buffer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x: int\n",
        "            Input number.\n",
        "\n",
        "        n_bits: int\n",
        "            Number of bits for store input number,\n",
        "            should be greater than log2(x).\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        assert x < 2 ** n_bits, f\"{x} >= 2^{n_bits}\"\n",
        "\n",
        "        bits_left = n_bits\n",
        "\n",
        "        while bits_left:\n",
        "            bit = (x & (1 << (bits_left - 1))) >> (bits_left - 1)\n",
        "            self._push_bit(bit)\n",
        "            bits_left -= 1\n",
        "\n",
        "    def pop(self, n_bits):\n",
        "        \"\"\"Pop n_bits from buffer and transform it to a number.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_bits: int\n",
        "            Number of bits for pop from buffer.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        x: int\n",
        "            Extracted number.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        bits_left = n_bits\n",
        "        x = 0\n",
        "\n",
        "        while bits_left:\n",
        "            x |= self._pop_bit() << (bits_left - 1)\n",
        "            bits_left -= 1\n",
        "\n",
        "        return x\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \u041f\u0440\u043e\u0432\u0435\u0440\u0438\u043c, \u0447\u0442\u043e \u0431\u0438\u0442\u043e\u0432\u044b\u0439 \u043c\u0430\u0441\u0441\u0438\u0432 \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def test_bit_buffer():\n",
        "    bb = BitBuffer()\n",
        "    bb.push(15, 6)\n",
        "    bb.push(0, 7)\n",
        "    bb.push(1, 1)\n",
        "    bb.push(100, 400)\n",
        "    answer = [15, 0, 1, 100]\n",
        "\n",
        "    res2 = [bb.pop(6), bb.pop(7), bb.pop(1), bb.pop(400)]\n",
        "    if res2 == answer:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "test_bit_buffer()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u0412 \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u043c \u043c\u043e\u0436\u043d\u043e \u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c \u0441\u0436\u0430\u0442\u044c \u0431\u0438\u0442\u043e\u0432\u044b\u0439 \u043c\u0430\u0441\u0441\u0438\u0432 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u043c \u0441\u0436\u0430\u0442\u0438\u044f \u0431\u0435\u0437 \u043f\u043e\u0442\u0435\u0440\u044c."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \u041a\u043b\u0430\u0441\u0441, \u0440\u0435\u0430\u043b\u0438\u0437\u0443\u044e\u0449\u0438\u0439 \u0438\u043d\u0442\u0435\u0440\u0444\u0435\u0439\u0441 \u0430\u0440\u0445\u0438\u0432\u0430\u0442\u043e\u0440\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class FractalCompressor:\n",
        "    \"\"\"Class that performs fractal compression/decompression of images.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    _num_bits_ver : int\n",
        "        Number of bits for store VERTICAL OFFSET for each transformation.\n",
        "\n",
        "    _num_bits_hor : int\n",
        "        Number of bits for store HORIZONTAL OFFSET for each transformation.\n",
        "\n",
        "    _num_bits_pix : int\n",
        "        Number of bits for store INTENSITY OFFSET for each transformation.\n",
        "\n",
        "    _num_bits_tfm : int\n",
        "        Number of bits for store TRANSFORMATION INDEX for each transformation.\n",
        "\n",
        "    _num_bits_flip : int\n",
        "        Number of bits for store FLIP for each transformation.\n",
        "\n",
        "    _num_bits_rotates : int\n",
        "        Number of bits for store ROTATES for each transformation.\n",
        "\n",
        "    _num_bits_bad : int\n",
        "        Number of bits for store flag of split into 4 block for each transformation.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self._num_bits_ver = 8\n",
        "        self._num_bits_hor = 8\n",
        "        self._num_bits_pix = 8\n",
        "        self._num_bits_tfm = 3\n",
        "        self._num_bits_flip = 1\n",
        "        self._num_bits_rotates = 2\n",
        "        self._num_bits_bad = 1\n",
        "\n",
        "    def _add_header(self, buffer, params):\n",
        "        \"\"\"Store header in buffer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        buffer: BitBuffer\n",
        "\n",
        "        params: FractalCompressionParams\n",
        "            Parameters that should be stored in buffer.\n",
        "\n",
        "        Note\n",
        "        ----\n",
        "        This method must be consistent with `_read_header`.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        buffer.push(params.height, 16)\n",
        "        buffer.push(params.width, 16)\n",
        "        buffer.push(params.is_colored, 1)\n",
        "        buffer.push(params.block_size, 8)\n",
        "        buffer.push(params.uv_block_size, 8)\n",
        "        buffer.push(params.stride, 8)\n",
        "\n",
        "    def _read_header(self, buffer):\n",
        "        \"\"\"Read header from buffer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        buffer: BitBuffer\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        params: FractalCompressionParams\n",
        "            Extracted parameters.\n",
        "\n",
        "        Note\n",
        "        ----\n",
        "        This method must be consistent with `_add_header`.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        params = FractalCompressionParams(\n",
        "            height=buffer.pop(16),\n",
        "            width=buffer.pop(16),\n",
        "            is_colored=bool(buffer.pop(1)),\n",
        "            block_size=buffer.pop(8),\n",
        "            uv_block_size=buffer.pop(8),\n",
        "            stride=buffer.pop(8),\n",
        "        )\n",
        "\n",
        "        return params\n",
        "\n",
        "    def _add_to_buffer(self, buffer, transform, stride):\n",
        "        \"\"\"Store block transformation in buffer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        buffer: BitBuffer\n",
        "\n",
        "        transform: BlockTransform\n",
        "\n",
        "        stride: int\n",
        "            Vertical and horizontal stride for domain block search.\n",
        "\n",
        "        Note\n",
        "        ----\n",
        "        This method must be consistent with `_read_transform`.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        buffer.push(transform.bad, self._num_bits_bad)\n",
        "        if not transform.bad:\n",
        "            buffer.push(\n",
        "                transform.x // stride, derive_num_bits(2 ** self._num_bits_ver, stride)\n",
        "            )\n",
        "            buffer.push(\n",
        "                transform.y // stride, derive_num_bits(2 ** self._num_bits_hor, stride)\n",
        "            )\n",
        "            buffer.push(transform.intensity_offset + 128, self._num_bits_pix)\n",
        "            buffer.push(transform.flip, self._num_bits_flip)\n",
        "            buffer.push(transform.rotates, self._num_bits_rotates)\n",
        "\n",
        "    def _read_transform(self, buffer, stride):\n",
        "        \"\"\"Read block transformation from buffer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        buffer: BitBuffer\n",
        "\n",
        "        stride: int\n",
        "            Vertical and horizontal stride for domain block search.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        transform: BlockTransform\n",
        "            Extracted block transformation.\n",
        "\n",
        "        Note\n",
        "        ----\n",
        "        This method must be consistent with `_add_to_buffer`.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        bad = bool(buffer.pop(self._num_bits_bad))\n",
        "\n",
        "        if bad:\n",
        "            return BlockTransform(\n",
        "                x=0, y=0, intensity_offset=0, flip=False, rotates=0, bad=True\n",
        "            )\n",
        "\n",
        "        return BlockTransform(\n",
        "            x=buffer.pop(derive_num_bits(2 ** self._num_bits_ver, stride)) * stride,\n",
        "            y=buffer.pop(derive_num_bits(2 ** self._num_bits_hor, stride)) * stride,\n",
        "            intensity_offset=buffer.pop(self._num_bits_pix) - 128,\n",
        "            flip=bool(buffer.pop(self._num_bits_flip)),\n",
        "            rotates=buffer.pop(self._num_bits_rotates),\n",
        "            bad=bad,\n",
        "        )\n",
        "\n",
        "    def _ifs2buf(self, params, transformations):\n",
        "        \"\"\"Store compression parameters and IFS in buffer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        params: FractalCompressionParams\n",
        "            Parameters of the compression.\n",
        "\n",
        "        transformations: list of BlockTransform's\n",
        "            Given IFS.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        buffer: BitBuffer\n",
        "\n",
        "        Note\n",
        "        ----\n",
        "        This method must be consistent with `_buf2ifs`.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        buffer = BitBuffer()\n",
        "        self._add_header(buffer, params)\n",
        "        for t in transformations:\n",
        "            self._add_to_buffer(buffer, t, params.stride)\n",
        "\n",
        "        return buffer\n",
        "\n",
        "    def _read_transform_for_block(self, buffer, block_size, stride):\n",
        "        \"\"\"Recursively get all transforms for one rank block.\n",
        "\n",
        "        If transform is bad then there are 4 more transforms for this rank block.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        buffer : BitBuffer\n",
        "\n",
        "        block_size : int\n",
        "            Size of rank block.\n",
        "\n",
        "        stride : int\n",
        "            Vertical and horizontal stride for domain block search.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        transforms : list of BlockTransform's\n",
        "            List of all transforms for this rank_block\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        transform = self._read_transform(buffer, stride)\n",
        "        transforms = [transform]\n",
        "        if transform.bad:\n",
        "            for _ in range(4):  # Quadtree\n",
        "                transforms.extend(\n",
        "                    self._read_transform_for_block(buffer, block_size // 2, stride)\n",
        "                )\n",
        "        return transforms\n",
        "\n",
        "    def _read_transforms(self, buffer, num_transforms, block_size, stride):\n",
        "        \"\"\"Read transforms.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        buffer : BitBuffer\n",
        "\n",
        "        num_transforms : int\n",
        "            Number of transforms to read\n",
        "\n",
        "        block_size : int\n",
        "            Size of rank block.\n",
        "\n",
        "        stride : int\n",
        "            Vertical and horizontal stride for domain block search.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        transforms : list of BlockTransform's\n",
        "            List of all transforms\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        transforms = []\n",
        "        for _ in range(num_transforms):\n",
        "            transforms.extend(\n",
        "                self._read_transform_for_block(buffer, block_size, stride)\n",
        "            )\n",
        "\n",
        "        return transforms\n",
        "\n",
        "    def _buf2ifs(self, buffer):\n",
        "        \"\"\"Store compression parameters and IFS in buffer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        buffer: BitBuffer\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        params: FractalCompressionParams\n",
        "            Extracted compression parameters.\n",
        "        transforms, transforms_{u,y,v}: list of BlockTransform's\n",
        "            Extracted IFS.\n",
        "\n",
        "        Note\n",
        "        ----\n",
        "        This method must be consistent with `_ifs2buf`.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        params = self._read_header(buffer)\n",
        "\n",
        "        num_transforms = int(params.height * params.width / params.block_size ** 2)\n",
        "\n",
        "        if params.is_colored:\n",
        "            num_transforms_uv = int(\n",
        "                params.height * params.width / params.uv_block_size ** 2\n",
        "            )\n",
        "\n",
        "            transforms_y = self._read_transforms(\n",
        "                buffer, num_transforms, params.block_size, params.stride\n",
        "            )\n",
        "            transforms_u = self._read_transforms(\n",
        "                buffer, num_transforms_uv, params.uv_block_size, params.stride\n",
        "            )\n",
        "            transforms_v = self._read_transforms(\n",
        "                buffer, num_transforms_uv, params.uv_block_size, params.stride\n",
        "            )\n",
        "        else:\n",
        "            transforms_y = self._read_transforms(\n",
        "                buffer, num_transforms, params.block_size, params.stride\n",
        "            )\n",
        "            transforms_u = transforms_v = None\n",
        "\n",
        "        return params, transforms_y, transforms_u, transforms_v\n",
        "\n",
        "    def _compress_block(\n",
        "        self,\n",
        "        image,\n",
        "        resized_image,\n",
        "        x,\n",
        "        y,\n",
        "        block_size,\n",
        "        stride,\n",
        "        block_size_limit,\n",
        "        loss_limit,\n",
        "    ):\n",
        "        \"\"\"Recursively find transforms for rank block.\n",
        "\n",
        "        If transform is bad then find 4 more transforms for this rank block.\n",
        "        block_size_limit limits minimal size of rank block.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        image : np.array\n",
        "            Source image.\n",
        "\n",
        "        resized_image : np.array\n",
        "            Resized source image.\n",
        "\n",
        "        x, y : int, int\n",
        "            Coordinates of the rank block.\n",
        "\n",
        "        block_size : int\n",
        "            Size of rank block.\n",
        "\n",
        "        stride : int\n",
        "            Vertical and horizontal stride for domain block search.\n",
        "\n",
        "        block_size_limit : int\n",
        "            Min block_size to use\n",
        "\n",
        "        loss_limit : int\n",
        "            Loss limit for founded block in terms of MSE\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        transforms : list of BlockTransform's\n",
        "            Transformations for rank block.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        transform = find_block_transform(\n",
        "            image, resized_image, x, y, block_size, stride, loss_limit=loss_limit\n",
        "        )\n",
        "\n",
        "        transforms = [transform]\n",
        "\n",
        "        if transform.bad:\n",
        "            if block_size > block_size_limit:\n",
        "                xs = range(x, x + block_size, block_size // 2)\n",
        "                ys = range(y, y + block_size, block_size // 2)\n",
        "\n",
        "                for x_, y_ in itertools.product(xs, ys):\n",
        "                    transforms.extend(\n",
        "                        self._compress_block(\n",
        "                            image,\n",
        "                            resized_image,\n",
        "                            x_,\n",
        "                            y_,\n",
        "                            block_size // 2,\n",
        "                            stride,\n",
        "                            block_size_limit,\n",
        "                            loss_limit,\n",
        "                        )\n",
        "                    )\n",
        "            else:\n",
        "                transforms[0] = transforms[0]._replace(bad=False)\n",
        "\n",
        "        return transforms\n",
        "\n",
        "    def _compress_one_component(\n",
        "        self, image, block_size, stride, block_size_limit, loss_limit\n",
        "    ):\n",
        "        \"\"\"Compress one color component of input image\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        image : np.array\n",
        "            Source image.\n",
        "\n",
        "        block_size: int, optional (default=8)\n",
        "            Size of rank block.\n",
        "\n",
        "        stride: int, optional (default=1)\n",
        "            Vertical and horizontal stride for domain block search.\n",
        "\n",
        "        block_size_limit : int\n",
        "            Min block_size to use\n",
        "\n",
        "        loss_limit : int\n",
        "            Loss limit for founded block in terms of MSE\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        transformations : list of BlockTransform's\n",
        "            Transformations for color component.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # Instead of reducing each domain block we will reduce the entire image\n",
        "        resized_image = resize(image, (image.shape[0] // 2, image.shape[1] // 2))\n",
        "\n",
        "        # Splitting source image into rank blocks\n",
        "        xs = range(0, image.shape[0], block_size)\n",
        "        ys = range(0, image.shape[1], block_size)\n",
        "\n",
        "        transformations = []\n",
        "        for x, y in tqdm(itertools.product(xs, ys), total=len(xs) * len(ys)):\n",
        "            transforms = self._compress_block(\n",
        "                image,\n",
        "                resized_image,\n",
        "                x,\n",
        "                y,\n",
        "                block_size,\n",
        "                stride,\n",
        "                block_size_limit,\n",
        "                loss_limit,\n",
        "            )\n",
        "            transformations.extend(transforms)\n",
        "\n",
        "        return transformations\n",
        "\n",
        "    def rgb2yuv8(self, image):\n",
        "        \"\"\"Convert image from rgb to my own format based on YUV.\n",
        "\n",
        "        RGB -> YUV -> Scale to UINT\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        image: np.array\n",
        "            Source rgb image\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        y8, u8, v8: np.array, np.array, np.array\n",
        "            Color components\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        y, u, v = np.split(rgb2yuv(image), [1, 2], axis=2)\n",
        "\n",
        "        y8 = (y + 0.000) * 255\n",
        "        u8 = (u + 0.436) * 292\n",
        "        v8 = (v + 0.615) * 207\n",
        "\n",
        "        return y8, u8, v8\n",
        "\n",
        "    def yuv82rgb(self, y8, u8, v8):\n",
        "        \"\"\"Convert image from my own format based on YUV to RGB.\n",
        "\n",
        "        Scale from UINT to FLOAT -> YUV -> RGB\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y8, u8, v8: np.array, np.array, np.array\n",
        "            Color components\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        image: np.array\n",
        "            rgb image\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        y = y8 / 255 - 0.000\n",
        "        u = u8 / 292 - 0.436\n",
        "        v = v8 / 207 - 0.615\n",
        "\n",
        "        rgb = yuv2rgb(np.dstack((y, u, v)))\n",
        "\n",
        "        rgb = np.rint(rgb * 255)\n",
        "        rgb[rgb < 0] = 0\n",
        "        rgb[rgb > 255] = 255\n",
        "\n",
        "        return rgb.astype(np.uint8)\n",
        "\n",
        "    def compress(\n",
        "        self,\n",
        "        image,\n",
        "        block_size=8,\n",
        "        stride=4,\n",
        "        block_size_limit=2,\n",
        "        uv_block_size=16,\n",
        "        loss_limit=256,\n",
        "    ):\n",
        "        \"\"\"Compress input image\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        image : np.array\n",
        "            Source image.\n",
        "\n",
        "        block_size: int, optional (default=8)\n",
        "            Size of rank block.\n",
        "\n",
        "        stride: int, optional (default=1)\n",
        "            Vertical and horizontal stride for domain block search.\n",
        "\n",
        "        block_size_limit : int, optional (default=8)\n",
        "            Min block_size to use\n",
        "\n",
        "        uv_block_size : int, optional (default=16)\n",
        "            Size of rank block for U and V components of colored image\n",
        "\n",
        "        loss_limit : int, optional(default=256)\n",
        "            Error limit for founded block in terms of MSE\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        byte_array: bytearray\n",
        "            Compressed image.\n",
        "\n",
        "        Note\n",
        "        ----\n",
        "        This method must be consistent with `decompress`.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        if not (image.dtype == np.uint8 and 0 <= image.min() and image.max() <= 255):\n",
        "            raise ValueError(\n",
        "                f\"Image values must be np.uint8 in 0..255, but {image.dtype} in {image.min()}..{image.max()} given.\"\n",
        "            )\n",
        "\n",
        "        if is_colored(image):\n",
        "            y8, u8, v8 = self.rgb2yuv8(image)\n",
        "\n",
        "            transformations = []\n",
        "            transformations.extend(\n",
        "                self._compress_one_component(\n",
        "                    y8, block_size, stride, block_size_limit, loss_limit\n",
        "                )\n",
        "            )\n",
        "            transformations.extend(\n",
        "                self._compress_one_component(\n",
        "                    u8, uv_block_size, stride, uv_block_size, loss_limit\n",
        "                )\n",
        "            )\n",
        "            transformations.extend(\n",
        "                self._compress_one_component(\n",
        "                    v8, uv_block_size, stride, uv_block_size, loss_limit\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            image = image.astype(np.double)\n",
        "            transformations = self._compress_one_component(\n",
        "                image, block_size, stride, block_size_limit, loss_limit\n",
        "            )\n",
        "\n",
        "        params = FractalCompressionParams(\n",
        "            height=image.shape[0],\n",
        "            width=image.shape[1],\n",
        "            is_colored=is_colored(image),\n",
        "            block_size=block_size,\n",
        "            uv_block_size=uv_block_size,\n",
        "            stride=stride,\n",
        "        )\n",
        "\n",
        "        buffer = self._ifs2buf(params, transformations)\n",
        "\n",
        "        return buffer.to_bytearray()\n",
        "\n",
        "    def compress2(self, image, quality=60):\n",
        "        \"\"\"Compress input image\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        image : np.array\n",
        "            Source image.\n",
        "\n",
        "        quality: int, optional (default=50)\n",
        "            Quality of image compression\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        byte_array: bytearray\n",
        "            Compressed image.\n",
        "\n",
        "        Note\n",
        "        ----\n",
        "        This method must be consistent with `decompress`.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        presets = {\n",
        "            0: {\n",
        "                \"block_size\": 16,\n",
        "                \"stride\": 4,\n",
        "                \"block_size_limit\": 8,\n",
        "                \"uv_block_size\": 32,\n",
        "            },\n",
        "            20: {\n",
        "                \"block_size\": 16,\n",
        "                \"stride\": 4,\n",
        "                \"block_size_limit\": 4,\n",
        "                \"uv_block_size\": 32,\n",
        "            },\n",
        "            40: {\n",
        "                \"block_size\": 8,\n",
        "                \"stride\": 4,\n",
        "                \"block_size_limit\": 4,\n",
        "                \"uv_block_size\": 16,\n",
        "            },\n",
        "            60: {\n",
        "                \"block_size\": 8,\n",
        "                \"stride\": 4,\n",
        "                \"block_size_limit\": 2,\n",
        "                \"uv_block_size\": 16,\n",
        "            },\n",
        "            80: {\n",
        "                \"block_size\": 4,\n",
        "                \"stride\": 2,\n",
        "                \"block_size_limit\": 4,\n",
        "                \"uv_block_size\": 16,\n",
        "            },\n",
        "            100: {\n",
        "                \"block_size\": 4,\n",
        "                \"stride\": 2,\n",
        "                \"block_size_limit\": 2,\n",
        "                \"uv_block_size\": 16,\n",
        "            },\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            preset = presets[quality]\n",
        "        except KeyError:\n",
        "            raise ValueError(f\"quality must be in {tuple(presets.keys())}\")\n",
        "\n",
        "        return self.compress(image, **preset)\n",
        "\n",
        "    def _decompress_one_component(self, params, transforms, num_iterations):\n",
        "        \"\"\"Recursively apply transforms for rank block.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        params: FractalCompressionParams\n",
        "            Extracted compression parameters.\n",
        "\n",
        "        transforms : list of BlockTransform's\n",
        "            Given IFS, Iterated Function System\n",
        "\n",
        "        num_iterations: int\n",
        "            Number of iterations to perform IFS.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        image: np.array\n",
        "            Transformed image.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        image = np.zeros((params.height, params.width), dtype=np.double)\n",
        "\n",
        "        for _ in range(num_iterations):\n",
        "            # Instead of reducing each domain block we will reduce the entire image\n",
        "            resized_image = resize(image, (image.shape[0] // 2, image.shape[1] // 2))\n",
        "            image = perform_transform(\n",
        "                image, resized_image, transforms, params.block_size\n",
        "            )\n",
        "\n",
        "        return image\n",
        "\n",
        "    def decompress(self, byte_array, num_iterations=25):\n",
        "        \"\"\"Compress input image\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        byte_array: bytearray\n",
        "            Compressed image.\n",
        "\n",
        "        num_iterations: int, optional (default=25)\n",
        "            Number of iterations to perform IFS.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        image: np.array\n",
        "            Decompressed image.\n",
        "\n",
        "        Note\n",
        "        ----\n",
        "        This method must be consistent with `compress`.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        buffer = BitBuffer(buffer=byte_array.copy())\n",
        "        params, transforms_y, transforms_u, transforms_v = self._buf2ifs(buffer)\n",
        "\n",
        "        if params.is_colored:\n",
        "            y8 = self._decompress_one_component(params, transforms_y, num_iterations)\n",
        "            u8 = self._decompress_one_component(\n",
        "                params._replace(block_size=params.uv_block_size),\n",
        "                transforms_u,\n",
        "                num_iterations,\n",
        "            )\n",
        "            v8 = self._decompress_one_component(\n",
        "                params._replace(block_size=params.uv_block_size),\n",
        "                transforms_v,\n",
        "                num_iterations,\n",
        "            )\n",
        "\n",
        "            return self.yuv82rgb(y8, u8, v8)\n",
        "        else:\n",
        "            gray = self._decompress_one_component(params, transforms_y, num_iterations)\n",
        "            gray[gray < 0] = 0\n",
        "            gray[gray > 255] = 255\n",
        "            return gray.astype(np.uint8)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "comp = FractalCompressor()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def weighted_psnr(ref, img):\n",
        "    assert ref.shape == img.shape, \"Shape mismatch\"\n",
        "    if is_colored(img):\n",
        "        ref_yuv = rgb2yuv(ref)\n",
        "        img_yuv = rgb2yuv(img)\n",
        "\n",
        "        return (\n",
        "            4 * psnr(ref_yuv[..., 0], img_yuv[..., 0])\n",
        "            + psnr(ref_yuv[..., 1], img_yuv[..., 1])\n",
        "            + psnr(ref_yuv[..., 2], img_yuv[..., 2])\n",
        "        ) / 6\n",
        "    else:\n",
        "        return psnr(ref, img)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u041f\u0440\u043e\u0431\u0443\u0435\u043c \u043f\u0440\u0438\u043c\u0435\u043d\u0438\u0442\u044c FractalCompressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result_gray = comp.compress2(lenna_gray_256x256, quality=60)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u0420\u0430\u0437\u043c\u0435\u0440 \u0441\u0436\u0430\u0442\u043e\u0433\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0432 \u0431\u0430\u0439\u0442\u0430\u0445 == \u0434\u043b\u0438\u043d\u0430 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u043e\u0433\u043e \u043c\u0430\u0441\u0441\u0438\u0432\u0430 `bytearray`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "len(result_gray)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \u042d\u0432\u043e\u043b\u044e\u0446\u0438\u044f \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u043f\u0440\u0438 \u0434\u0435\u043a\u043e\u043c\u043f\u0440\u0435\u0441\u0441\u0438\u0438\n",
        "\n",
        "\u041f\u043e\u0434\u0431\u043e\u0440\u043e\u043c \u043f\u0440\u0438\u0445\u043e\u0434\u0438\u043c \u043a 25 \u0438\u0442\u0435\u0440\u0430\u0446\u0438\u044f\u043c \u0434\u043b\u044f \u0434\u043e\u0441\u0442\u0438\u0436\u0435\u043d\u0438\u044f \u043e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0433\u043e PSNR."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def show_decompress(orig, result, n_iterations=(1, 2, 4, 8, 16, 25)):\n",
        "    images = []\n",
        "    for n in tqdm(n_iterations):\n",
        "        images.append(comp.decompress(result, n))\n",
        "\n",
        "    _, axs = plt.subplots(ncols=len(images) + 1)\n",
        "    for index in range(len(images)):\n",
        "        axs[index].imshow(images[index], cmap=\"gray\")\n",
        "        axs[index].set_title(\n",
        "            f\"its: {n_iterations[index]}, psnr: {round(psnr(images[index], orig), 2)}\"\n",
        "        )\n",
        "\n",
        "    axs[-1].imshow(orig, cmap=\"gray\")\n",
        "    axs[-1].set_title(\"orig\")\n",
        "\n",
        "    plt.savefig(\"images/decompress.jpg\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "show_decompress(lenna_gray_256x256, result_gray)\n",
        "\n",
        "#%%\n",
        "\"\"\"\n",
        "![Decompress](images/decompress.jpg)\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u0420\u0430\u0437\u0431\u0435\u0440\u0435\u043c\u0441\u044f \u0441 `YUV`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u0412\u043e\u0442 \u0442\u0430\u043a \u0432\u044b\u0433\u043b\u044f\u0434\u044f\u0442 \u043a\u043e\u043c\u043f\u043e\u043d\u0435\u043d\u0442\u044b YUV \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_yuv(image):\n",
        "    components = np.split(rgb2yuv(image), [1, 2], axis=2)\n",
        "\n",
        "    _, axs = plt.subplots(ncols=len(components))\n",
        "\n",
        "    for idx, component in enumerate(components):\n",
        "        axs[idx].imshow(component, cmap=\"gray\")\n",
        "\n",
        "    plt.savefig(\"images/yuv_components.jpg\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_yuv(lenna_rgb_256x256)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \u041a\u0430\u043a\u0438\u0435 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442 \u0444\u0443\u043d\u043a\u0446\u0438\u044f rgb2yuv?\n",
        "\n",
        "\u0424\u0443\u043d\u043a\u0446\u0438\u044f rgb2yuv \u043f\u0440\u0438\u043d\u0438\u043c\u0430\u0435\u0442 \u043d\u0430 \u0432\u0445\u043e\u0434 rgb \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435, \u0433\u0434\u0435 \u043a\u0430\u0436\u0434\u044b\u0439 \u043f\u0438\u043a\u0441\u0435\u043b\u044c \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d \u0442\u0440\u0435\u043c\u044f \u0447\u0438\u0441\u043b\u0430\u043c\u0438 \u0438\u0437 \u0434\u0438\u0430\u043f\u0430\u0437\u043e\u043d\u0430 `[0, 1]`.\n",
        "\n",
        "\u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c \u0442\u0440\u0438 \u0431\u0430\u0437\u0438\u0441\u043d\u044b\u0445 \u0432\u0435\u043a\u0442\u043e\u0440\u0430 \u0438 \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u043c \u043c\u0430\u0442\u0440\u0438\u0446\u0443 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0439."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def find_yuv_transform():\n",
        "    i = [[[1.0, 0.0, 0.0]]]\n",
        "    y = rgb2yuv(i)[0][0]\n",
        "\n",
        "    j = [[[0.0, 1.0, 0.0]]]\n",
        "    u = rgb2yuv(j)[0][0]\n",
        "\n",
        "    k = [[[0.0, 0.0, 1.0]]]\n",
        "    v = rgb2yuv(k)[0][0]\n",
        "\n",
        "    return np.vstack((y, u, v)).T\n",
        "\n",
        "\n",
        "find_yuv_transform()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \u041a\u0430\u043a\u0438\u0435 \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c \u0438 \u043c\u0438\u043d\u0438\u043c\u0443\u043c \u0434\u043e\u0441\u0442\u0438\u0436\u0438\u043c\u044b \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043a\u0430\u043d\u0430\u043b\u0430?\n",
        "\n",
        "\u041f\u043e\u0434\u0431\u0438\u0440\u0430\u0435\u043c \u0432\u0435\u043a\u0442\u043e\u0440\u044b \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0435 \u0438 \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def find_yuv_minmax():\n",
        "    z = [[[0.0, 0.0, 0.0]]]\n",
        "    y_min = rgb2yuv(z)[0][0][0]\n",
        "    o = [[[1.0, 1.0, 1.0]]]\n",
        "    y_max = rgb2yuv(o)[0][0][0]\n",
        "\n",
        "    z = [[[1.0, 1.0, 0.0]]]\n",
        "    u_min = rgb2yuv(z)[0][0][1]\n",
        "    z = [[[0.0, 0.0, 1.0]]]\n",
        "    u_max = rgb2yuv(z)[0][0][1]\n",
        "\n",
        "    z = [[[0.0, 1.0, 1.0]]]\n",
        "    v_min = rgb2yuv(z)[0][0][2]\n",
        "    z = [[[1.0, 0.0, 0.0]]]\n",
        "    v_max = rgb2yuv(z)[0][0][2]\n",
        "\n",
        "    df = pd.DataFrame(\n",
        "        data={\n",
        "            \"components\": [\"Y\", \"U\", \"V\"],\n",
        "            \"min\": [y_min, u_min, v_min],\n",
        "            \"max\": [y_max, u_max, v_max],\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "find_yuv_minmax()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \u0418\u0437\u043e\u0431\u0440\u0435\u0442\u0430\u044f \u0441\u0432\u043e\u0439 ~~\u0432\u0435\u043b\u043e\u0441\u0438\u043f\u0435\u0434~~ `rgb2ycbcr`\n",
        "\n",
        "\u0411\u0443\u0434\u0435\u0442 \u0437\u0434\u043e\u0440\u043e\u0432\u043e \u0441\u0436\u0438\u043c\u0430\u0442\u044c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 `[0, 255]`. \u041d\u0435 \u0431\u0443\u0434\u0443 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c YCbCr \u0442\u0430\u043a, \u043a\u0430\u043a \u043e\u043d \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u0442 \u0434\u0438\u0430\u043f\u0430\u0437\u043e\u043d \u043f\u043e Y. \u0418\u0437\u043e\u0431\u0440\u0435\u0442\u0435\u043c \n",
        "\u0441\u0432\u043e\u0435 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 `rgb2yuv`, \u0442\u0430\u043a \u0447\u0442\u043e\u0431\u044b \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0431\u044b\u043b \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u0438\u043c \u0432 \u0442\u0438\u043f\u0435 `uint8`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def my_rgb2yuv(image):\n",
        "    y, u, v = np.split(rgb2yuv(image), [1, 2], axis=2)\n",
        "\n",
        "    y8 = (y + 0.000) * 255\n",
        "    u8 = (u + 0.436) * 292\n",
        "    v8 = (v + 0.615) * 207\n",
        "\n",
        "    # Compress, decompress\n",
        "    y8 = np.rint(y8).astype(np.uint8)\n",
        "    u8 = np.rint(u8).astype(np.uint8)\n",
        "    v8 = np.rint(v8).astype(np.uint8)\n",
        "\n",
        "    y = y8 / 255 - 0.000\n",
        "    u = u8 / 292 - 0.436\n",
        "    v = v8 / 207 - 0.615\n",
        "\n",
        "    rgb = yuv2rgb(np.dstack((y, u, v)))\n",
        "\n",
        "    print(\n",
        "        \"\u041c\u0438\u043d\u0438\u043c\u0443\u043c \u0438 \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c \u0432 rgb \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0438:\",\n",
        "        round(rgb.min(), 3),\n",
        "        round(rgb.max(), 3),\n",
        "    )\n",
        "    print(\n",
        "        \"\u041d\u0430 \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u0445 \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u0432\u044b\u0445\u043e\u0434\u044f\u0449\u0438\u0435 \u0437\u0430 \u043f\u0440\u0435\u0434\u0435\u043b\u044b \u044f\u0440\u043a\u043e\u0441\u0442\u0438. \u041b\u0443\u0447\u0448\u0435 \u0432\u0441\u0435\u0433\u043e \u0438\u0445 \u043e\u0431\u0440\u0435\u0437\u0430\u0442\u044c.\"\n",
        "    )\n",
        "    rgb[rgb < 0] = 0\n",
        "    rgb[rgb > 1] = 1\n",
        "    rgb = np.rint(rgb * 255).astype(np.uint8)\n",
        "    plt.imshow(rgb)\n",
        "\n",
        "    print(\"PSNR:\", round(weighted_psnr(rgb, lenna_rgb_256x256), 3))\n",
        "\n",
        "\n",
        "my_rgb2yuv(lenna_rgb_256x256)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\n",
        "    weighted_psnr(\n",
        "        np.rint(ycbcr2rgb(np.rint(rgb2ycbcr(lenna_rgb_256x256))) * 255).astype(\n",
        "            np.uint8\n",
        "        ),\n",
        "        lenna_rgb_256x256,\n",
        "    )\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u0421\u0432\u043e\u0439 \u0432\u0435\u043b\u043e\u0441\u0438\u043f\u0435\u0434 \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u043b\u0443\u0447\u0448\u0435 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u0447\u043d\u043e\u0433\u043e \u0440\u0435\u0448\u0435\u043d\u0438\u044f, \u0442\u0430\u043a \u043a\u0430\u043a \u0445\u0440\u0430\u043d\u0438\u0442 \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u043f\u043e\u043b\u043d\u043e\u043c \u0434\u0438\u0430\u043f\u0430\u0437\u043e\u043d\u0435."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \u042d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u04421. \u041a\u0430\u043d\u0430\u043b\u044b \u043f\u043e\u0445\u043e\u0436\u0438 \u0434\u0440\u0443\u0433 \u043d\u0430 \u0434\u0440\u0443\u0433\u0430. \u0427\u0442\u043e \u0435\u0441\u043b\u0438 \u043f\u043e\u043b\u0443\u0447\u0430\u0442\u044c U \u0438\u043b\u0438 V \u0438\u0437 Y?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def only_y_transform(image):\n",
        "    _, axs = plt.subplots(ncols=4)\n",
        "\n",
        "    y, u, v = np.split(rgb2yuv(image), [1, 2], axis=2)\n",
        "\n",
        "    axs[0].imshow(image)\n",
        "    axs[0].set_title(\"RGB\")\n",
        "    axs[1].imshow(u, cmap=\"gray\")\n",
        "    axs[1].set_title(\"U\")\n",
        "\n",
        "    y8 = (y + 0.000) * 255\n",
        "    u8 = (u + 0.436) * 292\n",
        "    v8 = (v + 0.615) * 207\n",
        "\n",
        "    tr = find_block_transform(u8, y8, 0, 0, y8.shape[0], 1)\n",
        "    intensity_offset_u8 = tr.intensity_offset\n",
        "\n",
        "    tr = find_block_transform(v8, y8, 0, 0, y8.shape[0], 1)\n",
        "    intensity_offset_v8 = tr.intensity_offset\n",
        "\n",
        "    u8_from_y8 = 0.75 * y8 + intensity_offset_u8\n",
        "    v8_from_y8 = 0.75 * y8 + intensity_offset_v8\n",
        "\n",
        "    # Compress, decompress\n",
        "\n",
        "    y = y8 / 255 - 0.000\n",
        "    u_from_y = u8_from_y8 / 292 - 0.436\n",
        "    v_from_y = v8_from_y8 / 207 - 0.615\n",
        "\n",
        "    axs[2].imshow(u_from_y, cmap=\"gray\")\n",
        "    axs[2].set_title(f\"U from Y, psnr: {round(psnr(u, u_from_y), 2)}\")\n",
        "\n",
        "    rgb = yuv2rgb(np.dstack((y, u_from_y, v_from_y)))\n",
        "    rgb[rgb < 0] = 0\n",
        "    rgb[rgb > 1] = 1\n",
        "\n",
        "    axs[3].imshow(rgb, cmap=\"gray\")\n",
        "    axs[3].set_title(f\"result, psnr: {round(weighted_psnr(rgb, image), 2)}\")\n",
        "\n",
        "    plt.savefig(\"images/only_y.jpg\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "only_y_transform(lenna_rgb_256x256)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Save only Y component](images/only_y.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "U \u0432\u043e\u0441\u0441\u0442\u0430\u043d\u043e\u0432\u043b\u0435\u043d\u043d\u044b\u0439 \u0438\u0437 Y \u0441\u043e\u0432\u0435\u0440\u0448\u0435\u043d\u043d\u043e \u043d\u0435\u043f\u043e\u0445\u043e\u0436 \u043d\u0430 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b.\n",
        "\n",
        "\u041d\u0430 \u043e\u0431\u0449\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0438 \u0432\u0438\u0434\u043d\u043e \u0441\u0438\u043b\u044c\u043d\u043e\u0435 \u0438\u0441\u043a\u0430\u0436\u0435\u043d\u0438\u0435 \u0446\u0432\u0435\u0442\u043e\u0432."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \u042d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442 2. \u0427\u0442\u043e \u0435\u0441\u043b\u0438 \u0445\u0440\u0430\u043d\u0438\u0442\u044c \u043c\u0435\u043d\u044c\u0448\u0435 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438 \u043e \u0446\u0432\u0435\u0442\u0435?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "def resize_uv_transform(image, mn=8):\n",
        "    _, axs = plt.subplots(ncols=2)\n",
        "\n",
        "    y, u, v = np.split(rgb2yuv(image), [1, 2], axis=2)\n",
        "\n",
        "    axs[0].imshow(image)\n",
        "    axs[0].set_title(\"RGB\")\n",
        "\n",
        "    u = resize(u, (u.shape[0] // mn, u.shape[1] // mn))\n",
        "    v = resize(v, (v.shape[0] // mn, v.shape[1] // mn))\n",
        "\n",
        "    y8 = (y + 0.000) * 255\n",
        "    u8 = (u + 0.436) * 292\n",
        "    v8 = (v + 0.615) * 207\n",
        "\n",
        "    # Compress, decompress\n",
        "\n",
        "    y = y8 / 255 - 0.000\n",
        "    u = u8 / 292 - 0.436\n",
        "    v = v8 / 207 - 0.615\n",
        "\n",
        "    u = resize(u, (u.shape[0] * mn, u.shape[1] * mn))\n",
        "    v = resize(v, (v.shape[0] * mn, v.shape[1] * mn))\n",
        "\n",
        "    rgb = yuv2rgb(np.dstack((y, u, v)))\n",
        "    rgb[rgb < 0] = 0\n",
        "    rgb[rgb > 1] = 1\n",
        "\n",
        "    axs[1].imshow(rgb)\n",
        "    axs[1].set_title(f\"result, psnr: {round(weighted_psnr(rgb, image), 2)}\")\n",
        "\n",
        "    plt.savefig(\"images/resize_uv.jpg\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "resize_uv_transform(lenna_rgb_256x256)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Resize U and V components](images/resize_uv.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def optimal_mn(image, mns=(2, 4, 8, 16, 32, 64, 128, 256)):\n",
        "    psnrs = []\n",
        "\n",
        "    for mn in tqdm(mns):\n",
        "        y, u, v = np.split(rgb2yuv(image), [1, 2], axis=2)\n",
        "        u = resize(u, (u.shape[0] // mn, u.shape[1] // mn))\n",
        "        v = resize(v, (v.shape[0] // mn, v.shape[1] // mn))\n",
        "\n",
        "        y8 = (y + 0.000) * 255\n",
        "        u8 = (u + 0.436) * 292\n",
        "        v8 = (v + 0.615) * 207\n",
        "\n",
        "        # Compress, decompress\n",
        "\n",
        "        y = y8 / 255 - 0.000\n",
        "        u = u8 / 292 - 0.436\n",
        "        v = v8 / 207 - 0.615\n",
        "\n",
        "        u = resize(u, (u.shape[0] * mn, u.shape[1] * mn))\n",
        "        v = resize(v, (v.shape[0] * mn, v.shape[1] * mn))\n",
        "\n",
        "        rgb = yuv2rgb(np.dstack((y, u, v)))\n",
        "        rgb[rgb < 0] = 0\n",
        "        rgb[rgb > 1] = 1\n",
        "\n",
        "        psnrs.append(weighted_psnr(rgb, image))\n",
        "\n",
        "    plt.plot(mns, psnrs)\n",
        "    plt.savefig(\"images/optimal_mn.jpg\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "optimal_mn(lenna_rgb_256x256)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Optimal resize multiplier](images/optimal_mn.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u0423\u043c\u0435\u043d\u044c\u0448\u0435\u043d\u0438\u0435 \u0440\u0430\u0437\u043c\u0435\u0440\u0430 U \u0438 V \u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442 \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0432\u043b\u0438\u044f\u043d\u0438\u0435."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u0426\u0432\u0435\u0442\u043d\u043e\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result_rgb = comp.compress2(lenna_rgb_256x256, quality=60)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "len(result_rgb)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def show_colored_decompress(orig, result):\n",
        "    img = comp.decompress(result, 25)\n",
        "    _, axs = plt.subplots(ncols=2)\n",
        "    axs[0].imshow(img)\n",
        "    axs[0].set_title(f\"its: 25, psnr: {round(weighted_psnr(orig, img), 3)}\")\n",
        "    axs[1].imshow(orig, cmap=\"gray\")\n",
        "    axs[1].set_title(\"orig\")\n",
        "\n",
        "    plt.savefig(\"images/colored_decompress.jpg\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "show_colored_decompress(lenna_rgb_256x256, result_rgb)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Colored decompress](images/colored_decompress.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u041f\u043e\u0434\u0431\u043e\u0440 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430 `loss_limit`\n",
        "\n",
        "\u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 \u0432\u043b\u0438\u044f\u0435\u0442 \u043d\u0430 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u0441\u043c\u0430\u0442\u0440\u0438\u0432\u0430\u0435\u043c\u044b\u0445 \u0431\u043b\u043e\u043a\u043e\u0432. \u0415\u0433\u043e \u0443\u0432\u0435\u043b\u0438\u0447\u0435\u043d\u0438\u0435 \u043f\u0440\u0438\u0432\u043e\u0434\u0438\u0442 \u043a \u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u043c\u0443 \u0443\u0441\u043a\u043e\u0440\u0435\u043d\u0438\u044e \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u044b \u0437\u0430 \n",
        "\u0441\u0447\u0435\u0442 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043d\u0430\u0439\u0434\u0435\u043d\u043d\u044b\u0445 \u0431\u043b\u043e\u043a\u043e\u0432."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def find_loss_limit(image, loss_limits=(16, 32, 64, 128, 256)):\n",
        "    data = {\"loss_limit\": [], \"psnr\": [], \"time\": []}\n",
        "\n",
        "    for loss_limit in loss_limits:\n",
        "        start = time.time()\n",
        "        result = comp.compress(\n",
        "            image,\n",
        "            block_size=16,\n",
        "            stride=8,\n",
        "            block_size_limit=8,\n",
        "            uv_block_size=32,\n",
        "            loss_limit=loss_limit,\n",
        "        )\n",
        "        result = comp.decompress(result, 25)\n",
        "        duration = time.time() - start\n",
        "\n",
        "        data[\"loss_limit\"].append(loss_limit)\n",
        "        data[\"psnr\"].append(weighted_psnr(result, image))\n",
        "        data[\"time\"].append(duration)\n",
        "\n",
        "    df = pd.DataFrame(\n",
        "        data={\n",
        "            \"loss_limit\": data[\"loss_limit\"],\n",
        "            \"psnr\": data[\"psnr\"],\n",
        "            \"time\": data[\"time\"],\n",
        "        }\n",
        "    )\n",
        "\n",
        "    plt.plot(df[\"loss_limit\"], df[\"psnr\"], label=\"psnr\")\n",
        "    plt.legend()\n",
        "    plt.savefig(\"images/psnr_from_loss_limit.jpg\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(df[\"loss_limit\"], df[\"time\"], label=\"time\")\n",
        "    plt.legend()\n",
        "    plt.savefig(\"images/time_from_loss_limit.jpg\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "find_loss_limit(lenna_rgb_256x256)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![PSNR from loss limit](images/psnr_from_loss_limit.jpg)\n",
        "![time from loss limit](images/time_from_loss_limit.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u041d\u0435\u0431\u043e\u043b\u044c\u0448\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f `loss_limit` \u043f\u0440\u0438\u0432\u043e\u0434\u044f\u0442 \u043a \u0441\u043b\u0438\u0448\u043a\u043e\u043c \u0434\u043e\u043b\u0433\u0438\u043c \u043f\u043e\u0438\u0441\u043a\u0430\u043c \u0431\u043b\u043e\u043a\u043e\u0432. \u0412\u044b\u0431\u0435\u0440\u0435\u043c \u0431\u043e\u043b\u044c\u0448\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0434\u043b\u044f \u0443\u0441\u043a\u043e\u0440\u0435\u043d\u0438\u044f."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u041f\u043e\u0441\u0442\u0440\u043e\u0438\u043c \u0433\u0440\u0430\u0444\u0438\u043a \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430\n",
        "\u041a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u0432 \u0434\u0430\u043d\u043d\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435 \u0431\u0443\u0434\u0435\u0442 \u0438\u0437\u043c\u0435\u0440\u044f\u0442\u044c\u0441\u044f \u043f\u043e PSNR (\u0430 \u0437\u043d\u0430\u0447\u0438\u0442 \u0432 \u0434\u0435\u0446\u0438\u0431\u0435\u043b\u0430\u0445).\n",
        "\n",
        "\u042d\u0442\u043e \u0431\u0430\u0437\u043e\u0432\u044b\u0439 \u0433\u0440\u0430\u0444\u0438\u043a \u0434\u043b\u044f \u043f\u043e\u043d\u0438\u043c\u0430\u043d\u0438\u044f \u0441\u043e\u043e\u0442\u043d\u043e\u0448\u0435\u043d\u0438\u044f \u043c\u0435\u0436\u0434\u0443 \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u043e\u043c \u0441\u0436\u0430\u0442\u0438\u044f \u0438 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e\u043c, \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c\u044b\u043c \u043d\u0430 \u0432\u044b\u0445\u043e\u0434\u0435. \u041c\u043e\u0436\u043d\u043e \n",
        "\u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0435\u0442\u044c, \u043a\u0430\u043a \u043e\u043d \u0431\u0443\u0434\u0435\u0442 \u043c\u0435\u043d\u044f\u0442\u044c\u0441\u044f \u0432 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 \u043e\u0442 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u0438\u0442\u0435\u0440\u0430\u0446\u0438\u0439 \u043f\u0440\u0438 \u0434\u0435\u043a\u043e\u043c\u043f\u0440\u0435\u0441\u0441\u0438\u0438, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def test_image(img, quality=(0, 20, 40, 60, 80, 100)):\n",
        "    compressed_images = [comp.compress2(img, quality=q) for q in quality]\n",
        "    decompressed_images = [\n",
        "        comp.decompress(compressed) for compressed in compressed_images\n",
        "    ]\n",
        "    compression_rates = (\n",
        "        np.array([len(compressed) for compressed in compressed_images]) / img.size\n",
        "    )\n",
        "    psnrs = [weighted_psnr(img, decompressed) for decompressed in decompressed_images]\n",
        "    return compression_rates, psnrs, decompressed_images\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_results(results):\n",
        "    _, ax = plt.subplots()\n",
        "\n",
        "    compression_rates, psnrs, _ = results\n",
        "    ax.plot(compression_rates, psnrs, marker=\"o\", ms=10, ls=\"-.\")\n",
        "\n",
        "    ax.set_xlabel(\"Compression Rate\", fontsize=16)\n",
        "    ax.set_ylabel(\"PSNR, dB\", fontsize=16)\n",
        "\n",
        "    plt.savefig(\"images/psnr_rate.jpg\")\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_images(results, quality=(0, 20, 40, 60, 80, 100)):\n",
        "    _, axs = plt.subplots(ncols=len(quality), figsize=(18, 5))\n",
        "\n",
        "    compression_rates, psnrs, decompressed_images = results\n",
        "    for i, image in enumerate(decompressed_images):\n",
        "        axs[i].imshow(image)\n",
        "        orig_size = 256 * 256 * 3  # TODO: Add support for other sizes\n",
        "        axs[i].set_title(\n",
        "            f\"psnr: {round(psnrs[i], 3)}, size: {int(compression_rates[i] * orig_size)}b\"\n",
        "        )\n",
        "\n",
        "    plt.savefig(\"images/qualities.jpg\")\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lenna_results = test_image(lenna_rgb_256x256)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot_results(lenna_results)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot_images(lenna_results)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![PSNR from compression rate](images/psnr_rate.jpg)\n",
        "![Qualities](images/qualities.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u0423\u043b\u0443\u0447\u0448\u0438\u043c \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\n",
        "\u041e\u0434\u043d\u0438\u043c \u0438\u0437 \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0445 \u0441\u043f\u043e\u0441\u043e\u0431\u043e\u0432 \u0443\u043b\u0443\u0447\u0448\u0435\u043d\u0438\u044f \u0441\u0436\u0430\u0442\u0438\u044f \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0435 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438 \u043d\u0435 \u043d\u0430 \u0440\u0430\u0432\u043d\u044b\u0435 \u0431\u043b\u043e\u043a\u0438, \u0430 \u043d\u0430 \u0431\u043b\u043e\u043a\u0438 \n",
        "\u0440\u0430\u0437\u043d\u044b\u0445 \u0440\u0430\u0437\u043c\u0435\u0440\u043e\u0432. \u041a\u0430\u043a \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u0443\u044e \u0447\u0430\u0441\u0442\u044c \u0437\u0430\u0434\u0430\u043d\u0438\u044f, \u043c\u044b \u043f\u0440\u0435\u0434\u043b\u0430\u0433\u0430\u0435\u043c \u0440\u0435\u0430\u043b\u0438\u0437\u043e\u0432\u0430\u0442\u044c \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0435 \u043a\u0432\u0430\u0434\u0440\u043e\u0434\u0435\u0440\u0435\u0432\u043e\u043c, \u044d\u0442\u043e \u043f\u043e\u0437\u0432\u043e\u043b\u0438\u0442 \u0431\u043e\u043b\u0435\u0435\n",
        "\u0433\u0438\u0431\u043a\u043e \u043d\u0430\u0441\u0442\u0440\u0430\u0438\u0432\u0430\u0442\u044c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0441\u0436\u0430\u0442\u0438\u044f \u0438 \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u043b\u0443\u0447\u0448\u0438\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center>\u041f\u0440\u0438\u043c\u0435\u0440 \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u043d\u0430 \u0431\u043b\u043e\u043a\u0438 \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c \u043a\u0432\u0430\u0434\u0440\u043e\u0434\u0435\u0440\u0435\u0432\u0430</center>\n",
        "\n",
        "\u0418\u0441\u0445\u043e\u0434\u043d\u043e\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 | \u0420\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0435 \u043a\u0432\u0430\u0434\u0440\u043e\u0434\u0435\u0440\u0435\u0432\u043e\u043c\n",
        "- | -\n",
        "![Source image](images/house.jpg) | ![Segmentation](images/quadtree.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Changelog\n",
        "\n",
        "1. \u041d\u0430\u0438\u0432\u043d\u0430\u044f \u0440\u0435\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f\n",
        "1. \u041e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d \u043f\u043e\u0438\u0441\u043a `intensity offset`\n",
        "1. \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0430 \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u043e\u0438\u0441\u043a\u0430 \u043f\u043e\u0432\u043e\u0440\u043e\u0442\u043e\u0432 \u0438 \u043e\u0442\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u043f\u043e\u043b\u043d\u043e\u0433\u043e \u043f\u0435\u0440\u0435\u0431\u043e\u0440\u0430\n",
        "1. \u0412\u043c\u0435\u0441\u0442\u043e \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u044f \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0431\u043b\u043e\u043a\u0430, \u0438\u0437\u043c\u0435\u043d\u044f\u0435\u0442\u0441\u044f \u0440\u0430\u0437\u043c\u0435\u0440 \u0432\u0441\u0435\u0433\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\n",
        "1. \u0420\u0435\u0430\u043b\u0438\u0437\u043e\u0432\u0430\u043d\u043e \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0435 `intensity scale` \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0431\u043b\u043e\u043a\u0430\n",
        "1. \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0430 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0430 \u0441\u0436\u0430\u0442\u0438\u044f \u0446\u0432\u0435\u0442\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u043a\u043e\u043d\u0432\u0435\u0440\u0442\u0430\u0446\u0438\u0438 \u0432 `YUV`\n",
        "1. \u0420\u0435\u0430\u043b\u0438\u0437\u043e\u0432\u0430\u043d\u043e \u043a\u0432\u0430\u0434\u0440\u043e\u0434\u0435\u0440\u0435\u0432\u043e\n",
        "1. \u041e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u043d\u0438\u044f \u043d\u0430 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430 `intensity scale`\n",
        "1. \u0411\u044b\u0441\u0442\u0440\u043e\u0435 \u0441\u0440\u0430\u0432\u043d\u0435\u043d\u0438\u0435 \u0440\u0430\u043d\u0433\u043e\u0432\u043e\u0433\u043e \u0438 \u0434\u043e\u043c\u0435\u043d\u043d\u044b\u0445 \u0431\u043b\u043e\u043a\u043e\u0432 \u043d\u0430 \u043f\u0440\u0438\u0433\u043e\u0434\u043d\u043e\u0441\u0442\u044c\n",
        "1. \u041e\u0431\u043d\u043e\u0432\u043b\u0435\u043d\u0438\u0435 \u0431\u0438\u0442\u043e\u0432\u043e\u0433\u043e \u043c\u0430\u0441\u0441\u0438\u0432\u0430 \u0434\u043b\u044f \u043f\u043e\u0432\u044b\u0448\u0435\u043d\u0438\u044f \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u043e\u0441\u0442\u0438 \u0441\u0436\u0430\u0442\u0438\u044f \u043f\u0440\u0438 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0438 \u043a\u0432\u0430\u0434\u0440\u043e\u0434\u0435\u0440\u0435\u0432\u0430\n",
        "1. \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u044b \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438 \u043a\u0432\u0430\u0434\u0440\u043e\u0434\u0435\u0440\u0435\u0432\u0430\n",
        "1. \u0423\u043c\u043d\u044b\u0439 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043f\u043e\u0438\u0441\u043a\u0430 \u043f\u043e\u0432\u043e\u0440\u043e\u0442\u043e\u0432 \u0438 \u043e\u0442\u0440\u0430\u0436\u0435\u043d\u0438\u0439\n",
        "1. \u041f\u0440\u043e\u0440\u0435\u0436\u0438\u0432\u0430\u043d\u0438\u0435 \u043d\u0435\u0432\u0430\u0436\u043d\u044b\u0445 \u043a\u043e\u043c\u043f\u043e\u043d\u0435\u043d\u0442 \u0446\u0432\u0435\u0442\u043d\u043e\u0433\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\n",
        "1. \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0430 \u043a\u043e\u0440\u0440\u0435\u043a\u0446\u0438\u044f \u0440\u0430\u0437\u0436\u0430\u0442\u043e\u0433\u043e `RGB` \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\n",
        "1. \u041f\u043e\u0438\u0441\u043a \u0431\u043b\u043e\u043a\u0430 \u043e\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u0442\u0441\u044f \u043f\u0440\u0438 \u0434\u043e\u0441\u0442\u0438\u0436\u0435\u043d\u0438\u0438 \u043f\u0440\u0438\u0435\u043c\u043b\u0435\u043c\u043e\u0433\u043e \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430\n",
        "1. \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u044b \u043f\u043e\u044f\u0441\u043d\u0435\u043d\u0438\u044f \u0438 \u0432\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}